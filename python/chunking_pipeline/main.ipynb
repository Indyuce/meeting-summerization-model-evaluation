{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dependences, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /home/linagora/anaconda3/lib/python3.10/site-packages (2.97.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (2.11.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (2.21.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.59.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.23.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/linagora/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: bitsandbytes in /home/linagora/.local/lib/python3.10/site-packages (0.39.1)\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-jfht7cax\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-jfht7cax\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit f92cc7034a49959b247a46a210b912e56a6f977d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.14)\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-tdflwk46\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-tdflwk46\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install bitsandbytes\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install tiktoken\n",
    "!pip install torch\n",
    "!pip install scipy\n",
    "!pip install einops # Falcon dependency\n",
    "!pip install huggingface_hub[\"cli\"] # To empty model cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Wed Aug 23 13:03:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   41C    P0    41W / 250W |  12824MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   43C    P0    39W / 250W |  13198MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:      181108932    13059888    19918188     1297876   148130856   165111668\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /workspace/.miniconda3/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2023.6.0)\n",
      "Requirement already satisfied: requests in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.51.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (23.1)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.38)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2022.12.7)\n",
      "Requirement already satisfied: wcwidth in /workspace/.miniconda3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.6)\n",
      "Installing collected packages: pfzy, InquirerPy\n",
      "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/mt0-xxl (55.8G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m b5461b49: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-40b-instruct (50.3K, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m ca78eac0: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel ichitaka/falcon-40b-instruct-8bit (41.9G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 03dd12af: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (27.6G, used 2 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: (detached) # modified 6 days ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m d008fe87: main # modified 2 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-7b-instruct (14.4G, used 5 hours ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m eb410fb6: main # modified 5 hours ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel mosaicml/mpt-7b-instruct (13.3G, used 19 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 925e0d80: main # modified 19 minutes ago\u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[69D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/mt0-xxl (55.8G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m b5461b49: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-40b-instruct (50.3K, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m ca78eac0: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel ichitaka/falcon-40b-instruct-8bit (41.9G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 03dd12af: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (27.6G, used 2 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: (detached) # modified 6 days ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m d008fe87: main # modified 2 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-7b-instruct (14.4G, used 5 hours ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m eb410fb6: main # modified 5 hours ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel mosaicml/mpt-7b-instruct (13.3G, used 19 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 925e0d80: main # modified 19 minutes ago\u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Empty model cache\n",
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, traceback, datetime, torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work.\n",
    "#model.generation_config.do_sample = False\n",
    "#model.generation_config.max_new_tokens = 2048\n",
    "#model.generation_config.temperature = .3\n",
    "#model.generation_config.top_k = 100\n",
    "\n",
    "DO_SAMPLE = True\n",
    "MAX_NEW_TOKENS = 2048\n",
    "TEMPERATURE = .3\n",
    "TOP_K = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### >>> XGen 7B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b685c98ea8aa48ee9a07b373efca50a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Loading checkpoint shards'), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Salesforce/xgen-7b-8k-inst'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_1 = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "P1: You're finally here! What took so long?\n",
    "P2: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\n",
    "P1: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\n",
    "P2: I don't think it can be avoided, to be honest.\n",
    "P1: perhaps it would be better if you started taking public transport system to work.\n",
    "P2: I think it's something that I'll have to consider. The public transport system is pretty good.\n",
    "P1: It would be better for the environment, too.\n",
    "P2: I know. I feel bad about how much my car is adding to the pollution problem in this city.\n",
    "P1: Taking the subway would be a lot less stressful than driving as well.\n",
    "P2: The only problem is that I'm going to really miss having the freedom that you have with a car.\n",
    "P1: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\n",
    "P2: That's true. I could certainly use the exercise!\n",
    "P1: So, are you going to quit driving to work then?\n",
    "P2: Yes, it's not good for me or for the environment.\n",
    "\n",
    "### Assistant: Two individuals discuss the delay caused by traffic congestion near Carrefour intersection. One suggests finding an alternate route or using public transport. They discuss the benefits of public transport for the environment, stress reduction, and consider biking as an option in good weather. Eventually, one person decides to stop driving to work due to health and environmental concerns.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "AC: Once search-and-rescue efforts are under control in China, building experts are going to begin looking at the extent of structural damage. Stanford University's Ann Kiremidjian is a structural engineer. She helped assess damage years after China's 1976 huge earthquake that killed about 250,000 people. Ann Kiremidjian, when you look at the pictures and video of the collapsed buildings around Chengdu, I bet you see things that I don't notice.\n",
    "Pr. AK: Alex, what I have seen from the video clips is first of all a lot of concrete buildings, what we call concrete frames, and I would classify them as a non-ductile concrete frame. What that means is that there is very little steel reinforcement in the concrete and as a result, the concrete cannot resist displacement in the horizontal direction.\n",
    "AC: It needs to have steel bars, I think that is called rebar. Yeah.\n",
    "Pr. AK: That is correct. Not enough rebar both in the vertical direction and in the horizontal direction. And in addition, you have to provide rebar going from the column to the beam at the joint to provide continuity and a way to transfer the forces from one member to the other.\n",
    "AC: You inspected buildings after this last, huge, terrible earthquake more than 30 years ago. Did you make recommendations to the Chinese government then?\n",
    "Pr. AK: At the time, they didn't have earthquake-resistant codes in place. And since then, we've had numerous discussions, and the Chinese have had very strong programs to develop seismic codes, to develop seismic hazard maps. The seismic hazard maps similar to the ones that we have in the United States, are developed with the purpose to identify regions of frequent large earthquakes that can cause damage to buildings, the very first step in any earthquake-resistant design.\n",
    "AC: And what about this region around Chengdu, the Sichuan province, is this prone to earthquakes?\n",
    "Pr. AK: Yes, all of China is in a highly seismic area. You would notice that there is a fault that runs along the plateau between the Himalayas and where Chengdu is. If you trace all the aftershocks, you can probably trace the fault line that has ruptured. To cause a magnitude 7.8 earthquake, you will need to rupture more than 100 kilometers of a fault, and it looks it is almost 200 kilometers of locations of aftershock which is likely to be the length of the rupture of the fault.\n",
    "AC: Is there some way to measure the size of the earthquake and then overlay that on a map of the region and figure out, we have to look at every single building within a particular radius from the epicenter? I mean do you have to do that?\n",
    "Pr. AK: Oh, we do that all the time. In fact, what typically you would do is you would focus within the first 15 or 20 kilometers from the rupture zone. It's not just the epicenter, but it is the rupture zone, and the rupture can run about a couple of hundred kilometers, as it is in the case of China. So you are talking a lot of buildings. A single inspector or 10 or 20 inspectors cannot perform that task in a reasonable amount of time. What you have to do is recruit all the professional structural engineers to help with the inspection process.\n",
    "AC: Ann, you're speaking to us from your home in Los Altos Hills, that's south of San Francisco. And it's two miles from the most notorious earthquake fault in North America, the San Andreas Fault.\n",
    "Pr. AK: Correct.\n",
    "AC: Can you explain to me why a structural engineer would build a house there?\n",
    "Pr. AK: Yes, indeed. You have to take certain precautions. We have taken into consideration the fact that we are close to the fault. Can we do more? Yes, we can. There's always a balancing act between the economics, how much can you afford, and what you are willing to live with. It's a beautiful area, the weather is lovely, it's close to my work, that's where I live.\n",
    "AC: Ann Kirmidjian teaches structural engineering at Stanford University. Professor, thank you.\n",
    "Pr. AK: You're welcome.\n",
    "AC: NPR's DAY TO DAY continues.\n",
    "\n",
    "### Assistant: After the recent earthquake in China, structural engineer Ann Kiremidjian from Stanford University discusses the extent of structural damage. She identifies that many collapsed buildings had non-ductile concrete frames lacking sufficient steel reinforcement, both vertically and horizontally. She emphasizes the importance of earthquake-resistant design, mentioning how China has developed seismic codes and hazard maps over the years. All of China, including the Sichuan province where the earthquake occurred, is in a highly seismic area due to fault lines. Kiremidjian explains that inspecting buildings after earthquakes involves focusing on the rupture zone within the first 15-20 kilometers, which requires the involvement of numerous professional structural engineers. The interview also touches on building near earthquake faults, highlighting the trade-off between economic considerations and safety precautions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE_2 = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    "\n",
    "### Human: Summarize the following dialogue provided the context.\n",
    "\n",
    "1) Some context\n",
    "{summary}\n",
    "\n",
    "2) Dialogue:\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "INTERMEDIATE_FOLDER = 'xgen_7b_2sl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_from_output_sequence(output, n_shot = 2):\n",
    "    \n",
    "    # Un-prompt output\n",
    "    delimiter = '### Assistant:'\n",
    "    output = delimiter.join(output.split(delimiter)[1 + n_shot:])\n",
    "    \n",
    "    # Remove white spaces in front of summary\n",
    "    while len(output) > 0 and output[0] == ' ':\n",
    "        output = output[1:]\n",
    "    \n",
    "    # Remove <|endoftext|>\n",
    "    eos_token = '\\n<|endoftext|>'\n",
    "    output = output[:-len(eos_token)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def generate_output(prompt, counter, chunks):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    print('---- Computing chunk', counter, 'of', len(chunks), 'total, size:', len(input_ids['input_ids'][0]), 'tokens')\n",
    "    output_ids = model.generate(**input_ids, do_sample=DO_SAMPLE, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, eos_token_id=50256, top_k=TOP_K)\n",
    "    return tokenizer.decode(output_ids[0]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### >>> Falcon 7B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiiuae/falcon-7b\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m     model_name,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      8\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_1 = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    ">>QUESTION<<Summarize the following text.\n",
    "\n",
    "{text}\n",
    ">>ANSWER<<\"\"\"\n",
    "\n",
    "INTERMEDIATE_FOLDER = 'falcon_7b_inst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_from_output_sequence(output, n_shot = 0):\n",
    "    \n",
    "    # Un-prompt output\n",
    "    delimiter = '>>ANSWER<<'\n",
    "    output = delimiter.join(output.split(delimiter)[1 + n_shot:])\n",
    "    \n",
    "    # Remove white spaces in front of summary\n",
    "    while len(output) > 0 and output[0] == ' ':\n",
    "        output = output[1:]\n",
    "    \n",
    "    # Remove <|endoftext|>\n",
    "    eos_token = '<|endoftext|>'\n",
    "    output = output[:-len(eos_token)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def generate_output(prompt, counter, chunks):\n",
    "    input_ids = tokenizer(prompt, return_token_type_ids=False, return_tensors=\"pt\").to('cuda')\n",
    "    print('---- Computing chunk', counter, 'of', len(chunks), 'total, size:', len(input_ids['input_ids'][0]), 'tokens')\n",
    "    output_ids = model.generate(**input_ids, do_sample=DO_SAMPLE, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, top_k=TOP_K)\n",
    "    return tokenizer.decode(output_ids[0]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### >>> MPT-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating an MPTForCausalLM model from /workspace/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b-instruct/925e0d80e50e77aaddaf9c3ced41ca4ea23a1025/modeling_mpt.py\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ea42b0a2a74823b4433283a612011e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The model type mpt is not yet supported to be used with BetterTransformer. Feel free to open an issue at https://github.com/huggingface/optimum/issues if you would like this model type to be supported. Currently supported models are: dict_keys(['albert', 'bark', 'bart', 'bert', 'bert-generation', 'blenderbot', 'bloom', 'camembert', 'blip-2', 'clip', 'codegen', 'data2vec-text', 'deit', 'distilbert', 'electra', 'ernie', 'fsmt', 'gpt2', 'gpt_bigcode', 'gptj', 'gpt_neo', 'gpt_neox', 'hubert', 'layoutlm', 'llama', 'm2m_100', 'marian', 'markuplm', 'mbart', 'opt', 'pegasus', 'rembert', 'prophetnet', 'roberta', 'roc_bert', 'roformer', 'splinter', 'tapas', 't5', 'vilt', 'vit', 'vit_mae', 'vit_msn', 'wav2vec2', 'whisper', 'xlm-roberta', 'yolos']).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      9\u001b[0m     model_name,\n\u001b[1;32m     10\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m     12\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bettertransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3586\u001b[0m, in \u001b[0;36mPreTrainedModel.to_bettertransformer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3581\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install optimum>=1.7.0 to use Better Transformer. The version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimum_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3582\u001b[0m     )\n\u001b[1;32m   3584\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbettertransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BetterTransformer\n\u001b[0;32m-> 3586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBetterTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniconda3/lib/python3.10/site-packages/optimum/bettertransformer/transformation.py:228\u001b[0m, in \u001b[0;36mBetterTransformer.transform\u001b[0;34m(model, keep_original_model, max_memory, offload_dir, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m can not be supported to be used with BetterTransformer. The identified reason is:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBetterTransformerManager\u001b[38;5;241m.\u001b[39mCAN_NOT_BE_SUPPORTED[model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Currently supported models are:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBetterTransformerManager\u001b[38;5;241m.\u001b[39mMODEL_MAPPING\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m BetterTransformerManager\u001b[38;5;241m.\u001b[39msupports(model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type):\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not yet supported to be used with BetterTransformer. Feel free\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to open an issue at https://github.com/huggingface/optimum/issues if you would like this model type to be supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Currently supported models are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBetterTransformerManager\u001b[38;5;241m.\u001b[39mMODEL_MAPPING\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse(torch\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m parse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.14\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetterTransformer requires torch>=2.0 but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is installed. Please upgrade PyTorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The model type mpt is not yet supported to be used with BetterTransformer. Feel free to open an issue at https://github.com/huggingface/optimum/issues if you would like this model type to be supported. Currently supported models are: dict_keys(['albert', 'bark', 'bart', 'bert', 'bert-generation', 'blenderbot', 'bloom', 'camembert', 'blip-2', 'clip', 'codegen', 'data2vec-text', 'deit', 'distilbert', 'electra', 'ernie', 'fsmt', 'gpt2', 'gpt_bigcode', 'gptj', 'gpt_neo', 'gpt_neox', 'hubert', 'layoutlm', 'llama', 'm2m_100', 'marian', 'markuplm', 'mbart', 'opt', 'pegasus', 'rembert', 'prophetnet', 'roberta', 'roc_bert', 'roformer', 'splinter', 'tapas', 't5', 'vilt', 'vit', 'vit_mae', 'vit_msn', 'wav2vec2', 'whisper', 'xlm-roberta', 'yolos'])."
     ]
    }
   ],
   "source": [
    "model_name = 'mosaicml/mpt-7b-instruct'\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "config.attn_config['attn_impl'] = 'triton'\n",
    "config.init_device = 'cuda:0' # For fast initialization directly on GPU!\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template from HuggingFace. Dolly 15k\n",
    "PROMPT_TEMPLATE_1 = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "Summarize the following text.\n",
    "{text}\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "INTERMEDIATE_FOLDER = 'mpt_7b_inst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_from_output_sequence(output, n_shot = 0):\n",
    "    \n",
    "    # Un-prompt output\n",
    "    delimiter = '###Response:\\n'\n",
    "    output = delimiter.join(output.split(delimiter)[1 + n_shot:])\n",
    "    \n",
    "    # Remove white spaces in front of summary\n",
    "    while len(output) > 0 and output[0] == ' ':\n",
    "        output = output[1:]\n",
    "    \n",
    "    # Remove <|endoftext|>\n",
    "    eos_token = '<|endoftext|>'\n",
    "    output = output[:-len(eos_token)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def generate_output(prompt, counter, chunks):\n",
    "    input_ids = tokenizer(prompt, return_token_type_ids=False, return_tensors=\"pt\").to('cuda')\n",
    "    print('---- Computing chunk', counter, 'of', len(chunks), 'total, size:', len(input_ids['input_ids'][0]), 'tokens')\n",
    "    output_ids = model.generate(**input_ids, do_sample=DO_SAMPLE, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, top_k=TOP_K)\n",
    "    return tokenizer.decode(output_ids[0]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 samples: ['sample_10_9852.txt', 'sample_11_10498.txt', 'sample_12_11166.txt', 'sample_13_4562.txt', 'sample_14_6858.txt', 'sample_15_9989.txt', 'sample_16_6057.txt', 'sample_17_4135.txt', 'sample_18_9825.txt', 'sample_19_9648.txt', 'sample_1_4693.txt', 'sample_20_13365.txt', 'sample_21_7283.txt', 'sample_22_6522.txt', 'sample_23_9169.txt', 'sample_24_10638.txt', 'sample_25_2751.txt', 'sample_26_7860.txt', 'sample_27_9004.txt', 'sample_28_5705.txt', 'sample_29_3855.txt', 'sample_2_11567.txt', 'sample_30_8361.txt', 'sample_3_12019.txt', 'sample_4_13389.txt', 'sample_5_1343.txt', 'sample_6_10232.txt', 'sample_7_11826.txt', 'sample_8_7292.txt', 'sample_9_4578.txt']\n"
     ]
    }
   ],
   "source": [
    "def mkdir(folder_path):\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def get_intermediate_file_path(sample):\n",
    "    global INTERMEDIATE_FOLDER\n",
    "\n",
    "    return \"intermediate/\" + INTERMEDIATE_FOLDER + '/' + sample\n",
    "\n",
    "# Load samples from dataset\n",
    "samples = os.listdir('input/texts')\n",
    "samples = [sample for sample in samples if sample.endswith('.txt')]\n",
    "samples.sort()\n",
    "n_samples = len(samples)\n",
    "print('Found', n_samples, 'samples:', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chunking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHARACTER_CHUNK_SIZE = 2000 * 3\n",
    "\n",
    "def chunkize(text):\n",
    "    \"\"\"\n",
    "    Greedy implementation of a dialogue transcript chunking algorithm. This method returns a list of transcript chunks.\n",
    "    - It priorities stability over performance. There is a set maximum chunk size for LLM inference stability. Really long utterances bypass this limit.\n",
    "    - It guarantees the cuts are made at utterance ends.\n",
    "\n",
    "    !! WARNING !! The maximum size is in characters, not tokens. A good upper bound shall be used as there are\n",
    "    no clear and easy correspondance between characters and tokens, as it obviously depends on the model tokenizer.\n",
    "\n",
    "    Dialogue format recognized (used in the HF AMI dataset):\n",
    "    ----------------------\n",
    "    <A> Hello!\n",
    "    <B> Hey there\n",
    "    <A> What have you been up to\n",
    "    <B> Not much honestly\n",
    "    ----------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    chunks = [] # Final list of transcript chunks. This makes up the loop invariant\n",
    "    utterances = text.split('\\n') # Transcript is split into sentences\n",
    "    utterances.reverse() # Reverse everything!!\n",
    "    current_chunk = ''\n",
    "\n",
    "    # While there is still an utterance to process\n",
    "    while len(utterances) > 0:\n",
    "        utterance = utterances.pop()\n",
    "\n",
    "        # Add to current chunk and proceed to next\n",
    "        if len(current_chunk) + len(utterance) <= MAX_CHARACTER_CHUNK_SIZE:\n",
    "            if len(current_chunk) > 0:\n",
    "                current_chunk += '\\n'\n",
    "            current_chunk += utterance\n",
    "        \n",
    "        # Utterance is larger than maximum chunk size\n",
    "        elif len(current_chunk) == 0:\n",
    "            chunks.append(current_chunk)\n",
    "            chunks.append(utterance)\n",
    "            current_chunk = ''\n",
    "\n",
    "        # Current chunk is big enough, append to list and create new one\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = utterance\n",
    "\n",
    "    if len(current_chunk) > 0:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sample(sample):\n",
    "    \n",
    "    # Current summary is the concatenation of all the chunk sub-summaries \n",
    "    current_summary = ''\n",
    "    #previous_summary = ''\n",
    "    chunks = chunkize(sample)\n",
    "\n",
    "    # Split into chunks\n",
    "    counter = 0\n",
    "    for chunk in chunks:\n",
    "        counter += 1\n",
    "\n",
    "        # Create prompt for this chunk\n",
    "        #if len(previous_summary) == 0:\n",
    "        #    prompt = PROMPT_TEMPLATE_1.format(text=chunk)\n",
    "        #    n_shot = 2\n",
    "        #else:\n",
    "        #    prompt = PROMPT_TEMPLATE_2.format(summary=previous_summary, text=chunk)\n",
    "        #    n_shot = 0\n",
    "        prompt = PROMPT_TEMPLATE_1.format(text=chunk)\n",
    "        #n_shot = 0\n",
    "            \n",
    "        # Sample one sub-input\n",
    "        output = generate_output(prompt, counter, chunks)\n",
    "        subsummary = result_from_output_sequence(output)\n",
    "        print(subsummary)\n",
    "\n",
    "        # Add to summary\n",
    "        if len(current_summary) > 0:\n",
    "            current_summary += '\\n\\n'\n",
    "        current_summary += subsummary\n",
    "        #previous_summary = subsummary\n",
    "    \n",
    "    return current_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "<UI> Excellent.\n",
      "<UI> So um I sent you the agenda, it was on the in the project documents.\n",
      "<UI> I don't know if you got a chance to just have a look at it.\n",
      "<UI> Anyway, it's the meeting's gonna follow more or less the same structure as last time, so we'll go round each of you in turn and you can give your presentations on what you've been up to.\n",
      "<UI> Um and at the end of that we need to discuss what you've come up with, so that we can make a decision on the key remote control concepts, so that's we need to know about the components' properties, materials, the user interface and any trends that the Marketing Expert has been watching.\n",
      "<ID> Right.\n",
      "<UI> Okay.\n",
      "<UI> Um, do you wanna start again?\n",
      "<ID> Okay.\n",
      "<UI> Let me we've got forty minutes.\n",
      "<ID> Right s so I haven't made a PowerPoint presentation, yeah, I I thought I'll use the whiteboard instead.\n",
      "<UI> You haven't made a PowerPoint, okay.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um mm, okay, so basically I'll start off by uh I thought I'll use the whiteboard because we have so many different options and what we can do is that we can start um uh rubbing off the options that we do not require and putting in the options that uh are m or highlighting or underlining them or something like that.\n",
      "<UI> Let's hope the pen holds out.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Okay, so uh I'll start again with a brief introduction to connect that anyway brief introduction to the insides of a remote control and uh then we can probably uh discuss the various components.\n",
      "<UI> Yeah.\n",
      "<ID> Yeah.\n",
      "<ID> Okay, so w what you see here is so this is the outside of the remote, right?\n",
      "<UI> Mm-hmm.\n",
      "<ID> If you open it, you have a circuit board here, right, and this is the chip that I was talking about last time.\n",
      "<ID> This basically sends information to a tr uh transistor here, which then uh sends the information to an LED device here.\n",
      "<UI> Mm-hmm.\n",
      "<ID> If you flip the printed circuit board, and this is th the most important point here, uh everything else is kind of Okay, so if you flip the circuit board, this is what it looks like.\n",
      "<ID> So you see for example a particular button attaches to a particular place on the PCB and uh on pressing this button I a circuit completes, the information goes to the chip, which is somewhere here and the chip that tra then translates the code into an infra infrared radiation, which goes goes out through there.\n",
      "<UI> Yeah.\n",
      "<ID> So uh the important point that I read over the website was uh that the configurations of these printed circuit circuit boards uh are quite cheap to make, you can ge get them printed as you want to, so w we can have a configuration um irrespective of the cost, the way we want to have.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right?\n",
      "<ID> So that's the important point here, so these are the different options that we have.\n",
      "<ID> Okay.\n",
      "<ID> So the batteries, I'll start with the battery, right?\n",
      "<UI> Mm-hmm.\n",
      "<ID> So they can be simple which is like uh the normal batteries in uh our uh the cells, yeah?\n",
      "<UI> Yeah.\n",
      "<ID> Uh thes these are the kind different kind of batteries that the company makes, right?\n",
      "<ID> So.\n",
      "<ID> And dynamos.\n",
      "<ID> Um yeah, yeah.\n",
      "<PM> Does that mean like a wind-up one?\n",
      "<ID> So uh I don't know if even if you want to consider this, but these are the different things that the company makes, so th they'll they'll since uh they'll come internally from the company, they'll be eas uh cheaper, uh all these options.\n",
      "<PM> A wind-up remote.\n",
      "<UI> Okay.\n",
      "<UI> Mm-hmm.\n",
      "<ID> So the third one is uh the kinetic energy ones.\n",
      "<PM> You could make the hand dynamo into an exercise bike, and then people could exercise whilst watching TV.\n",
      "<ID> Yeah.\n",
      "<UI> And charging their remote, yeah.\n",
      "<PM> Yeah, and stop worrying about the whole RSI from the remote thing, 'cause that's just Yay.\n",
      "<ID> Yeah, it's a good option.\n",
      "<ME> So what was what was this k ka Okay.\n",
      "<ID> The the kinetic energy one is uh that e uh uh they are usually modern watches, since our hand keeps moving, it keeps the watch ticking.\n",
      "<UI> Uh yeah.\n",
      "<ID> But I dunno i if it is a good idea for a remote control, because it'll just lie there for a long while sometimes.\n",
      "<UI> Mm-hmm.\n",
      "<UI> For a remote, 'cause you Yeah.\n",
      "<ID> But as soon as you pick it up it moves and then again it uh re recharges or something.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<ID> And the fourth option is the solar cells, which are also made by the company.\n",
      "<ID> Environment friendly.\n",
      "<ID> Okay um so I'll list things and then we can come back and discuss what what we think from uh everybody's perspective.\n",
      "<UI> Yeah.\n",
      "<ID> There are different cases that can be provided.\n",
      "<ID> They can be basically the shape of the cases, they can be flat, they can be curved with uh one-sided curved and one side flat, and they can be curved with on both the sides.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<ID> These are the three options, right?\n",
      "<ID> Um Yeah, would it be flat on both the sides, would be curved from one side, or whatever uh there were different kind of supplements available, um like it can be in plastic, rubber, wood, or titanium, right?\n",
      "<ME> Um you mean this would be like the the overall shape of the remote control, yeah, mm-hmm.\n",
      "<ME> Yeah, mm-hmm, mm-hmm.\n",
      "<ME> Mm-hmm mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Okay.\n",
      "<PM> Did you say wool?\n",
      "<ID> Wo wo wood.\n",
      "<UI> Wood, wood.\n",
      "<PM> Wood.\n",
      "<ID> Yeah.\n",
      "<PM> Oh right.\n",
      "<UI> A fluffy remote.\n",
      "<ID> Not wool.\n",
      "<PM> Yeah, you'll understand why when we get to my presenta.\n",
      "<ID> Oh really?\n",
      "<ID> Okay.\n",
      "<UI> Huh.\n",
      "<ID> Um the so uh we can use even um a certain titanium is also used uh in the company to make uh uh some space design equipment, so it's kind of um uh it'll be probably nicer to use, because it relates to the overall image of the company, but uh it cannot be used on a double curved surface.\n",
      "<ID> If we choose this, we cannot use titanium.\n",
      "<UI> Mm.\n",
      "<ID> For for these two we can use titanium, wood, rubber, or plastic.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Yeah?\n",
      "<ID> Uh okay, the interface options now.\n",
      "-----------------------------------------\n",
      "<ID> So we can have push-buttons, like most remotes do and our company is an expert in making push-buttons.\n",
      "<ID> Ooh.\n",
      "<ID> Uh we can have scroll wheels like the ones on um uh mouse pointers uh uh Yeah, yeah, something like that.\n",
      "<PM> Sony.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Sony Ericsson mobile phones has it.\n",
      "<PM> Mm.\n",
      "<ID> So, and they have they can even have an an integrated uh push-button inside the scrolling thing.\n",
      "<UI> Okay.\n",
      "<ID> The scroll plus push.\n",
      "<ID> So this is something that has been recently developed by the company, um in the last decade, so not too recent.\n",
      "<ID> And LCDs, we can have LCDs.\n",
      "<ID> So these two are recent and and this is q quite old.\n",
      "<UI> Mm-hmm.\n",
      "<ID> The various electronic options are um uh so th this concerns firs first of all the the chips I I showed you at uh so there's there's a chip behind this one, right?\n",
      "<ID> The PCB is uh inexpensive, so we can put put in uh whatever we want, but the various integrated circuit options are, we have either a simple one or a regular or advanced.\n",
      "<UI> Mm-hmm.\n",
      "<ID> And uh the price goes up as we go down, obviously.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um okay, so the good thing about uh wh wh why why we would want to use advanced u why we might want to use advanced is that LCDs can only come with the advanced chip.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um the we need regular or advanced for uh scroll wheels.\n",
      "<ID> Right?\n",
      "<ID> Um and the chip basically includes the infra infrared sender.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Yeah.\n",
      "<ID> Uh besides this in electr under electronics uh also the company has started making a sample sender, which is did not explained what i what it was, but I'm guessing that uh so they have a sample sender and a sample speaker.\n",
      "<ID> So I'm guessing that uh the sample speaker is probably something like um uh you know, as soon as you press a button, it it mm uh give gives you feedback, one five or whatever.\n",
      "<ID> Yeah, on.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um and uh I dunno whether sample sender sender has to do something with voice recognition or not, but anyway.\n",
      "<UI> Mm-hmm.\n",
      "<ID> So, these are the different options that we have.\n",
      "<ID> Okay, so th that's that's basically now now uh I think that uh we can integrate um uh you know, uh the user interface uh and uh the marketing things in that, keep uh taking out things from this and uh underlining things that are important, yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Excellent.\n",
      "<UI> Do you wanna stay somewhere near the board, so that if we need to you can sit down, but just we might need you to leap up.\n",
      "<ME> Okay.\n",
      "<ID> Yeah, yeah, sure.\n",
      "<ID> Sure.\n",
      "<ID> Yeah.\n",
      "<UI> What are you, PowerPoint, or Okay.\n",
      "<ME> Okay.\n",
      "<ME> Um I have some PowerPoint, yeah.\n",
      "<ID> Right.\n",
      "<ME> Oh.\n",
      "<UI> Do you think these pens can give you cancer of the hand?\n",
      "<ME> 'Kay.\n",
      "<UI> Some sort of radiation?\n",
      "<PM> No it's got its little camera in there, plug it in.\n",
      "<UI> Yeah.\n",
      "<ME> Okay.\n",
      "<PM> 'S a Ugly.\n",
      "<ID> Yeah, it should should do it.\n",
      "<ID> Yeah.\n",
      "<UI> Right, interface concept.\n",
      "<ME> Okay.\n",
      "<ME> Um to be honest actually, I mentioned some some of the things which which could fit on the on the this talk um this time, I m I mentioned them already in the previous talk.\n",
      "<UI> That's fine.\n",
      "<ME> So um yeah, this time um I might not have them on the slides but I I can just mention them aw again.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Okay.\n",
      "<ME> So um I thought um I would also include the definition of user interface um so it's the aspects of a of of a computer system or programme which can be seen uh by the user um and and which uh the mechanisms that the user uses to control its operation and input data.\n",
      "<ME> So this would p includes things like shape and size and buttons and um voice recognition as well, and colour, and so on.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Um um the method I employed this time was a again having a look to related products and mainly on the internet and then um analyse them uh from the point of view of user fen friendliness and also um whether their appearance was was pleasant.\n",
      "<ME> Um and then um this uh this um this can help us to decide which features we want to incorporate in our product.\n",
      "<UI> Mm-hmm.\n",
      "<ME> So some findings um um.\n",
      "<ME> So in in the case of many user interfaces, they're just so full of buttons that it's actually uh hard to find the ones you you really um want to use and um and it's just confusing, it takes y know time to learn.\n",
      "<ME> Um okay, and I thought I would just quickly show some of them that I found.\n",
      "<ME> Okay, some of them are here.\n",
      "<ME> Um well the picture is not very clear, but as you can see, there are actu oi, oh oh oh, sorry for that.\n",
      "<ME> 'S go back.\n",
      "<ID> That's nice one.\n",
      "<ME> Ah, no, please.\n",
      "<ME> Okay, so yeah, they're quite big and have many many buttons.\n",
      "<ME> Actually of the of all these I personally p prefer this one, because it's it's the smallest and and with with least uh with the smallest number of buttons as well.\n",
      "<ME> And I would say even the appearance of some of them is kind of not so nice.\n",
      "<UI> Mm.\n",
      "<ME> Um okay.\n",
      "<ME> So let's carry on with this.\n",
      "<ME> Um So uh um o other findings um some new things um used, uh some of them were mentioned already by our Technical um Designer uh.\n",
      "<ME> Our own company has developed a new in user interface uh wait, no this is not the one.\n",
      "<ME> Okay, there is a we can uh include voice recognition and um it allows i it's possible to record eighty different voice samples on it.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Mm.\n",
      "<ME> Uh so uh this uh this one was already mentioned uh the LC display.\n",
      "<UI> It's yeah.\n",
      "<ME> Um s another new development is a scroll button, which was also th also already mentioned.\n",
      "<ME> And uh our own manufacturing division ha has uh designed a new um uh programmable speech uh mm sorry uh speaker unit I guess it's it should be.\n",
      "<UI> Yeah.\n",
      "-----------------------------------------\n",
      "<ME> Um and this means that um once uh uh it it it comes together with a voice recognition, but it's once once the mm um gadget uh recognises uh the voice of the speaker, there can be a um pre-programmed answer, for example, you can pick up the remote control and say something to it like hello and it says some hello and your name or whatever.\n",
      "<UI> Uh-huh, hi yeah.\n",
      "<ME> So I mean this is also one of the n dev new developments which we might consider if we wanted to include.\n",
      "<ID> Mm.\n",
      "<ID> Uh sorry, uh can you go back for a second?\n",
      "<ID> Um uh are you sure wha what this means, a spinning wheel with the LC display?\n",
      "<ID> Uh oh yeah are th Oh okay, the iPod thing, yeah.\n",
      "<UI> It's like the like you said, no?\n",
      "<UI> The scroll scroll wheel.\n",
      "<PM> Yeah, you can't Oh, it's like the iPod.\n",
      "<ME> No no, the scroll button is a different thing.\n",
      "<ME> I I have a picture if you just a moment, I'll I'll show you.\n",
      "<ME> I wasn't completely sure myself, but I think it's just like um it's it's a wheel, it's like not separate buttons.\n",
      "<ME> Look, this one here.\n",
      "<ME> But I'm I'm not really sure whether whether you can really turn it round, it's like you press this or this or Uh-huh.\n",
      "<PM> G yeah, no, you can.\n",
      "<ID> Uh it's the iPod uh kind of uh Alright, right.\n",
      "<PM> It's like it's like where you you know how you have your your mouse, and y you go round and i it's kind of like that and you spin round and it yeah.\n",
      "<UI> Uh-huh.\n",
      "<ID> Okay, okay.\n",
      "<ID> So instead of going down you just spin yeah, yeah.\n",
      "<PM> It is You just go round and it is a bit weird at first, but it's actually very like fast.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Uh-huh.\n",
      "<UI> Mm-hmm.\n",
      "<PM> I like the the wheels that click on the side you you get 'em much slower, so it's quite good if you like searching quite a lot of stuff.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right.\n",
      "<PM> Do you know, if you're lookin if you're th scrolling through the A to Z of your music and you're looking for something at T, then it's a lot faster than the wheel, but you've got a lot less control over it.\n",
      "<ID> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right.\n",
      "<ID> So maybe I should include that here as well, LCDs um plus spinning.\n",
      "<ME> Mm.\n",
      "<UI> Yeah.\n",
      "<ME> Uh Okay, and the personal preferences are pretty much the same as as as last time.\n",
      "<UI> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ME> It it has to be small, simple.\n",
      "<ME> Okay, we decided to include voice recognition, so to have the standard uh major buttons like on, off, um ch the channels and and then um volume and then the rest would be a menu on the screen.\n",
      "<ME> Um and I I also thought uh if we want to keep it small and nice um and actually I I quite like the idea of a scroll a scrolling button, I thought it could be for for voice like, I dunno, it mm like on a um i like it used to be on Walkmans or something.\n",
      "<ME> There is uh I think there is no reason why we couldn't use something like this for for the remote control.\n",
      "<ID> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<ME> So yeah, that's uh that's it.\n",
      "<UI> Excellent.\n",
      "<UI> Okay, straight to trends, and then we can discuss it all at once.\n",
      "<ID> Right.\n",
      "<PM> Okay, I've put the copy of the presentation in um the yeah.\n",
      "<UI> The project documents.\n",
      "<UI> Excellent.\n",
      "<UI> If you two could both do that as well, in case we need to refer to it.\n",
      "<ID> Mm-hmm.\n",
      "<PM> Cool.\n",
      "<UI> Here it comes.\n",
      "<UI> Okay.\n",
      "<PM> Fabulous.\n",
      "<PM> Okay, cool.\n",
      "<PM> Um so what I did was to search the internet to come up with market trends and you know what users are gonna be wanting in the the near future.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Okay.\n",
      "<PM> Right.\n",
      "<PM> Now, the first aspect is apparently twice as important as the second aspect, which is twice as important as the third a aspect.\n",
      "<UI> Okay.\n",
      "<PM> So, I mean the the easy to use thing is fairly low down on the which I think given the target group is what you would expect, really.\n",
      "<ID> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Um, you know, people want something new, something technologically innovative and different, so the whole idea with the LCDs and the spinning and the colours and the voice recognition is quite like, quite the thing to go for.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Okay.\n",
      "<PM> And um, yeah it wants to look fancy, fancy look and feel.\n",
      "<ID> So um uh maybe uh as you're discussing things, is it okay if we just uh keep highlighting things here?\n",
      "<PM> So Yeah, yeah.\n",
      "<UI> Yeah, yeah, sure.\n",
      "<UI> Yeah.\n",
      "<ID> Right.\n",
      "<ID> So mm uh so it yeah, so probably voice recognition is is kind of important, right?\n",
      "<UI> That's over on the interface, if if you could put Yeah.\n",
      "<ID> Um and an yeah.\n",
      "<UI> And maybe the LCD and spinning so that means we need an advanced thing.\n",
      "<ID> Okay, I I have a point about LCD, I dunno if it is the right point to take it up.\n",
      "<ID> W uh LCDs are basically for feedback, right, to the user who's pressing buttons, and the feedback can come through television itself, so do we need an LCD on the remote?\n",
      "<UI> Mm-hmm.\n",
      "<PM> Mm.\n",
      "<PM> Depends how fast your television runs, really, don't don't you think?\n",
      "<PM> I mean we've got one of those um Telewest boxes and you put the number in the remote and then you wait and then it goes to the TV and then you wait, and then it comes, so i it actually takes quite a long time.\n",
      "<ID> Mm.\n",
      "<UI> Mm.\n",
      "<PM> And if you get the number in wrong, then it's a bit of a pain, so I think, you know, a screen on the remote would probably cut down your time on that.\n",
      "<ID> Right.\n",
      "<PM> But like remotes do tend to get f thrown about a bit.\n",
      "<ID> Right.\n",
      "<UI> It it is also quite nice though to to have something here so you don't interrupt the picture on the screen, so if you're watching something Yeah.\n",
      "<PM> You know?\n",
      "<PM> Yeah.\n",
      "<ID> That's true, yeah, that's also Right.\n",
      "<PM> And i it would be like I mean if you could make it integrate with the TV then it could come up with new information about what's on, and you could just see that on the remote rather than Yeah.\n",
      "<UI> Rather than having to interrupt your viewing pleasure.\n",
      "-----------------------------------------\n",
      "<PM> But um I think maybe a way to do it would be a similar way to how you have your mobile phone, you know, like you have the slidey ones and you have the flippy ones and then the screen's protected so it doesn't actually get scratched.\n",
      "<UI> Mm.\n",
      "<ID> Mm-hmm.\n",
      "<PM> So you can have like what looks like a normal remote control, you know or like a minimalist remote control.\n",
      "<UI> Yeah.\n",
      "<PM> So you got your buttons one to nine, your on and off and your volume on that and then if you want to mess about with it, you flip it open and, yeah.\n",
      "<ID> Mm right.\n",
      "<UI> And then you can flip it open.\n",
      "<ID> Okay.\n",
      "<ID> So now we seem to have a consensus that LCDs are definitely the way to go because of style and Right.\n",
      "<UI> Yeah, I think so.\n",
      "<PM> Yeah, so that kind of decides your whole chip thing.\n",
      "<UI> Yeah.\n",
      "<ID> You you agree?\n",
      "<ID> Maarika, yeah?\n",
      "<ME> Yep, yeah.\n",
      "<ID> Yeah.\n",
      "<UI> Right.\n",
      "<ID> So LCDs, yeah, definitely.\n",
      "<PM> Okay?\n",
      "<ID> Go on.\n",
      "<PM> Cool.\n",
      "<PM> Okay, apparently, fruit and vegetables will be providing inspiration.\n",
      "<PM> Sorry, I discovered clip art.\n",
      "<PM> Um so these will be an important feature for clothes, shoes and furniture.\n",
      "<PM> So I mean, I'm taking this to mean, you know, curviness.\n",
      "<PM> Do you know?\n",
      "<PM> 'Cause you don't tend to get flat vegetables.\n",
      "<UI> Yeah, and possibly even uneven, like not not symmet yeah.\n",
      "<ID> Mm-hmm.\n",
      "<PM> You know?\n",
      "<PM> Yeah, bit of asymmetry and stuff.\n",
      "<PM> But that would be a good way to to get in the whole um RSI issue in there, because I mean if you think most people use the remote control with their right hand ha right hands so you wanna you curve it so that it's suitable for use with the right hand.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right.\n",
      "<ME> Mm-hmm.\n",
      "<ID> Mm.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Um yeah, I'm not quite sure about the relevance of material will be spongy.\n",
      "<PM> Um Yeah, but I mean y you have to Well I suppose you wouldn't get a remote uh an electric shock off your remote control if it was made of rubber.\n",
      "<UI> Something a bit squishy and Yeah, and it'd help if you drop it, it protects it as well.\n",
      "<ID> Yeah, we we have we have rubber, but there is a problem that I forgot to discuss with the um with using So if if we use uh latex cases, they won't allow us to use solar cells, as an energy source that is the constraint, so um we could use titanium, wood or plastic uh or uh Yeah, w energy source.\n",
      "<ME> So it could be like a rubbery yeah, uh-huh.\n",
      "<PM> Yeah, yeah.\n",
      "<UI> To some degree.\n",
      "<UI> Uh-huh.\n",
      "<UI> Or if we want to use the the latex, then we have to go with one of the other um power things.\n",
      "<PM> If it's made of rubber you could get the kinetic energy fairly easily there, you could just bounce it up and down.\n",
      "<UI> From from bouncing it.\n",
      "<ID> Yeah, tap it on the desk, yeah.\n",
      "<UI> You can have it as like a little ball to bounce, that flips open.\n",
      "<PM> Yeah.\n",
      "<PM> Um so yeah, um okay.\n",
      "<ID> Mm.\n",
      "<ID> So probably double curved surface is the way to go, yeah, .\n",
      "<PM> Yeah, yeah.\n",
      "<UI> Mm yeah.\n",
      "<ID> Or or curved at one end and flat on the top, because I I'm not sure if it is flat on both both the sides, then ho how much easy would it be to reach for buttons, etcetera.\n",
      "<ID> Um Yeah.\n",
      "<PM> You have to have a certain element of flatness, I think.\n",
      "<PM> It it depends on the whole ergonomics of it, you know, it's like how you put your hands so y it's the least movement basically.\n",
      "<ID> Yeah.\n",
      "<ID> Yeah, singe single side curved or double side curved does not say too much, does it?\n",
      "<UI> Uh-huh.\n",
      "<ID> It uh Mm.\n",
      "<PM> No, I d I don't think it makes a lot of difference.\n",
      "<PM> I I have one of those s slidey phones and I mean the back is essentially straight, but it's curvy, so.\n",
      "<UI> Mm.\n",
      "<PM> Besides, you have four sides to a thing, so I mean does curved one side mean one side is straight and, you know curved two sides means the whole thing is just a big curvy p thing?\n",
      "<UI> Yeah, 'cause the Yeah.\n",
      "<ID> Uh I think uh Right.\n",
      "<ID> Right.\n",
      "<UI> Dunno.\n",
      "<ID> Di now did it say anywhere in your research material about this sliding stuff uh because um according to the information that I have, I think uh the onl only options that we have with the case is are these three.\n",
      "<PM> Yeah.\n",
      "<ID> Uh eith either we have uh a flat surfaced uh case or a curved surfaced case.\n",
      "<ID> It does not say anything about uh whether technically, you know, this this stuff is available at all.\n",
      "<UI> Nothing to open them.\n",
      "<PM> Yeah.\n",
      "<PM> Uh it's it's more about the protecting the LCD, which I think is where it came from.\n",
      "<ID> Right, yeah, yeah.\n",
      "<PM> But no, my research didn't tell me anything, which is why we have all the pictures, 'cause I had nothing better to do with my time.\n",
      "<ID> Right.\n",
      "<ID> Okay.\n",
      "<PM> Okay, cool.\n",
      "<UI> Anything else?\n",
      "<UI> What've we got?\n",
      "<PM> Uh combine style with a level of functionality, um beauty and practicality and a thing of beauty and p function.\n",
      "<UI> Okay, so.\n",
      "<ID> Cool, thanks.\n",
      "<PM> Okay?\n",
      "<ME> Thanks Yeah uh-hum yeah.\n",
      "<UI> Looking at what we've got, we we want an LCD display with a spinning wheel.\n",
      "<ID> Yeah.\n",
      "<ID> Let's let's try to r rub off things and yeah, so um hand dynamos are definitely out, right?\n",
      "<UI> Yeah, rub off some of those.\n",
      "<ID> You you got a wind dynamo, yeah.\n",
      "<UI> Yeah, it's not that's not streamlined and sexy, having a having a wind up.\n",
      "<ID> Okay.\n",
      "<ID> Um kinetic energy does seem to have some kind of uh uh appeal, but uh it's Yeah.\n",
      "<UI> I think tha Depends how much how much movement it really needs.\n",
      "<PM> It's about the practicality of it really, isn't it?\n",
      "<PM> You know?\n",
      "<ID> As against a watch, which constantly keeps moving, this this thing will have to be tapped every time, which which might be very frustrating for the user.\n",
      "<PM> I mean if I can't imagine a m wooden remote control.\n",
      "<ID> Kinetic energy it needs I don't have too much technical information on that, yeah, right.\n",
      "<UI> Pr presumably if they're suggesting it, then we could use it.\n",
      "<ID> Okay, let's keep it option uh keep an option, yeah.\n",
      "<UI> I'd I'd keep it on.\n",
      "<ID> Um the flat co completely flat case is definitely out, right?\n",
      "-----------------------------------------\n",
      "<UI> We don't want that it's no it's not not vegetable.\n",
      "<ID> It has to be at least curved from one side, yeah.\n",
      "<ME> Yeah it's yeah.\n",
      "<ID> Um okay, we still have all all the options.\n",
      "<ID> Wood, do you think wood will be a good idea?\n",
      "<ME> N wood is I can't n how do you uh I mean you can't keep it really small uh you can't make it like thin and The wood thing.\n",
      "<ID> Mm.\n",
      "<ID> Right.\n",
      "<UI> Mm.\n",
      "<ME> Because you need to you n you need to put all the technology in, so I mean if the case you add the case and it it becomes a bit bulky wi mm-mm yeah.\n",
      "<ID> Yeah if if it is really thin if it is really thin it it's likely to break, it's it's much more uh Right.\n",
      "<UI> Mm.\n",
      "<ME> Yeah, yeah.\n",
      "<UI> Yeah, and given that we're we're looking at more spongy material preferences, I ha would think maybe rubber or plastic is more Yeah.\n",
      "<ME> Yeah.\n",
      "<ME> U yeah wood is not really yeah.\n",
      "<PM> Well it's not very cleanable either, do you know.\n",
      "<ID> That's true.\n",
      "<ME> Yeah.\n",
      "<PM> It's it's not a practical I mean it's it's alright for a table, but for a remote control, you know.\n",
      "<ID> Yeah.\n",
      "<PM> And splinters and stuff and It just m doesn't make any sense, I think is the thing with wood.\n",
      "<ID> Yeah, okay wood is out.\n",
      "<UI> Yeah.\n",
      "<ID> Right.\n",
      "<ME> Yeah, yeah, in the case of remote control not really.\n",
      "<UI> Yeah.\n",
      "<ID> Okay, now for the really interesting stuff, the interface.\n",
      "<UI> Yeah.\n",
      "<ID> Right, so uh the the push-buttons is is our expertise uh in the industry, but uh it seems to be out of trend, you know, nobody seems to be Mm right.\n",
      "<PM> You have to have some push-buttons, don't you?\n",
      "<ME> Yeah, but you um I think for for the channel numb uh channel numbers you still need them, wouldn't you?\n",
      "<UI> Mm-hmm.\n",
      "<PM> G yeah, yeah.\n",
      "<ME> Yeah, so for channel numbers but But I th yeah but I think the LCD display is kind of yeah, it's faster with a m yeah and w if we dis and when we s um discussed that we might like this flipping open thing, then I mean y you can use it as a normal remote control, but if you do want to use LCD, then you flip it open, but it's it it's more time-consuming.\n",
      "<ID> Oh, if if we have LCD displays, that opens up a whole world, you know, if you have an LCD display, then mm you can select almost everything on the LCD display.\n",
      "<UI> Just for fast Yeah.\n",
      "<ID> Right.\n",
      "<ID> Okay.\n",
      "<UI> Yeah.\n",
      "<PM> Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> I think this is going back to the the graph at the beginning that I made, where, you know, the buttons that people use all the time, you want buttons for them and everything else menu-driven.\n",
      "<ID> Mm right.\n",
      "<ME> Yeah.\n",
      "<UI> And it yeah L LCD.\n",
      "<ID> So uh in in the buttons we have for the channels also we have options.\n",
      "<ID> Do you do we enumerate everything from zero to nine?\n",
      "<ID> Or do we have just uh channel plus, channel minus, just to just to scroll?\n",
      "<ME> No, no, I mean mm we we definitely need the the numbers, because it's uh otherwise people don't want to flip through all the channels.\n",
      "<ID> The numbers.\n",
      "<PM> Yeah.\n",
      "<PM> Yeah.\n",
      "<UI> Do we need them on as buttons or do we need them as LCD?\n",
      "<ID> Right.\n",
      "<ME> Um Yeah, I would say buttons, because it's yeah.\n",
      "<ID> Or on the LCD we can, you know Okay.\n",
      "<PM> G yeah, I would think buttons, yeah.\n",
      "<UI> Buttons.\n",
      "<PM> It's it's the I think the thing is, so if someone just wants to turn on their TV and put on a channel, then it should be easier to use than any other remote, and then if someone wants to, you know, change the contrast on their TV and they should be able to do that and it should be accessible, but, you know, I mean most of the time I mean there's a limit to how much the biggest techno geek can spend fiddling with the TV, I think is the the the issue there.\n",
      "<ME> I Yeah.\n",
      "<ID> So mm Alright.\n",
      "<UI> Mm.\n",
      "<UI> Yeah.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<ID> Right.\n",
      "<ID> Okay, so buttons definitely in but oh shall we uh try to draw a prec um Uh okay.\n",
      "<UI> I think that's what you guys are gonna do next, so if we put down the key um things that we want.\n",
      "<ID> Okay, okay, so the components.\n",
      "<ME> Yeah.\n",
      "<ID> Right, so uh what about the the scrolling uh?\n",
      "<ME> Yeah but n I I'm not completely um completely clear uh I yeah, about the spinning wheel.\n",
      "<ME> So I think it it doesn't make sense to have both like a scrolling and spinning thing, it's uh you can al include everything in the spinning if you yeah, yeah, in that case.\n",
      "<PM> E either or G yeah.\n",
      "<UI> Just spinning and not scrolling, I would say.\n",
      "<PM> I would say the s the s the spinning goes at a high speed to th to the scrolling wheel, so you have to decide whether you you know, you want to be going so fast or not.\n",
      "<UI> Yeah.\n",
      "<PM> But I mean the the thing with this whole if y you're planning on making it out of rubber, on the basis that it's spongy, then I'm not sure how well a scrolling wheel would work.\n",
      "<UI> Hmm.\n",
      "<ID> Mm um I'm not sure it'll be a good idea to construct the whole thing out of rubber.\n",
      "<UI> But if you've got a if if you've got a flipped thing, effectively it's something that's curved on one side and flat on the other side, but you folded it in half.\n",
      "<ME> Ah, but I mean you can Yeah, I um I think so too, I mean the case would be yeah the case would be rubber and the the buttons, rubber buttons, but then Yeah.\n",
      "<PM> Yeah, but y your spinning wheel tends to go to one side.\n",
      "<UI> Th that would be on one side, uh-huh.\n",
      "<ID> Uh i it Or or at the corners, edges, just the edges covered by rubber or something like that.\n",
      "<UI> No, I think it's just the casing rubber on the outside.\n",
      "<PM> You want an outside of rubber and then open it up and Or maybe like interchangeable cases.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> Everything else in plastic or even titanium if we want to use it.\n",
      "<ID> Mm-hmm.\n",
      "<PM> 'Cause I know like we're going back to iPods again n the whole spinning wheel, but I have like a you know, obviously my iPod's not made of rubber, but then I have a little rubber case that goes over the top of it and I can change the colour, theoretically, to match my outfit.\n",
      "<ID> Right, right.\n",
      "<UI> Mm.\n",
      "-----------------------------------------\n",
      "<ID> Right, okay, so so that gives us a more trendy look as well.\n",
      "<ID> Um Right.\n",
      "<PM> Yeah, I think the spinning wheel is definitely very now.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Yeah, and uh we're going more for the trends than for the usability anyway, right?\n",
      "<ME> Mm-hmm.\n",
      "<UI> That's right, that's what they're after.\n",
      "<PM> Yeah.\n",
      "<ID> So I'll rub that out.\n",
      "<ID> And uh colours can be provided with the case rather than Um but we still need to te think about the colour of our remote as such, you know, just keep it black, or Mm.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Yeah I think we um it was a a requirement that we use our um th the colours of our company, so would it be like yellow, grey and black or something, or Yeah, does Yeah.\n",
      "<UI> I guess.\n",
      "<PM> That doesn't fit in with the whole vegetable theme though.\n",
      "<UI> Bananas.\n",
      "<ME> Banana's yellow, yeah, definitely.\n",
      "<PM> Yeah, but I mean do you think we could incorporate the colours of the company into the buttons and then make the colour of the main remote the colour like vegetable colours, do you know?\n",
      "<PM> So you could have like I mean I suppose vegetable colours would be orange and green and some reds and um maybe purple and that and then you'd pick the buttons in company colours to to match with it.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Green.\n",
      "<UI> Yeah.\n",
      "<ID> Okay.\n",
      "<ID> Um okay, if you g go over to uh the integrated circuits.\n",
      "<ID> Uh since we're having LCDs there there's no way that we're will be able to um what we do need to consider, however, is that the price is going up for the ever every such thing that we are considering, but since LCDs seems to be uh a definite yes, so it seems to be one area where we would want to spend.\n",
      "<UI> We need the advanced yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> So I'll rub off the other two.\n",
      "<UI> Mm-hmm.\n",
      "<PM> So are we discounting solar energy because rubber's gonna be used in there somewhere or If solar panels with the rubber.\n",
      "<UI> That was the We can't have solar panels with rubber, so.\n",
      "<ID> Oh is oh the constraint was uh yeah.\n",
      "<ID> Yeah.\n",
      "<ID> So I think uh we'll have uh uh using the simple battery will be a safer option as compared to the kinetic energy one, I mean, a although it does seem uh interesting.\n",
      "<PM> Yeah, okay, so we lose that I think.\n",
      "<UI> Shall we go for if we're going for rubber, we think uh on as our case, and then Yeah.\n",
      "<ME> Mm-hmm.\n",
      "<ME> And the buttons as well, I think.\n",
      "<ME> Yeah.\n",
      "<UI> We've got five more minutes.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> But it does not hold any advantages as such for a yeah.\n",
      "<UI> Yeah, mm-hmm.\n",
      "<PM> It's just a gimmick.\n",
      "<ID> Okay.\n",
      "<ID> Uh okay, so r we understand this better now that uh the the speaker is for the feedback, right?\n",
      "<UI> Mm-hmm.\n",
      "<ID> It it says uh the things that you type in or something like that, so Ye yeah, we we don't have too much information about it, um Yeah, okay, so so th this is in as well then, the sample speaker.\n",
      "<UI> Yeah.\n",
      "<UI> I think if we can if we can include them at not too much extra cost, then I'd put them in, but if it's Yeah.\n",
      "<ME> Yeah, but it it I think it should be quite cheap because it's from our own company, yeah.\n",
      "<UI> It's from the company, so Yeah.\n",
      "<UI> Okay.\n",
      "<ID> Right.\n",
      "<UI> And the case is curved on one side, but then flat flat, so it's flipped into each other.\n",
      "<ID> Flat on the top.\n",
      "<ME> Mm-hmm.\n",
      "<ID> Yeah.\n",
      "<ID> Okay.\n",
      "<UI> Can I pull the thing out the back of your computer?\n",
      "<PM> Yeah, sure j Sorry, do you want me to What does um ICS mean?\n",
      "<UI> Just so we can Nothing, it's right, I'm just There we go.\n",
      "<ID> ICs?\n",
      "<ID> Uh integrated circuits.\n",
      "<PM> Okay, cool.\n",
      "<PM> So it's advanced integrated circuits?\n",
      "<ID> Yeah.\n",
      "<UI> Uh oh now I've gone too far.\n",
      "<ID> Uh um we we're definitely going in for voice recognition as well as LCDs, mm.\n",
      "<ME> Yeah.\n",
      "<UI> Yeah.\n",
      "<UI> We're on our way.\n",
      "<UI> Okay.\n",
      "<UI> So we've basically worked out that we're going with a simple battery, the advanced chip and a curved on one side case which is folded in on itself, um made out of rubber and the buttons are also rubber.\n",
      "<ID> Right.\n",
      "<ID> Yep.\n",
      "<UI> We're having push-buttons on the outside and then on the inside an LCD with spinning wheel, and we're incorporating voice recognition.\n",
      "<UI> That's our overall concept, and it's gonna look sort of vegetable, and be in bright vegetable colours.\n",
      "<ME> Um Uh-huh.\n",
      "<ME> So w w would with have the spinning wheel inside with the LCD, or would it be on the outer Okay.\n",
      "<UI> I think it's on the Mm-mm.\n",
      "<PM> Imagine it would be inside.\n",
      "<PM> So um actually that could like really cut down your thing, so you've got your outside, which is like minimalist, and then you open it up and you've got a screen and a spinning wheel, which you can incorporate buttons into.\n",
      "<ID> Mm.\n",
      "<ME> Mm-hmm.\n",
      "<ME> Yeah, okay.\n",
      "<ME> Mm-hmm.\n",
      "<PM> Um so you've still not got like a lot of stuff in the You've maybe got, you know like if you're modelling on iPod you've got five buttons and a wheel, and four of the buttons are in the wheel, and the other one's the little bit inside the wheel, yeah.\n",
      "<UI> Yeah.\n",
      "<UI> On the Mm-hmm.\n",
      "<UI> In the centre, yeah, sure.\n",
      "<ME> Mm yeah.\n",
      "<UI> Okay, so now we've got thirty minutes before our next meeting.\n",
      "<UI> In the meantime, the Industrial Designer over here is gonna work on the look and feel design, which I'll presume he'll work out what that means.\n",
      "<ID> Mm-hmm.\n",
      "<UI> Um the User Interface Designer will work on the user interface design and the Marketing Expert is going to work on product evaluation.\n",
      "<UI> And as well as that, the two designers are going to work together on our prototype following those instructions that we've just come up with using modelling clay and you will get extra instructions from your personal coach.\n",
      "<ME> Mm-hmm.\n",
      "<ID> Cool.\n",
      "<UI> Is that all okay?\n",
      "<UI> And anyone who hasn't put their their presentation in the project documents folder, it would be good just so in case we have to refer to it.\n",
      "<ME> Yeah.\n",
      "<ID> Yeah, okay.\n",
      "<ME> Mm-hmm.\n",
      "<PM> Cool, I'm gonna go and sit on my own.\n",
      "<UI> Y ah nobody wants to talk to you.\n",
      "<PM> I know, I'm hated.\n",
      "<UI> Unplug yourself.\n",
      "-----------------------------------------\n",
      "<ME> Hmm.\n",
      "<PM> I've got a bit tangled up in all this.\n"
     ]
    }
   ],
   "source": [
    "# Tests for chunking algorithm\n",
    "import os\n",
    "\n",
    "sample_file_path = 'input/texts/' + samples[0]\n",
    "sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "sample = sample_file.read()\n",
    "sample_file.close()\n",
    "\n",
    "chunks = chunkize(sample)\n",
    "for chunk in chunks:\n",
    "    print('-----------------------------------------')\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation...\n",
      "Prompting on sample N1/30\n",
      "-- Completion: 0.0%\n",
      "---- Computing chunk 1 of 6 total, size: 1623 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while generating sample\n",
      "Done! Took 0:01:26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_77989/3447844630.py\", line 44, in <module>\n",
      "    output = inference_sample(sample)\n",
      "  File \"/tmp/ipykernel_77989/1605117687.py\", line 24, in inference_sample\n",
      "    output = generate_output(prompt, counter, chunks)\n",
      "  File \"/tmp/ipykernel_77989/3332469274.py\", line 20, in generate_output\n",
      "    output_ids = model.generate(**input_ids, do_sample=DO_SAMPLE, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, top_k=TOP_K)\n",
      "  File \"/workspace/.miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/workspace/.miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1642, in generate\n",
      "    return self.sample(\n",
      "  File \"/workspace/.miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2760, in sample\n",
      "    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "initial_time = time.time()\n",
    "skipped_samples = 0\n",
    "\n",
    "mkdir('intermediate')\n",
    "mkdir('intermediate/' + INTERMEDIATE_FOLDER)\n",
    "\n",
    "print('Starting computation...')\n",
    "\n",
    "# For each sample in dataset\n",
    "check = True\n",
    "for sample_n in range(n_samples):\n",
    "    if not(check):\n",
    "        break\n",
    "\n",
    "    # Estimate completion and time.\n",
    "    cur_samples = sample_n - skipped_samples\n",
    "    tot_samples = n_samples - skipped_samples\n",
    "    progress = cur_samples / tot_samples\n",
    "    pct = round(progress * 100, 1)\n",
    "    print('Prompting on sample N' + str(sample_n + 1) + '/' + str(n_samples))\n",
    "    print('-- Completion: ' + str(pct) + '%')\n",
    "    if cur_samples > 0:\n",
    "        approx_total = (time.time() - initial_time) / cur_samples * tot_samples\n",
    "        approx_remaining = approx_total * (1 - progress)\n",
    "        print('-- Estimated Remaining Time: ' + str(datetime.timedelta(seconds=int(approx_remaining))) + ' (total ' + str(datetime.timedelta(seconds=int(approx_total))) + ')')\n",
    "    \n",
    "    # Read sample and generate prompt\n",
    "    sample_file_path = 'input/texts/' + samples[sample_n]\n",
    "    sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "    sample = sample_file.read()\n",
    "    sample_file.close()\n",
    "    \n",
    "    # Find target file\n",
    "    target_file_path = get_intermediate_file_path(samples[sample_n])\n",
    "    if os.path.isfile(target_file_path):\n",
    "        print('-- Found intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        skipped_samples += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        check = False\n",
    "\n",
    "        # Inference\n",
    "        output = inference_sample(sample)\n",
    "\n",
    "        # Save answer in file\n",
    "        target_file = open(target_file_path, 'w', encoding='utf-8')\n",
    "        target_file.write(output)\n",
    "        target_file.close()\n",
    "        \n",
    "        check = True\n",
    "    except:\n",
    "        print('Error while generating sample')\n",
    "        traceback.print_exc()\n",
    "\n",
    "delta = time.time() - initial_time\n",
    "print('Done! Took', datetime.timedelta(seconds=int(delta)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Calculs de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ----------------------------- ---------- 1.1/1.5 MB 34.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 31.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in d:\\program files\\python311\\lib\\site-packages (from rouge_score) (1.25.2)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\program files\\python311\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Collecting click (from nltk->rouge_score)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/1a/70/e63223f8116931d365993d4a6b7ef653a4d920b41d03de7c59499962821f/click-8.1.6-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->rouge_score)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\program files\\python311\\lib\\site-packages (from nltk->rouge_score) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in d:\\program files\\python311\\lib\\site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml): started\n",
      "  Building wheel for rouge_score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24970 sha256=a6591765bd79bbd23371ae686d9880a68906fe5435e578e13122d199ed4c9e8d\n",
      "  Stored in directory: c:\\users\\jules\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge, joblib, click, absl-py, nltk, rouge_score\n",
      "Successfully installed absl-py-1.4.0 click-8.1.6 joblib-1.3.2 nltk-3.8.1 rouge-1.0.1 rouge_score-0.1.2\n",
      "Requirement already satisfied: evaluate in d:\\program files\\python311\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (1.25.2)\n",
      "Requirement already satisfied: dill in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in d:\\program files\\python311\\lib\\site-packages (from evaluate) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in d:\\program files\\python311\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: aiohttp in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.1/61.1 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.0.0 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.0.1+cu117)\n",
      "Requirement already satisfied: pandas>=1.0.1 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.0.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (4.32.0.dev0)\n",
      "Requirement already satisfied: numpy in d:\\program files\\python311\\lib\\site-packages (from bert-score) (1.25.2)\n",
      "Requirement already satisfied: requests in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (4.66.1)\n",
      "Collecting matplotlib (from bert-score)\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/4d/9c/65830d4a56c47f5283eaa244dc1228c5da9c844a9f999ebcc2e69bf6cc65/matplotlib-3.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.0)\n",
      "Requirement already satisfied: jinja2 in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.3.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bert-score)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/16/09/989b982322439faa4bafffcd669e6f942b38fee897c2664c987bcd091dec/contourpy-1.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bert-score)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bert-score)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/52/65/aaa3d2b7a292d93cc2cf1c534d03ba3f744e480f15b3b2ab6ad68189f7ee/fonttools-4.42.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading fonttools-4.42.0-cp311-cp311-win_amd64.whl.metadata (153 kB)\n",
      "     ---------------------------------------- 0.0/153.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 153.7/153.7 kB ? eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->bert-score)\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\program files\\python311\\lib\\site-packages (from matplotlib->bert-score) (9.3.0)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib->bert-score)\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 0.0/98.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 98.3/98.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: fsspec in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=3.0.0->bert-score) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\program files\\python311\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\program files\\python311\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.2.1)\n",
      "Downloading matplotlib-3.7.2-cp311-cp311-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.3/7.5 MB 27.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.7/7.5 MB 39.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.5 MB 59.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 47.7 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "   ---------------------------------------- 0.0/470.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 470.9/470.9 kB ? eta 0:00:00\n",
      "Downloading fonttools-4.42.0-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 67.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, bert-score\n",
      "Successfully installed bert-score-0.3.13 contourpy-1.1.0 cycler-0.11.0 fonttools-4.42.0 kiwisolver-1.4.4 matplotlib-3.7.2 pyparsing-3.0.9\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 118.9/118.9 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: regex in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (2023.8.8)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (1.25.2)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/31/58/e3b3dd6bb2ab7404f1f4992e2d0e6926ed40cef8ce1b3bbefd95877499e1/lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\jules\\appdata\\roaming\\python\\python311\\site-packages (from portalocker->sacrebleu) (306)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.9/3.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 26.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tabulate, portalocker, lxml, sacrebleu\n",
      "Successfully installed lxml-4.9.3 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0\n",
      "Requirement already satisfied: nltk in d:\\program files\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\program files\\python311\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in d:\\program files\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\program files\\python311\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in d:\\program files\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score rouge\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate, os, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scores computation...\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e758c4c624f339a0cc653d226bb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e818d1bd1e4c23867641a85929f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 29191.96 seconds, 0.00 sentences/sec\n",
      "Done!\n",
      "Average rouge1: 0.2661548987273394\n",
      "Average rouge2: 0.07980427751892992\n",
      "Average rougel: 0.15763943598433525\n",
      "Average bertscore: 0.20706295669078828\n"
     ]
    }
   ],
   "source": [
    "# Methods and variables\n",
    "print('Starting scores computation...')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "#STORAGE_FILE_NAME = 'scores'\n",
    "\n",
    "# Find output file for CSV scores\n",
    "#mkdir('output')\n",
    "#storage_file = open('output/' + STORAGE_FILE_NAME + '.csv', 'w', encoding='utf-8')\n",
    "#storage_file.write('path;rouge2;rougel;bertscore\\n')\n",
    "\n",
    "target_file_paths = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Find generated summary\n",
    "    target_file_path = get_intermediate_file_path(samples[sample_n])\n",
    "    if not os.path.isfile(target_file_path):\n",
    "        print('-- Found no intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        continue\n",
    "\n",
    "    # Read sample and generate prompt -> Keep summary\n",
    "    summary_file_path = 'input/summaries/' + samples[sample_n]\n",
    "    summary_file = open(summary_file_path, 'r', encoding='utf-8')\n",
    "    references.append(summary_file.read())\n",
    "    summary_file.close()\n",
    "\n",
    "    # Access generated summary\n",
    "    target_file = open(target_file_path, 'r', encoding='utf-8')\n",
    "    prediction = target_file.read()\n",
    "    target_file.close()\n",
    "\n",
    "    # Add prediction\n",
    "    target_file_paths.append(target_file_path)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "result_rouge = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "result_bertscore = bertscore.compute(predictions=predictions, references=references, lang='fr', rescale_with_baseline=True, verbose=True)\n",
    "\n",
    "# Calculate average\n",
    "list_rouge1, list_rouge2, list_rougel, list_bertscore = result_rouge['rouge1'], result_rouge['rouge2'], result_rouge['rougeL'], result_bertscore['f1']\n",
    "\n",
    "# Write to csv\n",
    "# Forget about BLEU...\n",
    "# Format: PATH | ROUGE1 | ROUGE2 | ROUGEL | BERTScore\n",
    "#for i in range(len(target_file_paths)):\n",
    "#    ligne = target_file_paths[i]\n",
    "#\n",
    "#    # list_rouge1[i]\n",
    "#    ligne += ';' + str(list_rouge2[i]) + \";\" + str(list_rougel[i])\n",
    "#    #ligne += \";\" + str(result_bleu['bleu'])\n",
    "#    ligne += \";\" + str(list_bertscore[i])\n",
    "#    \n",
    "#    storage_file.write(ligne + '\\n')\n",
    "\n",
    "#storage_file.close()\n",
    "print('Done!')\n",
    "\n",
    "# Calculate means\n",
    "print('Average rouge1:', statistics.mean(list_rouge1))\n",
    "print('Average rouge2:', statistics.mean(list_rouge2))\n",
    "print('Average rougel:', statistics.mean(list_rougel))\n",
    "print('Average bertscore:', statistics.mean(list_bertscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 2.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
