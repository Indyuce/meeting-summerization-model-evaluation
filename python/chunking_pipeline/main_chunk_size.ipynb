{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dependences, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /home/linagora/anaconda3/lib/python3.10/site-packages (2.97.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (2.11.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-python-client) (2.21.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.59.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /home/linagora/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.23.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/linagora/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: bitsandbytes in /home/linagora/.local/lib/python3.10/site-packages (0.39.1)\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-jfht7cax\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-jfht7cax\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit f92cc7034a49959b247a46a210b912e56a6f977d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers==4.32.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.32.0.dev0) (1.26.14)\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-tdflwk46\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-tdflwk46\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install bitsandbytes\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install tiktoken\n",
    "!pip install torch\n",
    "!pip install scipy\n",
    "!pip install einops # Falcon dependency\n",
    "!pip install huggingface_hub[\"cli\"] # To empty model cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Wed Aug 23 13:03:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   41C    P0    41W / 250W |  12824MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   43C    P0    39W / 250W |  13198MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:      181108932    13059888    19918188     1297876   148130856   165111668\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /workspace/.miniconda3/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2023.6.0)\n",
      "Requirement already satisfied: requests in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.51.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (23.1)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.38)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2022.12.7)\n",
      "Requirement already satisfied: wcwidth in /workspace/.miniconda3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.6)\n",
      "Installing collected packages: pfzy, InquirerPy\n",
      "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/mt0-xxl (55.8G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m b5461b49: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-40b-instruct (50.3K, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m ca78eac0: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel ichitaka/falcon-40b-instruct-8bit (41.9G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 03dd12af: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (27.6G, used 2 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: (detached) # modified 6 days ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m d008fe87: main # modified 2 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-7b-instruct (14.4G, used 5 hours ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m eb410fb6: main # modified 5 hours ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel mosaicml/mpt-7b-instruct (13.3G, used 19 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 925e0d80: main # modified 19 minutes ago\u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[69D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/mt0-xxl (55.8G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m b5461b49: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-40b-instruct (50.3K, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m ca78eac0: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel ichitaka/falcon-40b-instruct-8bit (41.9G, used 6 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 03dd12af: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (27.6G, used 2 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: (detached) # modified 6 days ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m d008fe87: main # modified 2 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel tiiuae/falcon-7b-instruct (14.4G, used 5 hours ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m eb410fb6: main # modified 5 hours ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel mosaicml/mpt-7b-instruct (13.3G, used 19 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 925e0d80: main # modified 19 minutes ago\u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Empty model cache\n",
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, traceback, datetime, torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work.\n",
    "#model.generation_config.do_sample = False\n",
    "#model.generation_config.max_new_tokens = 2048\n",
    "#model.generation_config.temperature = .3\n",
    "#model.generation_config.top_k = 100\n",
    "\n",
    "DO_SAMPLE = True\n",
    "MAX_NEW_TOKENS = 2048\n",
    "TEMPERATURE = .3\n",
    "TOP_K = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d28531b6088488599efeaa8bbfc1144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Salesforce/xgen-7b-8k-inst'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "P1: You're finally here! What took so long?\n",
    "P2: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\n",
    "P1: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\n",
    "P2: I don't think it can be avoided, to be honest.\n",
    "P1: perhaps it would be better if you started taking public transport system to work.\n",
    "P2: I think it's something that I'll have to consider. The public transport system is pretty good.\n",
    "P1: It would be better for the environment, too.\n",
    "P2: I know. I feel bad about how much my car is adding to the pollution problem in this city.\n",
    "P1: Taking the subway would be a lot less stressful than driving as well.\n",
    "P2: The only problem is that I'm going to really miss having the freedom that you have with a car.\n",
    "P1: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\n",
    "P2: That's true. I could certainly use the exercise!\n",
    "P1: So, are you going to quit driving to work then?\n",
    "P2: Yes, it's not good for me or for the environment.\n",
    "\n",
    "### Assistant: Two individuals discuss the delay caused by traffic congestion near Carrefour intersection. One suggests finding an alternate route or using public transport. They discuss the benefits of public transport for the environment, stress reduction, and consider biking as an option in good weather. Eventually, one person decides to stop driving to work due to health and environmental concerns.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "AC: Once search-and-rescue efforts are under control in China, building experts are going to begin looking at the extent of structural damage. Stanford University's Ann Kiremidjian is a structural engineer. She helped assess damage years after China's 1976 huge earthquake that killed about 250,000 people. Ann Kiremidjian, when you look at the pictures and video of the collapsed buildings around Chengdu, I bet you see things that I don't notice.\n",
    "Pr. AK: Alex, what I have seen from the video clips is first of all a lot of concrete buildings, what we call concrete frames, and I would classify them as a non-ductile concrete frame. What that means is that there is very little steel reinforcement in the concrete and as a result, the concrete cannot resist displacement in the horizontal direction.\n",
    "AC: It needs to have steel bars, I think that is called rebar. Yeah.\n",
    "Pr. AK: That is correct. Not enough rebar both in the vertical direction and in the horizontal direction. And in addition, you have to provide rebar going from the column to the beam at the joint to provide continuity and a way to transfer the forces from one member to the other.\n",
    "AC: You inspected buildings after this last, huge, terrible earthquake more than 30 years ago. Did you make recommendations to the Chinese government then?\n",
    "Pr. AK: At the time, they didn't have earthquake-resistant codes in place. And since then, we've had numerous discussions, and the Chinese have had very strong programs to develop seismic codes, to develop seismic hazard maps. The seismic hazard maps similar to the ones that we have in the United States, are developed with the purpose to identify regions of frequent large earthquakes that can cause damage to buildings, the very first step in any earthquake-resistant design.\n",
    "AC: And what about this region around Chengdu, the Sichuan province, is this prone to earthquakes?\n",
    "Pr. AK: Yes, all of China is in a highly seismic area. You would notice that there is a fault that runs along the plateau between the Himalayas and where Chengdu is. If you trace all the aftershocks, you can probably trace the fault line that has ruptured. To cause a magnitude 7.8 earthquake, you will need to rupture more than 100 kilometers of a fault, and it looks it is almost 200 kilometers of locations of aftershock which is likely to be the length of the rupture of the fault.\n",
    "AC: Is there some way to measure the size of the earthquake and then overlay that on a map of the region and figure out, we have to look at every single building within a particular radius from the epicenter? I mean do you have to do that?\n",
    "Pr. AK: Oh, we do that all the time. In fact, what typically you would do is you would focus within the first 15 or 20 kilometers from the rupture zone. It's not just the epicenter, but it is the rupture zone, and the rupture can run about a couple of hundred kilometers, as it is in the case of China. So you are talking a lot of buildings. A single inspector or 10 or 20 inspectors cannot perform that task in a reasonable amount of time. What you have to do is recruit all the professional structural engineers to help with the inspection process.\n",
    "AC: Ann, you're speaking to us from your home in Los Altos Hills, that's south of San Francisco. And it's two miles from the most notorious earthquake fault in North America, the San Andreas Fault.\n",
    "Pr. AK: Correct.\n",
    "AC: Can you explain to me why a structural engineer would build a house there?\n",
    "Pr. AK: Yes, indeed. You have to take certain precautions. We have taken into consideration the fact that we are close to the fault. Can we do more? Yes, we can. There's always a balancing act between the economics, how much can you afford, and what you are willing to live with. It's a beautiful area, the weather is lovely, it's close to my work, that's where I live.\n",
    "AC: Ann Kirmidjian teaches structural engineering at Stanford University. Professor, thank you.\n",
    "Pr. AK: You're welcome.\n",
    "AC: NPR's DAY TO DAY continues.\n",
    "\n",
    "### Assistant: After the recent earthquake in China, structural engineer Ann Kiremidjian from Stanford University discusses the extent of structural damage. She identifies that many collapsed buildings had non-ductile concrete frames lacking sufficient steel reinforcement, both vertically and horizontally. She emphasizes the importance of earthquake-resistant design, mentioning how China has developed seismic codes and hazard maps over the years. All of China, including the Sichuan province where the earthquake occurred, is in a highly seismic area due to fault lines. Kiremidjian explains that inspecting buildings after earthquakes involves focusing on the rupture zone within the first 15-20 kilometers, which requires the involvement of numerous professional structural engineers. The interview also touches on building near earthquake faults, highlighting the trade-off between economic considerations and safety precautions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "INTERMEDIATE_FOLDER = 'xgen_7b_2sl_1kT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_from_output_sequence(output, n_shot = 2):\n",
    "    \n",
    "    # Un-prompt output\n",
    "    delimiter = '### Assistant:'\n",
    "    output = delimiter.join(output.split(delimiter)[1 + n_shot:])\n",
    "    \n",
    "    # Remove white spaces in front of summary\n",
    "    while len(output) > 0 and output[0] == ' ':\n",
    "        output = output[1:]\n",
    "    \n",
    "    # Remove <|endoftext|>\n",
    "    eos_token = '\\n<|endoftext|>'\n",
    "    output = output[:-len(eos_token)]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def generate_output(prompt, counter, chunks):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    print('---- Computing chunk', counter, 'of', len(chunks), 'total, size:', len(input_ids['input_ids'][0]), 'tokens')\n",
    "    output_ids = model.generate(**input_ids, do_sample=DO_SAMPLE, max_new_tokens=MAX_NEW_TOKENS, temperature=TEMPERATURE, eos_token_id=50256, top_k=TOP_K)\n",
    "    return tokenizer.decode(output_ids[0]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 samples: ['sample_10_9852.txt', 'sample_11_10498.txt', 'sample_12_11166.txt', 'sample_13_4562.txt', 'sample_14_6858.txt', 'sample_15_9989.txt', 'sample_16_6057.txt', 'sample_17_4135.txt', 'sample_18_9825.txt', 'sample_19_9648.txt', 'sample_1_4693.txt', 'sample_20_13365.txt', 'sample_21_7283.txt', 'sample_22_6522.txt', 'sample_23_9169.txt', 'sample_24_10638.txt', 'sample_25_2751.txt', 'sample_26_7860.txt', 'sample_27_9004.txt', 'sample_28_5705.txt', 'sample_29_3855.txt', 'sample_2_11567.txt', 'sample_30_8361.txt', 'sample_3_12019.txt', 'sample_4_13389.txt', 'sample_5_1343.txt', 'sample_6_10232.txt', 'sample_7_11826.txt', 'sample_8_7292.txt', 'sample_9_4578.txt']\n"
     ]
    }
   ],
   "source": [
    "def mkdir(folder_path):\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def get_intermediate_file_path(sample):\n",
    "    global INTERMEDIATE_FOLDER\n",
    "\n",
    "    return \"intermediate/\" + INTERMEDIATE_FOLDER + '/' + sample\n",
    "\n",
    "# Load samples from dataset\n",
    "samples = os.listdir('input/texts')\n",
    "samples = [sample for sample in samples if sample.endswith('.txt')]\n",
    "samples.sort()\n",
    "n_samples = len(samples)\n",
    "print('Found', n_samples, 'samples:', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chunking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHARACTER_CHUNK_SIZE = 1000\n",
    "\n",
    "def token_len(text):\n",
    "    return len(tokenizer(text, return_tensors=\"pt\")['input_ids'][0])\n",
    "\n",
    "def append_to_chunk(current_chunk, utterance):\n",
    "    if len(current_chunk) > 0:\n",
    "        current_chunk += '\\n'\n",
    "    current_chunk += utterance\n",
    "    return current_chunk\n",
    "\n",
    "def chunkize(text):\n",
    "    \"\"\"\n",
    "    Greedy implementation of a dialogue transcript chunking algorithm. This method returns a list of transcript chunks.\n",
    "    - It priorities stability over performance. There is a set maximum chunk size for LLM inference stability. Really long utterances bypass this limit.\n",
    "    - It guarantees the cuts are made at utterance ends (\\n).\n",
    "    - It counts everything in MODEL TOKENS and not characters for more exact experiments.\n",
    "    \"\"\"\n",
    "    \n",
    "    chunks = [] # Final list of transcript chunks. This makes up the loop invariant\n",
    "    utterances = text.split('\\n') # Transcript is split into sentences\n",
    "    utterances.reverse() # Reverse everything!!\n",
    "    current_chunk = ''\n",
    "\n",
    "    # While there is still an utterance to process\n",
    "    while len(utterances) > 0:\n",
    "        utterance = utterances.pop()\n",
    "\n",
    "        # Add to current chunk and proceed to next\n",
    "        new_current_chunk = append_to_chunk(current_chunk, utterance)\n",
    "        if token_len(new_current_chunk) <= MAX_CHARACTER_CHUNK_SIZE:\n",
    "            current_chunk = new_current_chunk\n",
    "        \n",
    "        # Utterance is larger than maximum chunk size\n",
    "        elif len(current_chunk) == 0:\n",
    "            chunks.append(current_chunk)\n",
    "            chunks.append(utterance)\n",
    "            current_chunk = ''\n",
    "\n",
    "        # Current chunk is big enough, append to list and create new one\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = utterance\n",
    "\n",
    "    if len(current_chunk) > 0:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sample(sample):\n",
    "    \n",
    "    # Current summary is the concatenation of all the chunk sub-summaries \n",
    "    current_summary = ''\n",
    "    #previous_summary = ''\n",
    "    chunks = chunkize(sample)\n",
    "\n",
    "    # Split into chunks\n",
    "    counter = 0\n",
    "    for chunk in chunks:\n",
    "        counter += 1\n",
    "\n",
    "        # Create prompt for this chunk\n",
    "        #if len(previous_summary) == 0:\n",
    "        #    prompt = PROMPT_TEMPLATE_1.format(text=chunk)\n",
    "        #    n_shot = 2\n",
    "        #else:\n",
    "        #    prompt = PROMPT_TEMPLATE_2.format(summary=previous_summary, text=chunk)\n",
    "        #    n_shot = 0\n",
    "        prompt = PROMPT_TEMPLATE.format(text=chunk)\n",
    "        #n_shot = 0\n",
    "            \n",
    "        # Sample one sub-input\n",
    "        output = generate_output(prompt, counter, chunks)\n",
    "        subsummary = result_from_output_sequence(output)\n",
    "        print(subsummary)\n",
    "\n",
    "        # Add to summary\n",
    "        if len(current_summary) > 0:\n",
    "            current_summary += '\\n\\n'\n",
    "        current_summary += subsummary\n",
    "        #previous_summary = subsummary\n",
    "    \n",
    "    return current_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "<UI> All hooked up.\n",
      "<UI> Okay, so now we are here at the functional design meeting.\n",
      "<UI> Um hopefully this meeting I'll be doing a little bit less talking than I did last time 'cause this is when you get to show us what you've been doing individually.\n",
      "<UI> The agenda for the meeting, I put it in the sh shared documents folder.\n",
      "<UI> I don't know if that meant that you could see it or not.\n",
      "<UI> Did anyone?\n",
      "<ME> No.\n",
      "<ID> Mm.\n",
      "<UI> No.\n",
      "<UI> Oh well.\n",
      "<UI> Um I'll try and do that for the next meeting as well so if you check in there, there's a shared project documents folder.\n",
      "<UI> Um and it should be in there.\n",
      "<ME> Mm.\n",
      "<ME> Um um wi on on a what?\n",
      "<ME> Oh project project documents, yeah, yeah, yeah, okay.\n",
      "<UI> Project documents, yeah.\n",
      "<UI> So I'll put it in there.\n",
      "<ME> Oh okay, yeah.\n",
      "<UI> Is it best if I send you an email maybe, to let you know it's there?\n",
      "<ME> Yes, I think so.\n",
      "<UI> Yep.\n",
      "<UI> I'll do that next time.\n",
      "<UI> Um I'll act as secretary for this meeting and just take minutes as we go through, and then I'll send them to you after the meeting.\n",
      "<UI> The main the main focus of this meeting is your presentations that you've been preparing during the time, so we'll go through each of you one by one.\n",
      "<UI> Um then we need to briefly discuss the new project requirements that were sent to us.\n",
      "<UI> I just sent at the last minute, I'm sorry about that, but we can see how that affects what you were you were doing.\n",
      "<ME> Yeah, the last minute, yeah, yeah.\n",
      "<ME> Yeah.\n",
      "<UI> Um and then we need to, by the end of the meeting come to some kind of decision on who our target group's going to be and what the functions of the remote control that's the the main goal is to come up with those two things, target group and functions of the remote control.\n",
      "<UI> And we've got forty minutes to do that in.\n",
      "<UI> So I would say yeah?\n",
      "<ID> You said uh targ target groups, what does that mean?\n",
      "<UI> As uh who it is that we're going to be trying to sell this thing to, yeah.\n",
      "<ME> Um Okay.\n",
      "<ID> Uh okay, 'kay.\n",
      "<ID> So are Okay.\n",
      "<UI> So we need to yeah, we need to have a fairly defined group that that we want to focus on and then look at the functions um of the dem remote control itself.\n",
      "<UI> So with that I think it's best if I hand over to you.\n",
      "<UI> Does anyone have a preference for going first?\n",
      "<ID> Alright.\n",
      "<ID> I can go first, yeah.\n",
      "<UI> You wanna go first?\n",
      "<UI> Okay, so we need to unplug my laptop and plug in yours.\n",
      "<ME> Hmm.\n",
      "<UI> I assume we just pull it out?\n",
      "<ME> Mm.\n",
      "<ID> Right.\n",
      "<ID> Um so f from the Right sure.\n",
      "<UI> Just before you start, to make it easier, would you three mind emailing me your presentations?\n",
      "<UI> Once we you don't have to do it now but when once you go back, just so that I don't have to scribble everything down.\n",
      "<ME> Okay, yeah, afterwards, yeah, okay.\n",
      "<ID> Uh okay.\n",
      "<ID> So n uh with uh with regard to the uh working design of this uh uh remote control uh I've identified um a few basic uh components of the remote and uh se uh from the design, functional design perspective um w I c we can now uh know wha what exactly the components are and how how they work together with each other.\n",
      "<ID> So this is the method that uh I'll mostly be following in my um in my uh role.\n",
      "<ID> Um the identification of the components, uh and uh since since I'm dealing only with the technical aspects, I would need feedback from the marketing person uh and uh from the user interface person.\n",
      "<UI> Hmm.\n",
      "-----------------------------------------\n",
      "<ID> Uh we'll then integrate this into the product design at a technical level and uh basically update and come up with a new design, so it's a cyclical process.\n",
      "<ID> Okay, so these were the basic findings from today.\n",
      "<ID> The last three bullets have been integrated from uh the last minute uh email.\n",
      "<ID> Uh I just quickly jotted them down.\n",
      "<ID> Um so basically uh the as I told you the identification of how the remote control works and what are the various parts to it uh and what are the different processes um and how the parts uh communicate with each other.\n",
      "<ID> Um okay, so e the mee email said that teletext is now outdated, so we need to do away with that functionality of the remote control.\n",
      "<ID> Um also uh the remote control should be used only for television, because incorporating other features um makes it more comp complex.\n",
      "<ID> And the reason why teletext is outdated because uh of internet and uh the availability of internet over television.\n",
      "<ID> How however, our our remote control would only be dealing uh with the the use for television, in order to keep things simple.\n",
      "<ID> Um also the management wants that um our design should be unique uh it so it should incorporate um colour and the slogan uh that our company um has it as its standard.\n",
      "<ID> Okay, so he he here is a functional overview of the remote control.\n",
      "<ID> Um there's basically an energy source at the heart uh which feeds into the chip and the user interface.\n",
      "<ID> The user interf interface communicates with the chip, so I'll basic go over to the Okay.\n",
      "<ID> So if uh if this is our energy source and this is a cell, uh it communicates uh it feeds energy into the into the chip, which basically finds out h uh how how to do everything.\n",
      "<ID> There is a user interface here.\n",
      "<ID> So whe when the user presses a button, it feeds into the chip and the chip then generates a response and takes the response to an infrared terminal, um which then so the output of the chip is an infrared bit code, which is then communicated to the remote site, which h has an infrared receiver.\n",
      "<ID> Um the there can be uh a bulb here or something to indicate whether the remote is on or communicating.\n",
      "<ID> Um so these are the essent so a all the functionality of the remote control, whatever new functions that we need to do, um make the chip more complicated uh and bigger, basically.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Okay.\n",
      "<ID> Um so i in my personal preferences um I'm hoping that we can ke keep the design as simple and clear as possible.\n",
      "<ID> This would uh help us uh to upgrade our technology at a future point of time.\n",
      "<ID> And uh also if we can incorporate uh the latest features in our chip design, so that our um uh remote control does not become outdated soon and it's compatible with mot most uh televisions.\n",
      "<ID> That's about it.\n",
      "<ID> So anything that you would like to know or No, I don't have any idea about what each component costs.\n",
      "<UI> Okay.\n",
      "<ME> Thanks.\n",
      "<UI> Do you have any um i idea about costs at this point?\n",
      "<UI> Br Okay.\n",
      "<ID> Um yeah.\n",
      "<UI> 'Cause that's something to consider, I guess, if we're if we're using more advanced technology, it might increase the price.\n",
      "<ID> Anything else?\n",
      "<ID> Yeah.\n",
      "<ID> Certainly, yeah.\n",
      "<ID> So so tha yeah, we definitely need to operate within our constraints, but um unfortunately I I do not have any data, so uh I just identified the functional components for that.\n",
      "<UI> Yeah.\n",
      "<UI> That's fine.\n",
      "<UI> Are there any more questions, or shall we just skip straight to the next one and then we can discuss all of them together at the end?\n",
      "<ME> I think we need like some general discussion at the end probably.\n",
      "<UI> Yeah, I think that will do.\n",
      "<ID> Yeah, okay.\n",
      "<ME> Yeah.\n",
      "<UI> Okay, so do you want to Yes, shall shall we pull this up?\n",
      "<ME> Yeah, I think since since we were discussing some um design issues then I I I would like to continue okay, yeah.\n",
      "<UI> I think that has to come out of there.\n",
      "<ID> Yeah.\n",
      "<ID> Mm 'kay.\n",
      "<UI> Yeah.\n",
      "-----------------------------------------\n",
      "<ME> Thanks.\n",
      "<UI> Yeah, I thought those last minute things, they're gonna hit you the worst.\n",
      "<ME> Oh i Okay, I hope wait.\n",
      "<ME> Should it just There's just nothing.\n",
      "<ID> I it'll take some time.\n",
      "<UI> It ta takes a little Oh, and have you you need to then also press on yours, function F eight, so the blue function key at the bottom and F eight.\n",
      "<ME> Oh right, right, right, um Okay.\n",
      "<ME> Nothin okay, something is coming up.\n",
      "<ID> Oh, there it is, yeah.\n",
      "<UI> Now it's coming, computer no signal.\n",
      "<ID> It'll come up, it um uh no signal.\n",
      "<ME> No signal?\n",
      "<ME> Why?\n",
      "<UI> Maybe again?\n",
      "<ID> Yeah yeah, it says something now, adjusting Okay.\n",
      "<ME> Oh.\n",
      "<ME> My my computer went blank now.\n",
      "<UI> Okay, adjusting.\n",
      "<ME> Adjusting.\n",
      "<ME> But I don't see anything I don't see anything on my computer now.\n",
      "<UI> There we go, there we go.\n",
      "<ME> This is the problem, but Um.\n",
      "<ID> Oh, that's strange.\n",
      "<UI> Oh, if you press if you press function and that again there's there's usually three modes, one where it's only here, one where it's only there, and one where it's both.\n",
      "<ID> Okay.\n",
      "<ID> And one more time.\n",
      "<UI> Okay, so one more time.\n",
      "<ME> Uh now it's okay.\n",
      "<ME> No?\n",
      "<ME> No.\n",
      "<UI> Should yeah just wait for a moment, adjusting.\n",
      "<ID> Mm.\n",
      "<ME> Oh okay.\n",
      "<ME> Okay, that's fine, that's good.\n",
      "<UI> Okay.\n",
      "<ME> Okay, let's start from the beginning.\n",
      "<ME> So I'm going to speak about technical functions design uh just like some some first issues that came up.\n",
      "<ME> Um 'kay, so the method I was um adopting at this point, it's not um for the for the whole um period of the um all the project but it's just at th at this very moment.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Um uh my method was um to look at um other um remote controls, uh so mostly just by searching on the web and to see what um functionality they used.\n",
      "<ME> And then um after having got this inspiration and having compared what I found on the web um just to think about what the de what the user really needs and what um what the user might desire as additional uh functionalities.\n",
      "<ME> And yeah, and then just to um put the main function of the remote control in in words.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Um so the findings uh were um that the main function of the remote control is is just sending messages to the television set, so this quite straightforward.\n",
      "<ME> And uh w some of the main functions would be switching on, switching off, uh then the user would like to switch the channel um for example just m changing to the next channel to to flip through all all of the possible channels, or then mm uh the other possibility would be that um she might just want to choose one particular channel, so we would need the numbers.\n",
      "<ME> And and also the volume is very important.\n",
      "<ME> Um um I als okay.\n",
      "<ID> Sorry, cou could you go back for a second?\n",
      "<ID> Uh switching on off channel, uh volume, okay, that's great.\n",
      "<ME> 'Kay.\n",
      "<ME> Um um among the findings I found that m m most of the curr mm presently available remote controls also include other mm functionalities um in their design, like operating a VCR, but they don't seem to be able to deal with DVD players, but then there are surely there are many other functionali functions that could possibly be added to them, but according to the last minute update um actually um we do not want to have all this complicated functions added to our design.\n",
      "<UI> Mm-hmm.\n",
      "<ME> So my personal preferences would be uh to keep the mm the whole remote control small um just like the physical size.\n",
      "<ME> And then it must be easy to use, so it must follow some conventions um like whereabouts you find the on off button and maybe the colour tends to be red or something.\n",
      "-----------------------------------------\n",
      "<ME> Um then yeah, the must-have buttons would be on off and then the channel numbers and then um the one that allows us to go to the next or the previous channel, and then volume has to be there.\n",
      "<ME> But then um other functionalities um could be just uh there could be a menu button and you could change things on the screen then, um for example brightness and mm similar functions could be just um done through the menu.\n",
      "<ME> And yeah, the last question I had about whether we wanted to incorporate n uh more functionalities, the answer was already no because of the last minute update.\n",
      "<UI> Mm-hmm.\n",
      "<ME> So at the for the time being that's uh that's all.\n",
      "<ME> If you have questions Yeah, and also it's it's um other question is uh because there are so many different And there are so many different things that could possibly be included because besides video and DVD there are the mm um video CDs and whatever, so it might be problematic to to choose between all these possible things.\n",
      "<UI> Yeah.\n",
      "<UI> If I mean that was the the directive that came through from management, but if we had a a decent case for that we really think it's important to include video and DVD, I could get back to them and see.\n",
      "<UI> It's w it's just whether it's worth arguing about.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Okay.\n",
      "<UI> Are there any questions for clarification of Maarika before we go on to the next one?\n",
      "<ID> So in the u user interface requirements uh uh uh we we have been able to identify what are the basic buttons that we do want.\n",
      "<ID> Um but um so so at this stage, uh how we go about implementing those button we will not identify or I mean in we can completely do away with buttons and uh have some kind of a fancy user interface or something like that.\n",
      "<ID> But uh is is there any uh uh any thoughts on that?\n",
      "<ME> Um well, I think the buttons are still mm kind of the most um easy for the user to use, I mean um what other options would you have?\n",
      "<ID> Right.\n",
      "<ME> A little screen or something, but this would be really kind of I think a lot of learning for the user and and I mean the user just wants to get um get a result um quickly, not to spend time in like um giving several orders um I dunno.\n",
      "<ID> Yeah, and it'll make the costs yeah.\n",
      "<ID> Right.\n",
      "<UI> Mm-hmm.\n",
      "<ME> I think I th I would I would think the put the buttons, but if if you have other mm proposals um.\n",
      "<ID> Uh I think the co costs will also play a big role when we come to know about them.\n",
      "<UI> Mm.\n",
      "<ID> So well we can probably wait until t we have more knowledge on that.\n",
      "<ME> Yeah.\n",
      "<UI> Mm.\n",
      "<ME> Yeah.\n",
      "<ID> Uh i if the if the costs allow, we can have like an LCD display and uh with um because we do want something fancy and fashionable as well.\n",
      "<ME> Mm-hmm.\n",
      "<ID> So yeah?\n",
      "<UI> Mm-hmm.\n",
      "<ME> Yep.\n",
      "<ID> Cool.\n",
      "<UI> Sure, we can discuss that maybe after the next one.\n",
      "<PM> Cool.\n",
      "<UI> Do you want to yeah.\n",
      "<PM> Do you wanna give me the little cable thing?\n",
      "<ME> Uh am I going in the right direction?\n",
      "<ME> No.\n",
      "<ME> Wait.\n",
      "<PM> Yeah.\n",
      "<ME> Okay, here it comes.\n",
      "<UI> Oh, I'm getting hungry.\n",
      "<ME> Okay, here you are.\n",
      "<PM> Cool.\n",
      "<PM> Ah, that's why it won't meet.\n",
      "<PM> Okay, cool.\n",
      "<UI> You set?\n",
      "<PM> Yep, cool.\n",
      "<PM> Okay, functional requirements.\n",
      "<UI> Uh we need to do the function key thing so that it comes up on here.\n",
      "<PM> Alright, yeah.\n",
      "<UI> Hello.\n",
      "<ID> try to press oh, okay, yep.\n",
      "<UI> Is it plugged in prop it's working?\n",
      "<PM> It's working.\n",
      "<UI> Okay.\n",
      "<UI> Excellent.\n",
      "-----------------------------------------\n",
      "<PM> Cool, okay.\n",
      "<PM> So what I have, wh where I've got my information from is a survey where the usability lab um observed remote control use with um a hundred subjects and then they gave them a questionnaire.\n",
      "<PM> Um so it was all about, you know, how people feel about the look and feel of the remote control, you know.\n",
      "<PM> What's the most annoying things about remote controls and um the possibility of speech recognition and LCD screens in remote control.\n",
      "<PM> Not that they actually gave me any answers on the LCD screens, so I should have taken that bit out, but anyway.\n",
      "<PM> Um okay, so.\n",
      "<PM> What they found is that people don't like how current remote controls are, so you know, definitely you should be looking at something quite different.\n",
      "<PM> Um seventy five percent of users find most remote controls ugly.\n",
      "<PM> Uh the other twenty five percent have no fashion sense.\n",
      "<PM> Uh eighty percent of users would spend more to get um you know, a nice looking remote control.\n",
      "<PM> Um current remote controls, they don't match the user behaviour well, as you'll see on the next slide.\n",
      "<PM> Um I dunno what zapping is, but Oh, right.\n",
      "<UI> It's um switching between channels, sort of randomly going through.\n",
      "<PM> But you have that little thing that comes up at the bottom and tells you what's on.\n",
      "<PM> Um okay, fifty percent of users say they only use ten percent of the buttons, so that's going back to what, you know, we were saying earlier about, you know, do you need all the buttons on the remote control, they just make it look ugly.\n",
      "<ID> Mm.\n",
      "<ID> Right.\n",
      "<UI> Mm.\n",
      "<PM> Okay?\n",
      "<PM> Cool.\n",
      "<PM> Um so this is my little graph thing.\n",
      "<UI> Ooh, that's a bit difficult to see.\n",
      "<PM> Mm k Okay, well, I can send it to all of you.\n",
      "<UI> If you explain it to us it'll be fine.\n",
      "<UI> Yeah.\n",
      "<PM> What it is is um it's cones, 'cause I thought they'd be more exciting.\n",
      "<PM> Um but ooh where's it go?\n",
      "<UI> I liked the, I liked the litt ooh come back.\n",
      "<PM> Back.\n",
      "<PM> Oh.\n",
      "<UI> No.\n",
      "<PM> Oh yes, cool.\n",
      "<PM> Okay, I'm gonna stop playing with the little pointy thing.\n",
      "<ID> Mm-hmm.\n",
      "<PM> Um okay, so like what it shows is how much things are used relatively and what you can clearly see from that is the thing that's used most is the channel selection.\n",
      "<UI> Okay.\n",
      "<PM> What you can't see is volume selection, it's a little bit higher than all the others.\n",
      "<UI> Mm-hmm, that's the next one along, yeah?\n",
      "<PM> Yeah, so what the graph shows is that, you know, power, channel selection and volume selection are important, and the rest of them, you know, nobody really uses and so that's the the numbers along the top represent their like um their importance, you know, so on a scale of one to ten, how important is that and, you know, channel selection and volume selection are absolutely essential, and the power, well it's not quite so essential, apparently, although I don't understand how it couldn't be, um and everything else, I think, you know, you can forget about having those buttons on the remote control, 'cause they're just not needed, and they're not used.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Okay.\n",
      "<PM> This is the bit that the email messed up for me and that's what I was fiddling about with at the beginning of the thing.\n",
      "<PM> Okay, cool.\n",
      "<PM> So um okay, so this is what people find annoying about remote controls.\n",
      "<PM> Uh that they get lost, that the uh you know, they're not intuitive and that they're bad for repetitive strain injury.\n",
      "<UI> Mm-hmm.\n",
      "<PM> I think if you're watching enough TV to get repetitive strain injury from um you know, watching TV, then that's the least of your problems, but you know, it's up there.\n",
      "-----------------------------------------\n",
      "<UI> The remote control.\n",
      "<ID> Mm.\n",
      "<PM> Um that yeah.\n",
      "<PM> Okay, so um I mean the the RSI thing would be that, like when you have the computer keyboards and you keep your wrists up would be something that encourages you want something with an ergonomic t design that encourages good use of the remote control and you know, not straining your wrists watching TV.\n",
      "<ID> Right.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Mm-hmm.\n",
      "<ID> Hmm.\n",
      "<PM> Yes.\n",
      "<PM> Okay, cool.\n",
      "<PM> Right, um sorry this is pink because I was copying and pasting the table, and I didn't have time to white it out again.\n",
      "<UI> That's alright.\n",
      "<PM> Um okay, but that shows how people whether they would pay more for voice recognition software.\n",
      "<PM> So you can see from that that, you know, younger people to the age of thirty five are quite likely to pay quite a lot more f well quite are quite likely to pay more for voice recognition software, whereas as people get older, they're a bit more sceptical about it and they're less willing to to try it.\n",
      "<PM> Um so clearly voice recognition is something to think about, but um you know I d I do wonder how well that would work given that a TV, you know, tends to be people talking and um, you know, how are you going to stop it from just flipping channels whilst watching TV.\n",
      "<UI> Mm.\n",
      "<ID> Right.\n",
      "<PM> Um okay?\n",
      "<PM> Cool.\n",
      "<PM> Um okay, so these are my personal preferences.\n",
      "<PM> So you have sleek, stylish, sophisticated, you know, so something that's, you know, a bit cool.\n",
      "<PM> Um you know, functional, so it's useful, but minimalist.\n",
      "<PM> Um there's a there's an important thing that, you know, people use when, you know, when you're filling up your home, you know, a lot of people fill up their home with bits of crap, basically, you know, and you've got all this stuff, and you're just like, what the hell is that, who is ever gonna use it?\n",
      "<PM> You know, so things should either be functional or beautiful or preferably both, so I think we need to aim for both.\n",
      "<ID> Mm.\n",
      "<ID> Mm.\n",
      "<PM> Um okay, then a long battery life, like you were talking about earlier and um, you know, I was thinking that solar power would be quite cool because, you know, your remote control just sits there, and you could just sit it in the sunshine and save the environment a bit.\n",
      "<PM> Um and then like a locator, so you know, kind of like you have for a mobile phone or not a mobile phone Yeah, that's it, you know.\n",
      "<ID> Mm.\n",
      "<ID> Some kind of a ring, some Right.\n",
      "<UI> Keys and things like that, yeah.\n",
      "<UI> Whistle and it screams at you, yeah.\n",
      "<PM> I know, it's weird.\n",
      "<PM> My flatmate and I were talking about this on the way into uni this morning and I was like I need to get one for everything.\n",
      "<PM> So yeah, so maybe something where you clap and then it beeps, something a kind of sound that you don't often hear on the TV, you know, 'cause you don't want your remote control beeping every five minutes, 'cause you you'd then deliberately lose it by throwing it out the window or something.\n",
      "<UI> Mm-hmm.\n",
      "<PM> So okay?\n",
      "<ID> Hmm.\n",
      "<PM> Cool.\n",
      "<PM> That's me.\n",
      "<UI> That's you, excellent.\n",
      "<ID> Okay, that's great, thanks.\n",
      "<ME> Um that's very good, very interesting.\n",
      "<UI> Um.\n",
      "<UI> I'm just gonna tick yes.\n",
      "<UI> So, we've got about ten, fifteen minutes to discuss Mm-hmm.\n",
      "<ID> Mm.\n",
      "<ID> I think one of the very interesting things that came up in um uh Ka Kate Cat Cat's uh presentation was um uh this this issue of uh uh like voice recognition being more popular with uh younger people.\n",
      "<PM> Cat's.\n",
      "<PM> Ca.\n",
      "-----------------------------------------\n",
      "<ID> So if we need to have a target group um then uh I think as far as the m motto of our company is concerned, if we want to have something sleek and uh you know, good looking uh we are better off targeting a younger audience then um you know, people who are comparatively elderly.\n",
      "<ID> Um.\n",
      "<PM> Yeah, I mean that's the thing is that it didn't say in the survey, you know, whether, you know, these are the people that will pay more for a more stylish remote control, but I'm assuming, you know, yes.\n",
      "<ID> Right.\n",
      "<ID> Right.\n",
      "<ID> Bu but but the survey did say that f things like voice recognition are more popular with them, so if you want to put in something stylish, then uh th it'll certainly be more popular with this i ye with the younger people as compared to older people, yeah.\n",
      "<UI> Yeah.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<UI> Then again I guess the th where it was most popular was the fifteen to twenty five bracket and the I don't know how often they're buying televisions.\n",
      "<ID> Right, and Right.\n",
      "<PM> Well, that's when you go to uni, isn't it?\n",
      "<ID> Mm.\n",
      "<PM> So, you know Yeah.\n",
      "<UI> Yeah, but you don't have much money, generally.\n",
      "<ME> Yeah.\n",
      "<ME> Yeah, you share a television or something that yeah.\n",
      "<UI> I would've thought it's it's more that twenty five to thirty five, when people are really moving out and they've got their first job and they want their nice toys and O oh it's on sorry, we unplugged it.\n",
      "<ID> Right.\n",
      "<ID> But uh still, if if you can go back to that slide and uh, how popular was it?\n",
      "<PM> Oh, I've unplugged it.\n",
      "<PM> Do you want me to Yeah.\n",
      "<ID> Oh, oh, okay.\n",
      "<UI> Here, let me Yeah.\n",
      "<ID> That's alright, if you can just look it up on your computer, wh uh um people between twenty five to thirty five, uh how popular was so it was sti still still quite popular amongst them.\n",
      "<PM> Seventy six point three percent.\n",
      "<ME> It was seventy something, yeah, yeah.\n",
      "<PM> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ID> So even they are seventy six percent, is that high amount?\n",
      "<PM> Yeah, I kn I mean I know what you're saying about the fifteen to twenty five year olds, but I mean it has been proven that that people of that age group have a higher disposable income because they don't have like I mean, you know, if you're at university, you're paying your rent, but you don't have a mortgage, you don't have a life insurance policy, you don't normally have a car, yeah, so.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah, they've got no commitments and usually not a car and all of those things.\n",
      "<ID> Alright.\n",
      "<UI> Kids.\n",
      "<ID> Yeah.\n",
      "<PM> You're still learning to drive actually, so that just costs more than a car, but yeah.\n",
      "<UI> Yeah.\n",
      "<ID> So you're more likely to b Yeah.\n",
      "<PM> Um so I mean like it is an age group to target, really, I think.\n",
      "<UI> Yeah, and if we're if we're talking twenty five Euros as a price, that's not unaffordable, even for young people.\n",
      "<PM> No, I mean that's what, that's like fifteen Pounds?\n",
      "<UI> Yeah.\n",
      "<PM> You know, I think Yeah, I d I don't know many people without a TV.\n",
      "<ME> Yeah this this is not unaffordable, but the problem is whether people need it, whether they do have a TV to use its full Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> Yeah.\n",
      "<UI> But do they But the TVs are often kind of someone's old TV that's blah blah and be a bit strange to have a fancy rome remote.\n",
      "<PM> We didn't have a TV last year, and everyone thought we were off our heads, you know.\n",
      "<ME> Common, the students yeah, yeah.\n",
      "-----------------------------------------\n",
      "<ME> The s the stu yeah, and the remote control might not yeah, it might not even function with the old TV.\n",
      "<ID> Mm.\n",
      "<PM> Yeah, I d well we've we've got quite a d decent TV.\n",
      "<UI> Mm.\n",
      "<ID> Bu but even even in the case of twenty five to thirty five it's quite popular, right?\n",
      "<ME> Yeah, we're still yeah.\n",
      "<UI> Yeah.\n",
      "<ID> So mm uh are are are Mm.\n",
      "<ME> Or w maybe we can just kind of uh uh Yeah, but at the same time I think maybe we can we can just decide to to have both of these groups as our target, because actually I mean they're all still re young people.\n",
      "<PM> Yeah.\n",
      "<PM> I think I think the fact that, you know, ninety one point two percent of fifteen to twenty five year olds are saying yes, I would pay more for a voice recognition remote control, does say quite a lot really.\n",
      "<UI> Yeah.\n",
      "<PM> You know, so I mean that and the disposable income and I don't think it's something to ignore, you know.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> Is not a massive difference, you know.\n",
      "<ME> Yeah.\n",
      "<UI> Yeah, if we ta if we take fifteen to thirty five, but that then does imply that we should try and incorporate voice recognition.\n",
      "<PM> No, do totally.\n",
      "<ID> Mm.\n",
      "<ME> Yeah.\n",
      "<UI> Is that gonna have a an implication for the technical specs?\n",
      "<ID> Um I was having a a general outlook on um m most like sophisticated features, but voice recognition itself I'm not very sure about, because one of the p uh things that Cat pointed out was uh uh how do we go about implementing it?\n",
      "<UI> Mm-hmm.\n",
      "<ID> Uh and uh Yeah.\n",
      "<PM> You do have it in your mobile phone though, don't you?\n",
      "<PM> Because you have like I mean every mobile phone now has like call this person and it calls them.\n",
      "<UI> Yeah.\n",
      "<ID> But how frequently do we use it anyway and um uh h ho how good is it, you know uh voice recognition softwares are still quite uh Yeah.\n",
      "<ME> Yeah.\n",
      "<ME> Yeah.\n",
      "<PM> I don't know.\n",
      "<UI> Yeah.\n",
      "<UI> With um but with a TV remote it's gonna be quite limited if we're t saying the main things people want to do is on off channel five, louder, tha that should be relatively simple.\n",
      "<ME> An Yeah.\n",
      "<PM> Yeah.\n",
      "<ID> Right.\n",
      "<PM> S so y you'd maybe need a code word.\n",
      "<ID> Right.\n",
      "<ID> Okay.\n",
      "<ID> O Right.\n",
      "<PM> Do you know what I mean?\n",
      "<UI> Mm.\n",
      "<PM> So like when you say change, except that's being said quite a lot on TV, so maybe like, you know, remote.\n",
      "<PM> I mean how often do people say remote on TV?\n",
      "<UI> Yeah.\n",
      "<ID> Mm.\n",
      "<PM> Although I only watch Charmed, so really I wouldn't know but like so you'd just say remote five, you know, remote ten, remote one two nine.\n",
      "<ID> Right.\n",
      "<ID> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Okay, so it seems like a feasible thing to implement uh for for a limited yeah.\n",
      "<ME> Yeah.\n",
      "<UI> Yeah, but maybe if you wanna look into that just to just to check.\n",
      "<UI> Um, so if we go for the the fifteen to thirty five age group and then of course we're going to get th anyone who's older than thirty five who wants to look young and hip and trendy and has the money, then they'll they'll still go for the same advertising.\n",
      "<ME> Yeah but uh um Yeah, yeah sure, yeah, yeah.\n",
      "<ME> Yeah.\n",
      "<PM> I don't think there's a lot of uh voice recognition remote controls.\n",
      "-----------------------------------------\n",
      "<ME> Yeah, w well now the v the voice recognition if if it works wonderfully w we could possibly do away with all buttons, but I think this is not really the right moment yet, because people are just so used to buttons and um, yeah it's it's kind of safer, so we we need both, so the voice recognition would be just an extra, it wouldn't really reduce the size of the remote.\n",
      "<UI> Yeah, I think we need both.\n",
      "<ID> Mm.\n",
      "<ID> W What uh Mm.\n",
      "<UI> Yeah.\n",
      "<UI> Mm.\n",
      "<ID> What wh uh what I was thinking is that there is this uh separation between what the channels are on TV and how they are numbered on the remote control.\n",
      "<ID> If we can do with away with that, our product can be really popular uh in the sense that uh a person can say, I want to watch uh ITV one instead of saying that I want to go onto channel number forty five.\n",
      "<UI> Uh-huh.\n",
      "<PM> Yeah, that would be another way to do it.\n",
      "<UI> Uh-huh.\n",
      "<ID> Yeah, so if uh if something like that can be incorporated, some kind of Mm-hmm.\n",
      "<UI> So that if that was in the the voice recognition, that would be great.\n",
      "<PM> Yeah, but then the code word would be even more important, because I mean Sky advertise on every channel, don't they, you know, so then it would be you'd be watching Charmed, and then the Sky advert would come on and it would change to Sky.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Watch Sky and yeah.\n",
      "<PM> Yeah, yeah, and that would be really annoying.\n",
      "<ID> Alright.\n",
      "<ID> Yeah, that's Right.\n",
      "<UI> Mm-hmm.\n",
      "<UI> But that's definitely a possibility.\n",
      "<ME> Yeah but m but on the other hand, remote control isn't as close to you you probably might just just uh speak into it and and the TV would be already further away, so it might not pick up the other things coming from there.\n",
      "<ID> Mm.\n",
      "<UI> Yeah.\n",
      "<PM> Yeah.\n",
      "<PM> Do you not think that defeats the object of having voice recognition on a remote control though?\n",
      "<UI> So that you can yell at it, yeah.\n",
      "<PM> Yeah, you know, so you have to have the remote control.\n",
      "<PM> It's more like if you lost it and it's down the sofa sometime, you can yell at it and it'll just change it, you can look for it later, yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Alright.\n",
      "<ME> Yeah, but then the remote control I think I mean um the idea is kind of it's it's not that it's sitting there on on top of the television, because then you could already yell at the television and you wouldn't you you wouldn't need the remote control, so the remote control is still something you keep n near yourself.\n",
      "<PM> Yeah, yeah, I suppose nearer to you but a b like if you have surround sound then Yeah.\n",
      "<ID> Mm yeah and it might become very difficult from a distance for the television to understand what you're saying because of the noise factor for the remote control being cl I mean it'll it'll mm.\n",
      "<UI> Mm.\n",
      "<ME> Yeah, yeah, yeah.\n",
      "<UI> Yeah.\n",
      "<ME> No, but I I I was just defending the the fact why why we want to keep the remote control close to us, a and uh not to yell at it from the distance.\n",
      "<UI> Yeah.\n",
      "<ID> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> Mm.\n",
      "<UI> Yeah.\n",
      "<ID> So uh wh another thing uh that can be used is that uh there can be a beeper button on the TV, so you can go and press that button and um and the remote control, wherever it is, it'll beep, so we we can probably come to know where it is.\n",
      "<UI> Mm-hmm.\n",
      "<UI> That's but then if you're buying the remote separately, but y you could have something, but i if it was something that you could like stick onto the TV or something, some like a two p if you bought it in a two part pack, so one part attaches to the TV.\n",
      "<ME> Okay.\n",
      "<ME> Oh yeah, yeah.\n",
      "-----------------------------------------\n",
      "<ID> Right, yeah, yeah, yeah.\n",
      "<ME> Okay, yeah, mm-hmm.\n",
      "<PM> Yeah, 'cause it's it's quite important that you don't lose the the bit to locate the remote control.\n",
      "<UI> The l Well that's right, but it solves the problem of having different noises.\n",
      "<ID> Alright, yeah.\n",
      "<PM> Yeah, definitely, yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Okay, I think we're gonna have to wrap this up um.\n",
      "<UI> But if we go away with that that kind of general um specification in mind that we're looking at fifteen to thirty five year olds, we want it to look simple, but still have the buttons so it's easy to use, but only those key buttons, the major buttons and then one sort of menu one, and then voice recognition included as an option um but that obviously needs a little bit more working out as to whether it's really feasible and some of those problems we were mentioning um.\n",
      "<ME> The major ones, yeah.\n",
      "<ME> Mm-hmm.\n",
      "<ID> Right.\n",
      "<ID> Okay.\n",
      "<UI> What we have to do now is to go back to our little places, complete our questionnaire and some sort of summarisation, which y you'll get immediately by email.\n",
      "<UI> Send me your presentations so that I can use them to make the minutes, and then we've got a lunch break and after lunch we go back to our own little stations and have thirty minutes more work.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Um I'll put the minutes in that project documents folder, but I'll send you an email when I do it, so that you know.\n",
      "<ID> So where exactly is this i Ah, okay.\n",
      "<UI> It should be on your desktop, so on the yeah.\n",
      "<ID> Yeah.\n",
      "<ME> Yeah.\n",
      "<UI> So I'll put it I'll put them there as soon as I've written them.\n",
      "<ME> Did you find it?\n",
      "<ME> It's just yeah, yeah.\n",
      "<ID> Yeah, yeah in that one, right yeah.\n",
      "<UI> Yeah, and email them round.\n",
      "<PM> Oh, so y you want our um PowerPoint presentations in there, hey?\n",
      "<UI> Yeah, that would be great.\n",
      "<PM> Okay.\n",
      "<ME> Oh so so we'll just put them i there, we we yeah, w we won't even okay.\n",
      "<UI> Oh yeah, put them in there.\n",
      "<UI> Yeah, then you don't have to email them.\n",
      "<PM> There you go.\n",
      "<PM> But is everyone's called functional requirements?\n",
      "<UI> No, they're all called something slightly different.\n",
      "<ID> No.\n",
      "<UI> Technical requirements and something something, yeah.\n",
      "<PM> Okay, so that's good.\n",
      "<ME> Yeah.\n",
      "<PM> That's me done.\n",
      "<UI> So, if you put them in there, we'll all be able to see them and refer to them if we need to.\n",
      "<PM> Okay, cool.\n",
      "<UI> Um as to where we're going from here, you're going to look at the components concept.\n",
      "<ID> Right.\n",
      "<UI> Yeah?\n",
      "<UI> Whatever that means.\n",
      "<ME> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> I guess I'll find out.\n",
      "<UI> You'll be looking you'll be looking at the user interface concept, on something conceptual and you're watching trends to see how we go and surely voice recognition'll fall off the map or something that um we'll keep keep our options op hmm?\n",
      "<ME> Uh something conceptual, yeah.\n",
      "<ID> Wha what was it again that I was supposed to look into?\n",
      "<ID> Con components, oh.\n",
      "<UI> Components, yeah.\n",
      "<ME> Hmm.\n",
      "<ME> Sorry, but um the next meeting um are we going to have it um right after lunch or shall we prepare our To prepare, okay, yeah, that's good.\n",
      "<UI> No, we have we have after lunch we have thirty minutes to ourselves to prepare, so that's fine, w before lunch we just have to complete the questionnaire and some sort of summary.\n",
      "<ME> Okay.\n",
      "<UI> Okay?\n",
      "<UI> Right on time.\n",
      "<ME> Cool.\n",
      "<UI> Okay, so you can I guess we'll see you for lunch in a sec?\n",
      "<ME> Okay, see you.\n"
     ]
    }
   ],
   "source": [
    "# Tests for chunking algorithm\n",
    "import os\n",
    "\n",
    "sample_file_path = 'input/texts/' + samples[0]\n",
    "sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "sample = sample_file.read()\n",
    "sample_file.close()\n",
    "\n",
    "chunks = chunkize(sample)\n",
    "for chunk in chunks:\n",
    "    print('-----------------------------------------')\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation...\n",
      "Prompting on sample N1/30\n",
      "-- Completion: 0.0%\n",
      "---- Computing chunk 1 of 10 total, size: 2458 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "initial_time = time.time()\n",
    "skipped_samples = 0\n",
    "\n",
    "mkdir('intermediate')\n",
    "mkdir('intermediate/' + INTERMEDIATE_FOLDER)\n",
    "\n",
    "print('Starting computation...')\n",
    "\n",
    "# For each sample in dataset\n",
    "check = True\n",
    "for sample_n in range(n_samples):\n",
    "    if not(check):\n",
    "        break\n",
    "\n",
    "    # Estimate completion and time.\n",
    "    cur_samples = sample_n - skipped_samples\n",
    "    tot_samples = n_samples - skipped_samples\n",
    "    progress = cur_samples / tot_samples\n",
    "    pct = round(progress * 100, 1)\n",
    "    print('Prompting on sample N' + str(sample_n + 1) + '/' + str(n_samples))\n",
    "    print('-- Completion: ' + str(pct) + '%')\n",
    "    if cur_samples > 0:\n",
    "        approx_total = (time.time() - initial_time) / cur_samples * tot_samples\n",
    "        approx_remaining = approx_total * (1 - progress)\n",
    "        print('-- Estimated Remaining Time: ' + str(datetime.timedelta(seconds=int(approx_remaining))) + ' (total ' + str(datetime.timedelta(seconds=int(approx_total))) + ')')\n",
    "    \n",
    "    # Read sample and generate prompt\n",
    "    sample_file_path = 'input/texts/' + samples[sample_n]\n",
    "    sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "    sample = sample_file.read()\n",
    "    sample_file.close()\n",
    "    \n",
    "    # Find target file\n",
    "    target_file_path = get_intermediate_file_path(samples[sample_n])\n",
    "    if os.path.isfile(target_file_path):\n",
    "        print('-- Found intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        skipped_samples += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        check = False\n",
    "\n",
    "        # Inference\n",
    "        output = inference_sample(sample)\n",
    "\n",
    "        # Save answer in file\n",
    "        target_file = open(target_file_path, 'w', encoding='utf-8')\n",
    "        target_file.write(output)\n",
    "        target_file.close()\n",
    "        \n",
    "        check = True\n",
    "    except:\n",
    "        print('Error while generating sample')\n",
    "        traceback.print_exc()\n",
    "\n",
    "delta = time.time() - initial_time\n",
    "print('Done! Took', datetime.timedelta(seconds=int(delta)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculs de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ----------------------------- ---------- 1.1/1.5 MB 34.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 31.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in d:\\program files\\python311\\lib\\site-packages (from rouge_score) (1.25.2)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\program files\\python311\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Collecting click (from nltk->rouge_score)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/1a/70/e63223f8116931d365993d4a6b7ef653a4d920b41d03de7c59499962821f/click-8.1.6-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->rouge_score)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\program files\\python311\\lib\\site-packages (from nltk->rouge_score) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in d:\\program files\\python311\\lib\\site-packages (from nltk->rouge_score) (4.66.1)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml): started\n",
      "  Building wheel for rouge_score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24970 sha256=a6591765bd79bbd23371ae686d9880a68906fe5435e578e13122d199ed4c9e8d\n",
      "  Stored in directory: c:\\users\\jules\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge, joblib, click, absl-py, nltk, rouge_score\n",
      "Successfully installed absl-py-1.4.0 click-8.1.6 joblib-1.3.2 nltk-3.8.1 rouge-1.0.1 rouge_score-0.1.2\n",
      "Requirement already satisfied: evaluate in d:\\program files\\python311\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (1.25.2)\n",
      "Requirement already satisfied: dill in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in d:\\program files\\python311\\lib\\site-packages (from evaluate) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in d:\\program files\\python311\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in d:\\program files\\python311\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: aiohttp in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\program files\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.1/61.1 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.0.0 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.0.1+cu117)\n",
      "Requirement already satisfied: pandas>=1.0.1 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.0.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (4.32.0.dev0)\n",
      "Requirement already satisfied: numpy in d:\\program files\\python311\\lib\\site-packages (from bert-score) (1.25.2)\n",
      "Requirement already satisfied: requests in d:\\program files\\python311\\lib\\site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (4.66.1)\n",
      "Collecting matplotlib (from bert-score)\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/4d/9c/65830d4a56c47f5283eaa244dc1228c5da9c844a9f999ebcc2e69bf6cc65/matplotlib-3.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\program files\\python311\\lib\\site-packages (from bert-score) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\program files\\python311\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.0)\n",
      "Requirement already satisfied: jinja2 in d:\\program files\\python311\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\program files\\python311\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.3.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->bert-score)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/16/09/989b982322439faa4bafffcd669e6f942b38fee897c2664c987bcd091dec/contourpy-1.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->bert-score)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->bert-score)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/52/65/aaa3d2b7a292d93cc2cf1c534d03ba3f744e480f15b3b2ab6ad68189f7ee/fonttools-4.42.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading fonttools-4.42.0-cp311-cp311-win_amd64.whl.metadata (153 kB)\n",
      "     ---------------------------------------- 0.0/153.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 153.7/153.7 kB ? eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->bert-score)\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\program files\\python311\\lib\\site-packages (from matplotlib->bert-score) (9.3.0)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib->bert-score)\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 0.0/98.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 98.3/98.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python311\\lib\\site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: fsspec in d:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=3.0.0->bert-score) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\program files\\python311\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\program files\\python311\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.2.1)\n",
      "Downloading matplotlib-3.7.2-cp311-cp311-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.3/7.5 MB 27.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.7/7.5 MB 39.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.5 MB 59.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 47.7 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "   ---------------------------------------- 0.0/470.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 470.9/470.9 kB ? eta 0:00:00\n",
      "Downloading fonttools-4.42.0-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 67.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, bert-score\n",
      "Successfully installed bert-score-0.3.13 contourpy-1.1.0 cycler-0.11.0 fonttools-4.42.0 kiwisolver-1.4.4 matplotlib-3.7.2 pyparsing-3.0.9\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 0.0/118.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 118.9/118.9 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: regex in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (2023.8.8)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (1.25.2)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/31/58/e3b3dd6bb2ab7404f1f4992e2d0e6926ed40cef8ce1b3bbefd95877499e1/lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\jules\\appdata\\roaming\\python\\python311\\site-packages (from portalocker->sacrebleu) (306)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.9/3.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 26.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tabulate, portalocker, lxml, sacrebleu\n",
      "Successfully installed lxml-4.9.3 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0\n",
      "Requirement already satisfied: nltk in d:\\program files\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\program files\\python311\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in d:\\program files\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\program files\\python311\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in d:\\program files\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score rouge\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate, os, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scores computation...\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e758c4c624f339a0cc653d226bb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e818d1bd1e4c23867641a85929f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 29191.96 seconds, 0.00 sentences/sec\n",
      "Done!\n",
      "Average rouge1: 0.2661548987273394\n",
      "Average rouge2: 0.07980427751892992\n",
      "Average rougel: 0.15763943598433525\n",
      "Average bertscore: 0.20706295669078828\n"
     ]
    }
   ],
   "source": [
    "# Methods and variables\n",
    "print('Starting scores computation...')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "#STORAGE_FILE_NAME = 'scores'\n",
    "\n",
    "# Find output file for CSV scores\n",
    "#mkdir('output')\n",
    "#storage_file = open('output/' + STORAGE_FILE_NAME + '.csv', 'w', encoding='utf-8')\n",
    "#storage_file.write('path;rouge2;rougel;bertscore\\n')\n",
    "\n",
    "target_file_paths = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Find generated summary\n",
    "    target_file_path = get_intermediate_file_path(samples[sample_n])\n",
    "    if not os.path.isfile(target_file_path):\n",
    "        print('-- Found no intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        continue\n",
    "\n",
    "    # Read sample and generate prompt -> Keep summary\n",
    "    summary_file_path = 'input/summaries/' + samples[sample_n]\n",
    "    summary_file = open(summary_file_path, 'r', encoding='utf-8')\n",
    "    references.append(summary_file.read())\n",
    "    summary_file.close()\n",
    "\n",
    "    # Access generated summary\n",
    "    target_file = open(target_file_path, 'r', encoding='utf-8')\n",
    "    prediction = target_file.read()\n",
    "    target_file.close()\n",
    "\n",
    "    # Add prediction\n",
    "    target_file_paths.append(target_file_path)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "result_rouge = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "result_bertscore = bertscore.compute(predictions=predictions, references=references, lang='fr', rescale_with_baseline=True, verbose=True)\n",
    "\n",
    "# Calculate average\n",
    "list_rouge1, list_rouge2, list_rougel, list_bertscore = result_rouge['rouge1'], result_rouge['rouge2'], result_rouge['rougeL'], result_bertscore['f1']\n",
    "\n",
    "# Write to csv\n",
    "# Forget about BLEU...\n",
    "# Format: PATH | ROUGE1 | ROUGE2 | ROUGEL | BERTScore\n",
    "#for i in range(len(target_file_paths)):\n",
    "#    ligne = target_file_paths[i]\n",
    "#\n",
    "#    # list_rouge1[i]\n",
    "#    ligne += ';' + str(list_rouge2[i]) + \";\" + str(list_rougel[i])\n",
    "#    #ligne += \";\" + str(result_bleu['bleu'])\n",
    "#    ligne += \";\" + str(list_bertscore[i])\n",
    "#    \n",
    "#    storage_file.write(ligne + '\\n')\n",
    "\n",
    "#storage_file.close()\n",
    "print('Done!')\n",
    "\n",
    "# Calculate means\n",
    "print('Average rouge1:', statistics.mean(list_rouge1))\n",
    "print('Average rouge2:', statistics.mean(list_rouge2))\n",
    "print('Average rougel:', statistics.mean(list_rougel))\n",
    "print('Average bertscore:', statistics.mean(list_bertscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 2.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
