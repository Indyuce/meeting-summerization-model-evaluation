{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.92.0-py2.py3-none-any.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting httplib2<1.dev0,>=0.15.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0.dev0,>=1.19.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /workspace/.miniconda3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, httplib2, cachetools, rsa, pyasn1-modules, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.3.1 google-api-core-2.11.1 google-api-python-client-2.92.0 google-auth-2.21.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.59.1 httplib2-0.22.0 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 uritemplate-4.1.1\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-uaf34nd3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-uaf34nd3\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 30ed3adf474aaf2972ab56f5624089bc24a6adf3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers==4.31.0.dev0)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (4.51.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2022.12.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7308539 sha256=572e932b29f9d5a981fbb63006ea1a3b03ef2d0abaa21807b30de10eb726b3fd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mc0_du5j/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, regex, pyyaml, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 pyyaml-6.0 regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0.dev0\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-t6nc09mj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-t6nc09mj\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 95bffdec4326acf6a5d1c3dbaa857a26502aa265\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0.dev0) (1.2.1)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=241741 sha256=6f54a2971974f8f9c7eb365719725e8a5d0357ab55bc1718cc51e01e959ee2b1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-im_59kwc/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0.dev0\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n",
      "Requirement already satisfied: torch in /workspace/.miniconda3/lib/python3.10/site-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /workspace/.miniconda3/lib/python3.10/site-packages (from scipy) (1.24.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install bitsandbytes>=0.39.0\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install tiktoken\n",
    "!pip install torch\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 13:43:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070         Off| 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   55C    P8               16W / 220W|     15MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1165      G   /usr/lib/xorg/Xorg                            9MiB |\n",
      "|    0   N/A  N/A      1319      G   /usr/bin/gnome-shell                          4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:      181108932    10473132    73337164     5609268    97298636   163382608\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8316f3ca56c94b1eaf02767682c6c0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      4\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:484\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    483\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:2904\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2895\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2897\u001b[0m     (\n\u001b[1;32m   2898\u001b[0m         model,\n\u001b[1;32m   2899\u001b[0m         missing_keys,\n\u001b[1;32m   2900\u001b[0m         unexpected_keys,\n\u001b[1;32m   2901\u001b[0m         mismatched_keys,\n\u001b[1;32m   2902\u001b[0m         offload_index,\n\u001b[1;32m   2903\u001b[0m         error_msgs,\n\u001b[0;32m-> 2904\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   2923\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3244\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3243\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3244\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3248\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3249\u001b[0m     state_dict,\n\u001b[1;32m   3250\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3254\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3255\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:460\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'legendhasit/xgen-7b-8k-inst-8bit'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub[\"cli\"]\n",
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found 9 samples: ['sample_10_3018.txt', 'sample_11_3629.txt', 'sample_1_3070.txt', 'sample_3_2693.txt', 'sample_4_3564.txt', 'sample_5_3020.txt', 'sample_6_2751.txt', 'sample_7_3238.txt', 'sample_8_2389.txt']\n"
     ]
    }
   ],
   "source": [
    "def mkdir(folder_path):\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "# Define prompt template\n",
    "# ==========================================================================================\n",
    "PROMPT_TEMPLATE = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "<UI> Uh, making a profit of fifty million Euros.\n",
    "<ID> Alright so twenty five.\n",
    "<ME> Mm 'kay.\n",
    "<UI> So, it's go gonna have to be be pretty damn trendy.\n",
    "<ID> So yeah, I've The only the only remote controls I've used usually come with the television, and they're fairly basic.\n",
    "<UI> Yeah.\n",
    "<ME> Mm-hmm.\n",
    "<UI> Yeah.\n",
    "<ID> So uh Mm.\n",
    "<UI> Yeah, I was thinking that as well, I think the the only ones that I've seen that you buy are the sort of one for all type things where they're, yeah.\n",
    "<ME> Yeah the universal ones.\n",
    "<ME> Yeah.\n",
    "<UI> So presumably that might be an idea to put into.\n",
    "<ID> But but to sell it for twenty five you need a lot of neat features.\n",
    "<PM> Slim.\n",
    "<ID> For sure.\n",
    "<ME> Yeah.\n",
    "<UI> Yeah, yeah.\n",
    "<UI> Uh 'cause I mean, what uh twenty five Euros, that's about I dunno, fifteen Pounds or so?\n",
    "<ME> Mm-hmm, it's about that.\n",
    "<UI> And that's quite a lot for a remote control.\n",
    "<ID> Yeah, yeah.\n",
    "<ME> Mm.\n",
    "<ME> Um well my first thoughts would be most remote controls are grey or black.\n",
    "<ME> As you said they come with the TV so it's normally just your basic grey black remote control functions, so maybe we could think about colour?\n",
    "<UI> Uh-huh.\n",
    "<UI> Mm-hmm.\n",
    "<ME> Make that might make it a bit different from the rest at least.\n",
    "<ME> Um, and as you say, we need to have some kind of gimmick, so um I thought maybe something like if you lose it and you can whistle, you know those things?\n",
    "<UI> Okay.\n",
    "<UI> The the keyrings, yeah yeah.\n",
    "<ME> Because we always lose our remote control.\n",
    "<ID> Right.\n",
    "<UI> Okay, that's cool.\n",
    "<PM> Uh yeah uh, being as a Marketing Exper Expert I will like to say like before deciding the cost of this remote control or any other things we must see the market potential for this product like what is the competition in the market?\n",
    "<PM> What are the available prices of the other remote controls in the prices?\n",
    "<PM> What speciality other remote controls are having and how complicated it is to use these remote controls as compared to other remote controls available in the market.\n",
    "<UI> Okay.\n",
    "<PM> So before deciding or before finalising this project, we must discuss all these things, like and apart from this, it should be having a good look also, because people really li uh like to play with it when they are watching movies or playing with or playing with their CD player, MP three player like any electronic devices.\n",
    "<ME> Okay.\n",
    "<ME> Mm.\n",
    "<ME> Mm-hmm.\n",
    "<ME> Mm-hmm.\n",
    "<PM> They really want to have something good, having a good design in their hands, so, yes, all this.\n",
    "<ME> Yeah.\n",
    "<UI> Okay.\n",
    "<UI> 'Kay.\n",
    "<ID> Uh, what do we think a What do we think a good size would be for this?\n",
    "<UI> So, we're looking for 'Kay.\n",
    "<UI> We're Sorry, carry on.\n",
    "<ID> 'Cause I I know as you add more buttons to the remote it sometimes gets so big and clunky and there's just like a hundred buttons on it, or you could have a really small slim one but then you could lose it easily.\n",
    "<ME> Yeah.\n",
    "<UI> Mm-hmm.\n",
    "<UI> Mm-hmm.\n",
    "<ME> Yeah.\n",
    "<ME> Then you lose it, yeah.\n",
    "<UI> Okay.\n",
    "<ME> Kind of um, maybe more like a PDA kind of, just hand held, like, 'cause Yeah.\n",
    "<UI> For for uh remember we're trying to make it for twelve Euros fifty.\n",
    "<ME> No, I wasn't, no sorry I wasn't thinking of the screen of like a PDA but Okay.\n",
    "<UI> Okay well right we'll have to um I'll we're k having another meeting in half an hour so um we should all look into a bit uh, oh actually, no, we'll allocate.\n",
    "<UI> So you do the looking around at other remote controls.\n",
    "<PM> Yeah.\n",
    "<UI> Um, if you could maybe come up with sort of shapes and suggested shades or whatever, and you could look into um basically how how it's made IE like how you make it all in one, how what sort of materials are available to you whatever.\n",
    "<UI> And obviously, other instructions will come from the personal coach.\n",
    "<ID> Right.\n",
    "<UI> Which will probably just usurp what I said so Shapes and colours and um basically how to make it attractive.\n",
    "<ME> So you want me to look at shapes and everything you said?\n",
    "<ME> Yep.\n",
    "<ME> Okay.\n",
    "<UI> Uh.\n",
    "<ME> Mm-hmm.\n",
    "<UI> And you look at competition and design.\n",
    "<PM> Yep.\n",
    "<UI> Cool.\n",
    "<ME> Okay.\n",
    "<ID> Okay.\n",
    "<UI> So we have uh Um.\n",
    "<ID> Wait for emails?\n",
    "<PM> Uh.\n",
    "<ID> Hmm.\n",
    "<UI> Okay, groovy.\n",
    "<UI> And no doubt we'll get um Sorry.\n",
    "<ME> Oh no, .\n",
    "<ME> Sorry it's okay.\n",
    "<UI> We'll get um warnings for next meetings as well.\n",
    "<ME> Okay, cool.\n",
    "<UI> Okay.\n",
    "<UI> I shall I can't imagine these are worth much.\n",
    "<UI> Okay.\n",
    "<PM> Hmm.\n",
    "<UI> Fashion into electronic.\n",
    "<UI> Okay.\n",
    "\n",
    "### Assistant: The group discussed their initial ideas about the features that they wanted to integrate into the design. They discussed making a universal remote with a locator function. They also discussed the shape and the number of functions in the main interface. The Project Manager instructed the Marketing Expert to examine competitors' remotes, the User Interface Designer to research possible shapes and colors, and the Industrial Designer to research possible materials and the necessary internal components of the device.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "<ID> So welcome.\n",
    "<ID> The first kick-off meeting.\n",
    "<ID> What shall we do?\n",
    "<ID> First the opening, then the rest.\n",
    "<ID> What are we going to do.\n",
    "<ID> We m have to make a new remote control.\n",
    "<ID> It has to be original, trendy and user-friendly.\n",
    "<ID> So we will get back th on that.\n",
    "<ID> First we have to make a functional design.\n",
    "<ID> After that we have to make a conceptual design, and then after that a detailed design.\n",
    "<ID> So we'll discuss that later.\n",
    "<ID> First we have a look at.\n",
    "<ID> So first to we have to make a small painting.\n",
    "<ID> What have do we have to do.\n",
    "<ID> First you can save the documents.\n",
    "<ID> We have to do that every time we make something.\n",
    "<ID> You can print it.\n",
    "<ID> No.\n",
    "<ID> And we have to use the pen and the eraser.\n",
    "<ID> So Now.\n",
    "<ID> We all have to use this one.\n",
    "<ID> You have to make your own favourite animal.\n",
    "<ID> So I'll make an example.\n",
    "<ME> Yep.\n",
    "<ID> First don't touch that things.\n",
    "<ID> You can use the pen.\n",
    "<ID> And then you can make um something.\n",
    "<UI> Nice.\n",
    "<ID> Um you can change some things.\n",
    "<ID> Um format, line, and change it.\n",
    "<ID> And you can change the colour.\n",
    "<UI> An elephant.\n",
    "<ID> So that's it.\n",
    "<ID> So So and after it you have to save it.\n",
    "<ME> Okay.\n",
    "<ID> Now we can make a new one.\n",
    "<ID> You have to paint now.\n",
    "<ME> Oh.\n",
    "<ID> So you're next.\n",
    "<UI> 'Kay.\n",
    "<ME> Well we will try.\n",
    "<ME> Where it going?\n",
    "<PM> Hmm.\n",
    "<PM> That's uh strange.\n",
    "<ID> What is going on?\n",
    "<UI> pop-ups.\n",
    "<ID> What are you What?\n",
    "<ME> Hmm.\n",
    "<UI> What is this, Pictionary.\n",
    "<ME> Uh Mm.\n",
    "<ID> Um Is a It is a It is a A duck.\n",
    "<UI> Uh a bird.\n",
    "<UI> Bird.\n",
    "<ME> So Now save?\n",
    "<UI> Yeah.\n",
    "<ID> Yes.\n",
    "<ID> Hmm.\n",
    "<ME> Now uh blank?\n",
    "<ID> Blank, yes.\n",
    "<PM> Yeah.\n",
    "<ME> Yeah.\n",
    "<ID> Okay next one.\n",
    "<PM> Okay.\n",
    "<PM> Let's try this.\n",
    "<UI> Whoo.\n",
    "<PM> Uh Um.\n",
    "<ME> Yeah, yeah.\n",
    "<PM> Mm-hmm.\n",
    "<PM> Mm.\n",
    "<UI> Oh not.\n",
    "<UI> Oh.\n",
    "<ID> Oh.\n",
    "<UI> Okay.\n",
    "<UI> Okay.\n",
    "<UI> Yeah.\n",
    "<UI> No problem.\n",
    "<UI> Shit happens.\n",
    "<ME> I'm not getting anything uh on my screen now.\n",
    "<ME> Okay.\n",
    "<UI> A parrot.\n",
    "<ME> Wow.\n",
    "<UI> Ish.\n",
    "<ME> Oh.\n",
    "<UI> He did it before.\n",
    "<PM> Uh No, no.\n",
    "<PM> Yeah.\n",
    "<PM> Okay.\n",
    "<ME> Nice.\n",
    "<UI> Oh.\n",
    "<ID> Very good.\n",
    "<PM> Uh blank.\n",
    "<UI> Thank you.\n",
    "<ID> Okay.\n",
    "<ID> Very good.\n",
    "<ID> So um you can always go back.\n",
    "<ID> So That's it.\n",
    "<ID> So that was two.\n",
    "<ID> Now next.\n",
    "<ID> The budget.\n",
    "<ID> The b Uh we will sell the t at twenty five Euros.\n",
    "<ID> And we have only twenty of twelve and a half Euro to make it.\n",
    "<ID> So now we have to think about what we will make.\n",
    "<ID> First I wanna hear from you.\n",
    "<ID> Uh what are your experiences with remote controls.\n",
    "<ID> So F first.\n",
    "<UI> Uh I will start.\n",
    "<UI> Uh Big one, they are uh not easy to use.\n",
    "<UI> Um I have one set and uh a remote control, when I dropped it, uh it broke.\n",
    "<UI> So that won't be uh our goal, I think.\n",
    "<PM> No.\n",
    "<UI> And uh g big buttons, m uh that's easier to use than uh I think.\n",
    "<UI> Not all the small buttons, you don't know Big buttons, positive.\n",
    "<ID> Is this positive or negative, that uh big buttons?\n",
    "<ID> Positive.\n",
    "<UI> All all small buttons like when you have uh like a hundred buttons on your remote control, you won't know what they're working for.\n",
    "<ID> Okay.\n",
    "<ID> What are your experiences?\n",
    "<PM> Uh well I think the the the goal of a remote control is that it's it it has an influence on the TV set.\n",
    "<PM> And that it controls the channels and the the volume.\n",
    "<ID> Mm.\n",
    "<PM> And uh I I I think it's positive if there's a a LED uh uh a LED on the corner of the of the remote.\n",
    "<PM> So that you know it s it still has batteries on it in it.\n",
    "<PM> And that if you push the button the LED uh gives a light, and uh and you see that it's working.\n",
    "<PM> And uh yeah.\n",
    "<PM> Uh Yeah, but No no no.\n",
    "<ID> So and do they always have that?\n",
    "<PM> But I my my experience is that it it it's convenient to have that.\n",
    "<ID> It's easy to you.\n",
    "<PM> Yeah.\n",
    "<ID> Okay.\n",
    "<PM> Yeah.\n",
    "<ID> 'Kay.\n",
    "<ME> Uh at home we have a TV, a video uh recorder, a DVD player, and a satellite receiver.\n",
    "<ME> We have uh four distinctive remote controls for that.\n",
    "<UI> Thank you.\n",
    "<ME> That's not really ea easy.\n",
    "<UI> Help also.\n",
    "<ME> So it would be nice if we have one for all.\n",
    "<UI> Thank you.\n",
    "<ME> And we also had a remote control for our radio set.\n",
    "<ME> But um i it it had a lot of buttons on it, and you didn't know which one was what.\n",
    "<ME> And it was uh uh v not easy to use.\n",
    "<ME> So we n barely used it.\n",
    "<ID> Okay so they have too much.\n",
    "<ID> So next.\n",
    "<PM> Hmm.\n",
    "<ID> For our own remote control we have to think how do we make it.\n",
    "<ID> So what ideas do you have for it, for the new remote control?\n",
    "<ID> What what does it have to have?\n",
    "<UI> The weight.\n",
    "<UI> Not not too heavy.\n",
    "<ID> Not too heavy.\n",
    "<UI> Not much buttons.\n",
    "<ID> Yes.\n",
    "<ID> Yeah.\n",
    "<UI> Bust-free.\n",
    "<UI> That when you drop it, it won't break.\n",
    "<UI> Like uh some kind of rubber on it.\n",
    "<UI> Or hard uh hard plastic.\n",
    "<UI> Uh buttons not too small.\n",
    "<UI> Uh something like when you uh lose your uh remote control, sometimes it happen.\n",
    "<ID> Yes.\n",
    "<UI> Uh it between the couch and you can't find it.\n",
    "<UI> When you push a but a button on the TV, then you hear some uh some sort of bleep.\n",
    "<ID> Like a phone.\n",
    "<UI> And then you uh, hey there there's remote control.\n",
    "<ME> Yeah.\n",
    "<ID> Okay.\n",
    "<PM> Yeah.\n",
    "<ID> So, that's.\n",
    "<UI> Next.\n",
    "<PM> Yeah well that's that are good ideas.\n",
    "<PM> Uh Yeah well the LED on the corner, that that indicates that it's working.\n",
    "<PM> If you push a button.\n",
    "<PM> Um Yeah.\n",
    "<PM> And looking on the budget, not too expensive uh material.\n",
    "<PM> So probably plastic or something.\n",
    "<PM> Uh Mm no.\n",
    "<ID> Okay.\n",
    "<ME> Yeah I think it uh from a marketing point of view, it also has to look nice.\n",
    "<ME> Or you won't sell it.\n",
    "<ID> Yes.\n",
    "<ME> And um yeah uh on our website we can see what products we already have.\n",
    "<ME> And it should work with as many uh as possible of them.\n",
    "<ID> Okay.\n",
    "<ID> This is It has to be compatible with other things.\n",
    "<ME> Yes.\n",
    "<ID> Okay.\n",
    "<UI> I have one more idea.\n",
    "<UI> Just popped up.\n",
    "<ID> Yes?\n",
    "<UI> Uh it it won't take a lot of batteries.\n",
    "<UI> So you don't won't have to change the batteries uh once a week or uh once every two weeks.\n",
    "<ID> No battery use.\n",
    "<ID> So more ideas?\n",
    "<ID> No okay.\n",
    "<ID> It's only the first ideas.\n",
    "<ID> So uh what are we going to do now is Next meeting is in half an h hour.\n",
    "<ID> Uh Okay.\n",
    "<ID> Next meeting, half an hour.\n",
    "<ID> Um, what you have to do.\n",
    "<ID> Well look on your.\n",
    "<ID> And Next instructions you'll get in your email.\n",
    "<ID> So This is the first meeting.\n",
    "<ID> See you later in half an hour.\n",
    "<PM> Yes.\n",
    "<UI> Okay.\n",
    "<ME> Okay.\n",
    "<UI> Thank you.\n",
    "\n",
    "### Assistant: For the first meeting, the task of designing a remote control was briefly introduced along with the plan for the subsequent meetings. The group then drew animals to practise using the drawing platform. They discussed their likes and dislikes regarding current remote controls, including ease of use, multiple systems and power indicators. They then offered suggestions as to what they would like from their remote. They would like the remote to be durable, for it to include a device to help find it when lost and not use too many batteries.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "DATASET_NAME = 'ami'\n",
    "\n",
    "mkdir('input')\n",
    "mkdir('input/' + DATASET_NAME)\n",
    "mkdir('input/' + DATASET_NAME + '/texts')\n",
    "mkdir('input/' + DATASET_NAME + '/summaries')\n",
    "\n",
    "# Load samples from dataset\n",
    "# ==========================================================================================\n",
    "samples = os.listdir('input/' + DATASET_NAME + '/texts')\n",
    "samples = [sample for sample in samples if sample.endswith('.txt')]\n",
    "samples.sort()\n",
    "n_samples = len(samples)\n",
    "print('-- Found', n_samples, 'samples:', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation...\n",
      "Prompting instruction N1/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_1.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_2.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_3.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_4.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_5.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_6.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_7.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_8.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_9.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_10.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_1.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_2.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_3.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_4.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_5.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_6.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_7.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_8.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_9.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_10.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_1.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_2.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_3.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_4.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_5.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_6.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_7.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_8.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_9.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_10.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_1.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_2.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_3.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_4.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_5.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_6.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_7.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_8.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_9.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_10.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_1.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_2.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_3.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_4.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_5.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_6.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_7.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_8.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_9.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_10.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_1.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_2.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_3.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_4.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_5.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_6.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_7.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_8.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_9.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_10.txt', skipped.\n",
      "Done! Took 0:00:00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# ==========================================================================================\n",
    "initial_time = time.time()\n",
    "skipped_samples = 0\n",
    "\n",
    "mkdir('intermediate')\n",
    "mkdir('intermediate/' + DATASET_NAME)\n",
    "\n",
    "print('Starting computation...')\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Estimate completion and time.\n",
    "    cur_samples = sample_n - skipped_samples\n",
    "    tot_samples = n_samples - skipped_samples\n",
    "    progress = cur_samples / tot_samples\n",
    "    pct = round(progress * 100, 1)\n",
    "    print('Prompting on sample N' + str(sample_n + 1) + '/' + str(n_samples))\n",
    "    print('-- Completion: ' + str(pct) + '%')\n",
    "    if cur_samples > 0:\n",
    "        approx_total = (time.time() - initial_time) / cur_samples * tot_samples\n",
    "        approx_remaining = approx_total * (1 - progress)\n",
    "        print('-- Estimated Remaining Time: ' + str(datetime.timedelta(seconds=int(approx_remaining))) + ' (total ' + str(datetime.timedelta(seconds=int(approx_total))) + ')')\n",
    "    \n",
    "    # Read sample and generate prompt\n",
    "    sample_file_path = 'input/' + DATASET_NAME + '/texts/' + samples[sample_n]\n",
    "    sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "    sample = sample_file.read()\n",
    "    sample_file.close()\n",
    "    prompt = PROMPT_TEMPLATE.format(text=sample)\n",
    "    \n",
    "    # Find target file\n",
    "    target_file_path = 'intermediate/' + DATASET_NAME + '/' + samples[sample_n]\n",
    "    if os.path.isfile(target_file_path):\n",
    "        print('-- Found intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        skipped_samples += 1\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        # Sample one answer\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        input_length = len(input_ids['input_ids'][0])\n",
    "        print('-- Input Length:', input_length)\n",
    "        sample = model.generate(**input_ids, do_sample=True, max_new_tokens=2048, top_k=100, eos_token_id=50256, temperature=0.3)\n",
    "        output = tokenizer.decode(sample[0]).strip()\n",
    "\n",
    "        # Save answer in file\n",
    "        target_file = open(target_file_path, 'w', encoding='utf-8')\n",
    "        target_file.write(output)\n",
    "        target_file.close()\n",
    "\n",
    "        del input_ids\n",
    "        del sample\n",
    "        del output\n",
    "    \n",
    "    except:\n",
    "        print('Could not compute prompt:')\n",
    "        print(prompt)\n",
    "        traceback.print_exc()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "delta = time.time() - initial_time\n",
    "print('Done! Took', datetime.timedelta(seconds=int(delta)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=333555242f4e464ad2f1466233462741b2f13d4d85af3a6bfe866ca7f1f269f6\n",
      "  Stored in directory: /home/linagora/.cache/pip/wheels/3e/94/5c/7ff8a51c53c1bbc8df4cac58aa4990ffbc6fa203e9f0808fdd\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge, absl-py, rouge_score\n",
      "Successfully installed absl-py-1.4.0 rouge-1.0.1 rouge_score-0.1.2\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2.28.1)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: pandas in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: packaging in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (22.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, responses, datasets, evaluate\n",
      "Successfully installed datasets-2.13.1 evaluate-0.4.0 multiprocess-0.70.14 pyarrow-12.0.1 responses-0.18.0 xxhash-3.2.0\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from bert-score) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.5.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (22.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.31.0.dev0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2022.7)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.12.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.101)\n",
      "Requirement already satisfied: setuptools in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (16.0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score) (2022.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/linagora/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.0.0->bert-score) (1.2.1)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (2022.7.9)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: colorama in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\n",
      "Requirement already satisfied: lxml in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (4.9.1)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.7.0 sacrebleu-2.3.1\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score rouge\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scores computation...\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29575c6ff19f417080dc51bf873afe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df94b1e466be4d65a1b5d7a0aaf213a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 279482.79 seconds, 0.00 sentences/sec\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Methods and variables\n",
    "# ==========================================================================================\n",
    "print('Starting scores computation...')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "STORAGE_FILE_NAME = 'scores'\n",
    "\n",
    "# Used to process out n-shot examples\n",
    "def find_nth_occurrence(s, sub, n):\n",
    "    count = s.count(sub)\n",
    "    if count < n:\n",
    "        return -1\n",
    "    else:\n",
    "        index = -1\n",
    "        for i in range(n):\n",
    "            index = s.find(sub, index+1)\n",
    "        return index\n",
    "\n",
    "# Script itself\n",
    "# ==========================================================================================\n",
    "\n",
    "# Find output file for CSV scores\n",
    "mkdir('output')\n",
    "storage_file = open('output/' + STORAGE_FILE_NAME + '.csv', 'w', encoding='utf-8')\n",
    "storage_file.write('path;rouge2;rougel;bertscore\\n')\n",
    "\n",
    "target_file_paths = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Find generated summary\n",
    "    target_file_path = 'intermediate/' + DATASET_NAME + '/' + samples[sample_n]\n",
    "    if not os.path.isfile(target_file_path):\n",
    "        print('-- Found no intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        continue\n",
    "\n",
    "    # Read sample and generate prompt -> Keep summary\n",
    "    summary_file_path = 'input/' + DATASET_NAME + '/summaries/' + samples[sample_n]\n",
    "    summary_file = open(summary_file_path, 'r', encoding='utf-8')\n",
    "    references.append(summary_file.read())\n",
    "    summary_file.close()\n",
    "\n",
    "    # Access generated summary\n",
    "    target_file = open(target_file_path, 'r', encoding='utf-8')\n",
    "    prediction = target_file.read()\n",
    "    target_file.close()\n",
    "\n",
    "    # Process answer\n",
    "    separator = \"### Assistant:\"\n",
    "    cut_index = find_nth_occurrence(prediction, separator, 3) + len(separator)\n",
    "    prediction = prediction[cut_index:]\n",
    "    if prediction[0] == \" \": # Enlever l'espace devant\n",
    "        prediction = prediction[1:]\n",
    "    prediction = prediction[:-len(\"<|endoftext|>\") - 2]\n",
    "\n",
    "    # Add prediction\n",
    "    target_file_paths.append(target_file_path)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "result_rouge = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "result_bertscore = bertscore.compute(predictions=predictions, references=references, lang='fr', rescale_with_baseline=True, verbose=True)\n",
    "\n",
    "# Write to csv\n",
    "# Forget about BLEU...\n",
    "# Format: PATH | ROUGE2 | ROUGEL | BERTScore\n",
    "for i in range(len(target_file_paths)):\n",
    "    ligne = target_file_paths[i]\n",
    "    ligne += ';' + str(result_rouge['rouge2'][i]) + \";\" + str(result_rouge['rougeL'][i])\n",
    "    #ligne += \";\" + str(result_bleu['bleu'])\n",
    "    ligne += \";\" + str(result_bertscore['f1'][i])\n",
    "\n",
    "    storage_file.write(ligne + '\\n')\n",
    "\n",
    "storage_file.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
