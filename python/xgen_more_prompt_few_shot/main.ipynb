{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.92.0-py2.py3-none-any.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting httplib2<1.dev0,>=0.15.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0.dev0,>=1.19.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /workspace/.miniconda3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, httplib2, cachetools, rsa, pyasn1-modules, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.3.1 google-api-core-2.11.1 google-api-python-client-2.92.0 google-auth-2.21.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.59.1 httplib2-0.22.0 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 uritemplate-4.1.1\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-uaf34nd3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-uaf34nd3\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 30ed3adf474aaf2972ab56f5624089bc24a6adf3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers==4.31.0.dev0)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (4.51.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2022.12.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7308539 sha256=572e932b29f9d5a981fbb63006ea1a3b03ef2d0abaa21807b30de10eb726b3fd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mc0_du5j/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, regex, pyyaml, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 pyyaml-6.0 regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0.dev0\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-t6nc09mj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-t6nc09mj\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 95bffdec4326acf6a5d1c3dbaa857a26502aa265\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0.dev0) (1.2.1)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=241741 sha256=6f54a2971974f8f9c7eb365719725e8a5d0357ab55bc1718cc51e01e959ee2b1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-im_59kwc/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0.dev0\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n",
      "Requirement already satisfied: torch in /workspace/.miniconda3/lib/python3.10/site-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /workspace/.miniconda3/lib/python3.10/site-packages (from scipy) (1.24.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install bitsandbytes>=0.39.0\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install tiktoken\n",
    "!pip install torch\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 27 15:28:31 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3070         Off| 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 44%   57C    P8               16W / 220W|     15MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1158      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    0   N/A  N/A      1317      G   /usr/bin/gnome-shell                          4MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\r\n",
      "Mem:        65761324     1063672    47848760        4072    16848892    63994368\r\n",
      "Swap:        2097148           0     2097148\r\n"
     ]
    }
   ],
   "source": [
    "!free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c3eb384d5d4d27a1ee25b97a8b5b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'legendhasit/xgen-7b-8k-inst-8bit'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /home/linagora/anaconda3/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.12.2)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (2022.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0)\n",
      "Collecting InquirerPy==0.3.4\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.36)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: wcwidth in /home/linagora/anaconda3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.5)\n",
      "Installing collected packages: pfzy, InquirerPy\n",
      "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n",
      "\u001b[6n\u001b[?2004h\u001b[?1l\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bert-base-multilingual-cased (715.3M, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m fdfce55e: main # modified 1 week ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel OpenLLM-France/bloom-560m-ecommerce-faq-fr (12.6M, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 239462ee: (detached) # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 3b13cb96: main # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (44.4K, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 5fe0f1b2: (detached) # modified 3 weeks ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/bloom-560m (1.1G, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 4f42c91d: main # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel legendhasit/xgen-7b-8k-inst-8bit (13.8G, used 55 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 0fced741: main # modified 3 weeks ago\u001b[0m\n",
      "\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[69D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
      "\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;180m?\u001b[0m Select revisions to delete:\u001b[0;38;5;249m 0 revisions selected counting for 0.0. \u001b[0m\n",
      "\u001b[0;38;5;75m❯\u001b[0m \u001b[0;38;5;108m○\u001b[0m \u001b[0;38;5;75mNone of the following (if selected, nothing will be deleted).\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bert-base-multilingual-cased (715.3M, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m fdfce55e: main # modified 1 week ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel OpenLLM-France/bloom-560m-ecommerce-faq-fr (12.6M, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 239462ee: (detached) # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 3b13cb96: main # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel Salesforce/xgen-7b-8k-inst (44.4K, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 5fe0f1b2: (detached) # modified 3 weeks ago\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 68f77dec: main # modified 6 days ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel bigscience/bloom-560m (1.1G, used 3 days ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 4f42c91d: main # modified 4 weeks ago\u001b[0m\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[0mModel legendhasit/xgen-7b-8k-inst-8bit (13.8G, used 55 minutes ago)\u001b[0m\n",
      "\u001b[0m  \u001b[0;38;5;108m○\u001b[0m 0fced741: main # modified 3 weeks ago\u001b[0m\n",
      "\n",
      "\u001b[0m \u001b[0m\n",
      "\u001b[79Ci\u001b[0m49mPress <space> to select, <enter> to validate and <ctrl+c> to quit without modif\n",
      "\u001b[0;38;5;249mcation.\u001b[7D\u001b[22A\u001b[69C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub[\"cli\"]\n",
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found 1 texts: ['txt_ami.txt']\n",
      "Types of prompts: \n",
      "['Summarize the following text.', 'Summarize.', 'Provide a structured summary with 5 paragraphs of the following text.', 'Summarize the following text writing 5 paragraphs.', 'Summarize the following text writing 5 paragraphs which contain all the important details']\n",
      "\n",
      "['Summarize the following text.', 'Summarize.', 'Give the key points in the following text.', 'Provide a list of key points for this text, containing all the important details.', 'As a secretary, write down the minutes of the following meeting.']\n",
      "\n",
      "['Summarize the following text.', 'Summarize.', 'Provide a one paragraph summary of the following text.', 'Summarize the following text as one paragraph.', 'Provide a one paragraph summary of the following text, containing all the important details.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters:\n",
    "# - DATASET_NAME\n",
    "# - HEADER\n",
    "# - PROMPT_TEMPLATE\n",
    "# - samples in dataset 'input/<dataset_name>'\n",
    "# - instructions in 'instructions.txt'\n",
    "\n",
    "def mkdir(folder_path):\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "mkdir('input')\n",
    "\n",
    "# Define prompt template\n",
    "# ==========================================================================================\n",
    "HEADER = (\n",
    "    \"A chat between a curious human and an artificial intelligence assistant. \"\n",
    "    \"The assistant gives helpful, detailed, and polite answers to the human's questions.\\n\\n\"\n",
    ")\n",
    "\n",
    "EXAMPLE_TEMPLATE = \"\"\"### Human: {instruction}\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant: {answer}\"\"\"\n",
    "\n",
    "REQUEST_TEMPLATE = \"\"\"### Human: {instruction}\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "# Load texts from input folder\n",
    "# ==========================================================================================\n",
    "texts_list = os.listdir('input/texts')\n",
    "texts = [text for text in texts_list]\n",
    "texts.sort()\n",
    "n_texts = len(texts)\n",
    "print('-- Found', n_texts, 'texts:', texts)\n",
    "\n",
    "# Load instructions\n",
    "# ==========================================================================================\n",
    "mkdir('instructions')\n",
    "type_folder = os.listdir('input/instructions')\n",
    "print(\"Types of prompts: \")\n",
    "instruction_types = []\n",
    "n_instructions = 0\n",
    "for subfolder in type_folder:\n",
    "    instruction_file = open('input/instructions/'+subfolder+'/pro_'+subfolder+'.txt', 'r', encoding='utf-8')\n",
    "    prompts = instruction_file.readlines()\n",
    "    n_prompts = len(prompts)\n",
    "    n_instructions += n_prompts\n",
    "    for i in range(n_prompts):\n",
    "        prompts[i] = prompts[i].replace('\\n', '')\n",
    "    instruction_types.append(prompts)\n",
    "    instruction_file.close()\n",
    "    print(prompts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation...\n",
      "Inférence 1/60:\n",
      "-- Found intermediate result file 'intermediate/1/sum_1_1.txt', skipped.\n",
      "Inférence 2/60:\n",
      "-- Estimated Remaining Time: 0:00:00 (total 0:00:00)\n",
      "-- Found intermediate result file 'intermediate/1/sum_1_2.txt', skipped.\n",
      "Inférence 3/60:\n",
      "-- Estimated Remaining Time: 0:00:00 (total 0:00:00)\n",
      "-- Found intermediate result file 'intermediate/1/sum_1_3.txt', skipped.\n",
      "Inférence 4/60:\n",
      "-- Estimated Remaining Time: 0:00:00 (total 0:00:00)\n",
      "-- Found intermediate result file 'intermediate/1/sum_1_4.txt', skipped.\n",
      "Inférence 5/60:\n",
      "-- Estimated Remaining Time: 0:00:00 (total 0:00:00)\n",
      "-- Found intermediate result file 'intermediate/1/sum_1_5.txt', skipped.\n",
      "Inférence 6/60:\n",
      "-- Estimated Remaining Time: 0:00:00 (total 0:00:00)\n",
      "-- Input Length: 16\n",
      "Inférence 7/60:\n",
      "-- Estimated Remaining Time: 0:00:15 (total 0:00:17)\n",
      "-- Input Length: 16\n",
      "Inférence 8/60:\n",
      "-- Estimated Remaining Time: 0:00:26 (total 0:00:30)\n",
      "-- Input Length: 16\n",
      "Inférence 9/60:\n",
      "-- Estimated Remaining Time: 0:00:34 (total 0:00:39)\n",
      "-- Input Length: 16\n",
      "Inférence 10/60:\n",
      "-- Estimated Remaining Time: 0:00:39 (total 0:00:46)\n",
      "-- Input Length: 16\n",
      "Inférence 11/60:\n",
      "-- Estimated Remaining Time: 0:00:43 (total 0:00:52)\n",
      "-- Input Length: 16\n",
      "Inférence 12/60:\n",
      "-- Estimated Remaining Time: 0:00:46 (total 0:00:57)\n",
      "-- Input Length: 16\n",
      "Inférence 13/60:\n",
      "-- Estimated Remaining Time: 0:00:48 (total 0:01:01)\n",
      "-- Input Length: 16\n",
      "Inférence 14/60:\n",
      "-- Estimated Remaining Time: 0:00:50 (total 0:01:04)\n",
      "-- Input Length: 16\n",
      "Inférence 15/60:\n",
      "-- Estimated Remaining Time: 0:00:51 (total 0:01:07)\n",
      "-- Input Length: 16\n",
      "Inférence 16/60:\n",
      "-- Estimated Remaining Time: 0:00:52 (total 0:01:09)\n",
      "-- Input Length: 16\n",
      "Inférence 17/60:\n",
      "-- Estimated Remaining Time: 0:00:52 (total 0:01:12)\n",
      "-- Input Length: 16\n",
      "Inférence 18/60:\n",
      "-- Estimated Remaining Time: 0:00:53 (total 0:01:13)\n",
      "-- Input Length: 16\n",
      "Inférence 19/60:\n",
      "-- Estimated Remaining Time: 0:00:52 (total 0:01:15)\n",
      "-- Input Length: 16\n",
      "Inférence 20/60:\n",
      "-- Estimated Remaining Time: 0:00:52 (total 0:01:17)\n",
      "-- Input Length: 16\n",
      "Inférence 21/60:\n",
      "-- Estimated Remaining Time: 0:00:52 (total 0:01:18)\n",
      "-- Input Length: 16\n",
      "Inférence 22/60:\n",
      "-- Estimated Remaining Time: 0:00:51 (total 0:01:19)\n",
      "-- Input Length: 16\n",
      "Inférence 23/60:\n",
      "-- Estimated Remaining Time: 0:00:51 (total 0:01:21)\n",
      "-- Input Length: 16\n",
      "Inférence 24/60:\n",
      "-- Estimated Remaining Time: 0:00:50 (total 0:01:22)\n",
      "-- Input Length: 16\n",
      "Inférence 25/60:\n",
      "-- Estimated Remaining Time: 0:00:50 (total 0:01:23)\n",
      "-- Input Length: 16\n",
      "Inférence 26/60:\n",
      "-- Estimated Remaining Time: 0:00:49 (total 0:01:24)\n",
      "-- Input Length: 16\n",
      "Inférence 27/60:\n",
      "-- Estimated Remaining Time: 0:00:48 (total 0:01:25)\n",
      "-- Input Length: 16\n",
      "Inférence 28/60:\n",
      "-- Estimated Remaining Time: 0:00:47 (total 0:01:26)\n",
      "-- Input Length: 16\n",
      "Inférence 29/60:\n",
      "-- Estimated Remaining Time: 0:00:46 (total 0:01:26)\n",
      "-- Input Length: 16\n",
      "Inférence 30/60:\n",
      "-- Estimated Remaining Time: 0:00:45 (total 0:01:27)\n",
      "-- Input Length: 16\n",
      "Inférence 31/60:\n",
      "-- Estimated Remaining Time: 0:00:43 (total 0:01:27)\n",
      "-- Input Length: 16\n",
      "Inférence 32/60:\n",
      "-- Estimated Remaining Time: 0:00:42 (total 0:01:28)\n",
      "-- Input Length: 16\n",
      "Inférence 33/60:\n",
      "-- Estimated Remaining Time: 0:00:41 (total 0:01:29)\n",
      "-- Input Length: 16\n",
      "Inférence 34/60:\n",
      "-- Estimated Remaining Time: 0:00:40 (total 0:01:29)\n",
      "-- Input Length: 16\n",
      "Inférence 35/60:\n",
      "-- Estimated Remaining Time: 0:00:39 (total 0:01:30)\n",
      "-- Input Length: 16\n",
      "Inférence 36/60:\n",
      "-- Estimated Remaining Time: 0:00:37 (total 0:01:30)\n",
      "-- Input Length: 16\n",
      "Inférence 37/60:\n",
      "-- Estimated Remaining Time: 0:00:36 (total 0:01:30)\n",
      "-- Input Length: 16\n",
      "Inférence 38/60:\n",
      "-- Estimated Remaining Time: 0:00:35 (total 0:01:31)\n",
      "-- Input Length: 16\n",
      "Inférence 39/60:\n",
      "-- Estimated Remaining Time: 0:00:33 (total 0:01:31)\n",
      "-- Input Length: 16\n",
      "Inférence 40/60:\n",
      "-- Estimated Remaining Time: 0:00:32 (total 0:01:32)\n",
      "-- Input Length: 16\n",
      "Inférence 41/60:\n",
      "-- Estimated Remaining Time: 0:00:30 (total 0:01:32)\n",
      "-- Input Length: 16\n",
      "Inférence 42/60:\n",
      "-- Estimated Remaining Time: 0:00:29 (total 0:01:32)\n",
      "-- Input Length: 16\n",
      "Inférence 43/60:\n",
      "-- Estimated Remaining Time: 0:00:27 (total 0:01:33)\n",
      "-- Input Length: 16\n",
      "Inférence 44/60:\n",
      "-- Estimated Remaining Time: 0:00:26 (total 0:01:33)\n",
      "-- Input Length: 16\n",
      "Inférence 45/60:\n",
      "-- Estimated Remaining Time: 0:00:24 (total 0:01:33)\n",
      "-- Input Length: 16\n",
      "Inférence 46/60:\n",
      "-- Estimated Remaining Time: 0:00:23 (total 0:01:33)\n",
      "-- Input Length: 16\n",
      "Inférence 47/60:\n",
      "-- Estimated Remaining Time: 0:00:21 (total 0:01:34)\n",
      "-- Input Length: 16\n",
      "Inférence 48/60:\n",
      "-- Estimated Remaining Time: 0:00:20 (total 0:01:34)\n",
      "-- Input Length: 16\n",
      "Inférence 49/60:\n",
      "-- Estimated Remaining Time: 0:00:18 (total 0:01:34)\n",
      "-- Input Length: 16\n",
      "Inférence 50/60:\n",
      "-- Estimated Remaining Time: 0:00:17 (total 0:01:34)\n",
      "-- Input Length: 16\n",
      "Inférence 51/60:\n",
      "-- Estimated Remaining Time: 0:00:15 (total 0:01:35)\n",
      "-- Input Length: 16\n",
      "Inférence 52/60:\n",
      "-- Estimated Remaining Time: 0:00:14 (total 0:01:35)\n",
      "-- Input Length: 16\n",
      "Inférence 53/60:\n",
      "-- Estimated Remaining Time: 0:00:12 (total 0:01:35)\n",
      "-- Input Length: 16\n",
      "Inférence 54/60:\n",
      "-- Estimated Remaining Time: 0:00:11 (total 0:01:35)\n",
      "-- Input Length: 16\n",
      "Inférence 55/60:\n",
      "-- Estimated Remaining Time: 0:00:09 (total 0:01:35)\n",
      "-- Input Length: 16\n",
      "Inférence 56/60:\n",
      "-- Estimated Remaining Time: 0:00:08 (total 0:01:36)\n",
      "-- Input Length: 16\n",
      "Inférence 57/60:\n",
      "-- Estimated Remaining Time: 0:00:06 (total 0:01:36)\n",
      "-- Input Length: 16\n",
      "Inférence 58/60:\n",
      "-- Estimated Remaining Time: 0:00:04 (total 0:01:36)\n",
      "-- Input Length: 16\n",
      "Inférence 59/60:\n",
      "-- Estimated Remaining Time: 0:00:03 (total 0:01:36)\n",
      "-- Input Length: 16\n",
      "Inférence 60/60:\n",
      "-- Estimated Remaining Time: 0:00:01 (total 0:01:36)\n",
      "-- Input Length: 16\n",
      "Done! Took 0:01:36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# ==========================================================================================\n",
    "initial_time = time.time()\n",
    "skipped_samples = 0\n",
    "\n",
    "n_samples = 4 # A CHANGER A 4\n",
    "n_inferences_total = n_instructions * n_texts * n_samples # Total number of inferences\n",
    "n_inference = 0\n",
    "\n",
    "def TwoShotHeader(k, instruction): # k désigne le type de prompt (1, 2 ou 3). Renvoie un header avec deux exemples.\n",
    "    file_example = open('input/examples/txt_gpt.txt', 'r', encoding='utf-8')\n",
    "    text_example = file_example.read()\n",
    "    file_example.close()\n",
    "    file_sum = open('input/summaries/'+str(k)+'/sum_'+str(k)+'_gpt.txt', 'r', encoding='utf-8')\n",
    "    text_sum = file_sum.read()\n",
    "    file_sum.close()\n",
    "    example_1 = EXAMPLE_TEMPLATE.format(instruction=instruction, text=text_example, answer=text_sum)\n",
    "    file_example = open('input/examples/txt_fre.txt', 'r', encoding='utf-8')\n",
    "    text_example = file_example.read()\n",
    "    file_example.close()\n",
    "    file_sum = open('input/summaries/'+str(k)+'/sum_'+str(k)+'_fre.txt', 'r', encoding='utf-8')\n",
    "    text_sum = file_sum.read()\n",
    "    file_sum.close()\n",
    "    example_2 = EXAMPLE_TEMPLATE.format(instruction=instruction, text=text_example, answer=text_sum)\n",
    "\n",
    "    return HEADER + example_1 + \"\\n\\n\" + example_2 + \"\\n\\n\" \n",
    "\n",
    "def treatOutput(output, i, n_inference, sample): # DOIT PRENDRE EN ENTREE L'OUTPUT DETOKENIZED ET LE TOKENIZED (sample)\n",
    "    mkdir('output')\n",
    "    mkdir('output/'+str(i))\n",
    "    target_path = 'output/'+str(i)+'/sum_'+str(i)+'_'+str(n_inference)+'.txt' # Format sum_2_9.txt\n",
    "    text_file = open(target_path, 'w', encoding='utf-8')\n",
    "    occ_1 = output.find(\"### Assistant: \")\n",
    "    occ_2 = output.find(\"### Assistant: \", occ_1+1)\n",
    "    occ_3 = output.find(\"### Assistant: \", occ_2+1)\n",
    "    output = output[occ_3+15:]\n",
    "    if output.find('<|endoftext|>')!=-1:\n",
    "        output = output[:-14]\n",
    "    text_file.write(str(len(sample[0]))+'\\n'+output)\n",
    "    text_file.close()\n",
    "\n",
    "mkdir('intermediate')\n",
    "print('Starting computation...')\n",
    "for i in range(len(instruction_types)):\n",
    "    instructions = instruction_types[i]\n",
    "    mkdir('intermediate/'+str(i+1))\n",
    "    for name_text in texts:\n",
    "        # Pour un prompt donné, un texte donné:\n",
    "        text_file = open('input/texts/'+name_text, 'r', encoding='utf-8')\n",
    "        text_request = text_file.read()\n",
    "        text_file.close()\n",
    "        # Construction des exemples\n",
    "        for instruction in instructions:\n",
    "            two_shot_header = TwoShotHeader(i+1, instruction)\n",
    "            user_request = REQUEST_TEMPLATE.format(instruction=instruction, text=text_request)\n",
    "            prompt = two_shot_header + user_request\n",
    "            for j in range(n_samples): # for j in range(n_samples): # puis tout décaler\n",
    "                n_inference += 1\n",
    "                ### DISPLAY :\n",
    "                print(\"Inférence \"+str(n_inference)+\"/\"+str(n_inferences_total)+\":\")\n",
    "                if n_inference>1: # Pour une estimation, il faut forcément attendre le 2ème passage\n",
    "                    approx_total = n_inferences_total * (time.time() - initial_time) / (n_inference-1)\n",
    "                    approx_remaining = approx_total * (1 - (n_inference-1)/n_inferences_total)\n",
    "                    print('-- Estimated Remaining Time: ' + str(datetime.timedelta(seconds=int(approx_remaining))) + ' (total ' + str(datetime.timedelta(seconds=int(approx_total))) + ')')\n",
    "\n",
    "                target_path = 'intermediate/'+str(i+1)\n",
    "                mkdir(target_path)\n",
    "                target_path += '/sum_'+str(i+1)+'_'+str(n_inference)+'.txt' # Format sum_2_9.txt\n",
    "                if os.path.isfile(target_path):\n",
    "                    print('-- Found intermediate result file \\'' + target_path + '\\', skipped.')\n",
    "                    skipped_samples += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda') # ICI RESTRICTION sur prompt\n",
    "                    input_length = len(input_ids['input_ids'][0])\n",
    "                    print('-- Input Length:', input_length)\n",
    "                    sample = model.generate(**input_ids, do_sample=True, max_new_tokens=700, top_k=20, eos_token_id=50256, temperature=0.3) # Top-k, température, max new tokens\n",
    "                    output = tokenizer.decode(sample[0]).strip()\n",
    "                    treatOutput(output, i+1, n_inference, sample)\n",
    "                    # Save answer in file\n",
    "                    target_file = open(target_path, 'w', encoding='utf-8')\n",
    "                    target_file.write(output)\n",
    "                    target_file.close()\n",
    "\n",
    "                    del input_ids\n",
    "                    del sample\n",
    "                    del output\n",
    "                except:\n",
    "                    print('Could not compute '+str(i)+'_'+str(j)+' prompt.')\n",
    "                    #print(prompt) (trop long comme prompt)\n",
    "                    traceback.print_exc()\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "delta = time.time() - initial_time\n",
    "print('Done! Took', datetime.timedelta(seconds=int(delta)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=333555242f4e464ad2f1466233462741b2f13d4d85af3a6bfe866ca7f1f269f6\n",
      "  Stored in directory: /home/linagora/.cache/pip/wheels/3e/94/5c/7ff8a51c53c1bbc8df4cac58aa4990ffbc6fa203e9f0808fdd\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge, absl-py, rouge_score\n",
      "Successfully installed absl-py-1.4.0 rouge-1.0.1 rouge_score-0.1.2\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2.28.1)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: pandas in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: packaging in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (22.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, responses, datasets, evaluate\n",
      "Successfully installed datasets-2.13.1 evaluate-0.4.0 multiprocess-0.70.14 pyarrow-12.0.1 responses-0.18.0 xxhash-3.2.0\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from bert-score) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.5.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (22.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.31.0.dev0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2022.7)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.12.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.101)\n",
      "Requirement already satisfied: setuptools in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (16.0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score) (2022.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/linagora/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.0.0->bert-score) (1.2.1)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (2022.7.9)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: colorama in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\n",
      "Requirement already satisfied: lxml in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (4.9.1)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.7.0 sacrebleu-2.3.1\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score rouge\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "leprompt = \"\"\"In this conversation, Valérie Pécresse, Éric Zemmour, and the moderator discuss various economic proposals and reforms. The main topic of debate is Emmanuel Macron's proposal to raise the legal retirement age to sixty-five. Pécresse accuses Macron of previously mismanaging funds but now trying to replenish the pension system. Zemmour mocks the proposal, suggesting an even higher retirement age. \n",
    "\n",
    "The conversation moves on to other economic issues, with Pécresse criticizing Macron for not implementing necessary reforms during his presidency. She highlights the need for reforms in civil service positions, unemployment insurance, and the RSA (a social benefit program). Zemmour sarcastically suggests taking away benefits from foreigners as a courageous reform, to which Pécresse argues that foreigners represent only a small percentage of benefit recipients.\n",
    "\n",
    "The discussion returns to the retirement age, and the moderator asks Pécresse if she would implement a similar reform if she becomes president. Pécresse confirms her support for raising the retirement age to sixty-five but with exceptions for those who have had physically demanding careers. She also discusses her plans for unemployment insurance reform, reducing civil service positions, and increasing minimum pensions and widow's pensions.\n",
    "\n",
    "Zemmour challenges Pécresse's commitment to fundamental reforms, questioning her ability to follow through on promises. He believes that previous promises of reducing public staff have been empty words. Pécresse acknowledges the need for sector-specific hiring and job eliminations but emphasizes the importance of careful assessment and planning.\n",
    "\n",
    "The conversation briefly touches on decentralization and proposed budgetary savings, particularly related to non-European foreigners and fighting social fraud. Zemmour believes his program is fully funded through these measures, along with economic relief from charges and tax reductions. Pécresse dismisses these claims as empty promises and raises concerns about the funding of CSG (general social contribution) and hospitals in Zemmour's program.\n",
    "\n",
    "Pécresse argues that unannounced reforms are less likely to be implemented, citing Nicolas Sarkozy's job cut announcements and her own successful implementation of job cuts in her region. Zemmour responds by comparing Pécresse to Macron and implying that their policies are similar. Pécresse emphasizes the importance of economic power and the need for reforms to address the country's financial challenges.\n",
    "\n",
    "The conversation ends with Pécresse highlighting the increasing debt and the urgency of implementing reforms, while Zemmour maintains that reforms are unnecessary.\"\"\"\n",
    "\n",
    "\n",
    "Mafoi = tokenizer(leprompt, return_tensors=\"pt\").to('cuda') # ICI RESTRICTION sur prompt\n",
    "input_length = len(Mafoi['input_ids'][0])\n",
    "print(input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scores computation...\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d524aecf5224aec807f7d3f335027c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f721ce635a6048508c0654c74da3f44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 14839.71 seconds, 0.00 sentences/sec\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Method and variables\n",
    "# ==========================================================================================\n",
    "print('Starting scores computation...')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "STORAGE_FILE_NAME = 'scores'\n",
    "PREPROCESS_SUMMARIES = True\n",
    "\n",
    "# Script itself\n",
    "# ==========================================================================================\n",
    "\n",
    "# Find output file for CSV scores\n",
    "mkdir('output')\n",
    "mkdir('output/scores')\n",
    "storage_file = open('output/scores/'+ 'scores' + '.csv', 'w', encoding='utf-8')\n",
    "storage_file.write('path;rouge2;rougel;bertscore\\n')\n",
    "\n",
    "target_file_paths = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "# For each instruction\n",
    "for instruction_n in range(n_instructions):\n",
    "\n",
    "    # Read instruction and create prompt\n",
    "    instruction = instructions[instruction_n]\n",
    "    \n",
    "    # For each sample in dataset\n",
    "    for sample_n in range(n_samples):\n",
    "        \n",
    "        # Find target file\n",
    "        target_file_path = 'intermediate/' + DATASET_NAME + '/' + str(instruction_n + 1) + '_' + str(sample_n + 1) + '.txt'\n",
    "        if not os.path.isfile(target_file_path): # A MODIFIER : SI UN RESUME N'A PAS ETE GENERE\n",
    "            print('-- Found no intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "            continue\n",
    "        \n",
    "        # Read sample and generate prompt -> Keep summary\n",
    "        summary_file_path = 'input/' + DATASET_NAME + '/summaries/sample_' + str(sample_n + 1) + '.txt'\n",
    "        summary_file = open(summary_file_path, 'r', encoding='utf-8')\n",
    "        references.append(summary_file.read())\n",
    "        summary_file.close()\n",
    "\n",
    "        # Access generated summary\n",
    "        target_file = open(target_file_path, 'r', encoding='utf-8')\n",
    "        prediction = target_file.read()\n",
    "        target_file.close()\n",
    "\n",
    "        # Process answer\n",
    "        if PREPROCESS_SUMMARIES:\n",
    "            separator = \"### Assistant:\"\n",
    "            prediction = prediction[prediction.index(separator) + len(separator):]\n",
    "            if prediction[0] == \" \": # Enlever l'espace devant\n",
    "                prediction = prediction[1:]\n",
    "            prediction = prediction[:-len(\"<|endoftext|>\") - 2]\n",
    "            #print(prediction)\n",
    "            #print('---------------------------------------')\n",
    "        \n",
    "        # Add prediction\n",
    "        target_file_paths.append(target_file_path)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "result_rouge = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "#result_bleu = bleu.compute(predictions=predictions, references=references)\n",
    "result_bertscore = bertscore.compute(predictions=predictions, references=references, lang='fr', rescale_with_baseline=True, verbose=True)\n",
    "\n",
    "# Write to csv\n",
    "# Forget about BLEU...\n",
    "# Format: PATH | ROUGE2 | ROUGEL | (BLEU |) BERTScore\n",
    "for i in range(len(target_file_paths)):\n",
    "    ligne = target_file_paths[i]\n",
    "    ligne += ';' + str(result_rouge['rouge2'][i]) + \";\" + str(result_rouge['rougeL'][i])\n",
    "    #ligne += \";\" + str(result_bleu['bleu'])\n",
    "    ligne += \";\" + str(result_bertscore['f1'][i])\n",
    "\n",
    "    storage_file.write(ligne + '\\n')\n",
    "\n",
    "storage_file.close()\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
