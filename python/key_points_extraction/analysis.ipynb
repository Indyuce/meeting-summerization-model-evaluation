{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"results/4/scores1.csv\")\n",
    "df = pd.read_csv(\"results/4/scores.csv\")\n",
    "\n",
    "df1[\"consistency\"] = df[\"consistency\"]\n",
    "df1[\"description\"] = df[\"description\"]\n",
    "\n",
    "df1.to_csv('scores.csv', encoding='utf-8')\n",
    "\n",
    "#for i in range(len(df)):\n",
    "#    row = df.iloc[i]\n",
    "#    file = open(\"results/4/\" + row[\"input_path\"], 'r', encoding='utf-8')\n",
    "#    data = json.load(file)\n",
    "#    file.close()\n",
    "#    words = re.findall(r'\\b\\w+\\b', data[\"text\"])  # Find all word-like sequences using regular expression\n",
    "#    row[\"nb_words_generated\"] = len(words)\n",
    "\n",
    "#df.to_csv('scores.csv', encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_list = [1]*41\n",
    "description_list = [-1]*41\n",
    "specificities_consistency = {0:0, 2:0, 8:0, 9:0, 11:0, 13:0, 17:0, 19:0, 21:0, 25:0, 27:0, 28:0, 30:0, 37:0, 38:0, 39:0}\n",
    "specificities_description = {0:\"chinese\", 2:\"chinese\", 5:\"Key points per utterance\", 8:\"chinese\", 9:\"Repeats the conversation\", 11:\"chinese\", 13:\"full chinese text\", 17:\"full chinese text\", 19:\"full chinese text\", 21:\"full chinese text\", 25:\"full chinese text\", 27:\"full chinese text\", 28:\"takes back the discourse\", 30:\"takes back the discourse\", 37:\"full chinese text\", 38:\"Sort 2 mots\", 39:\"full chinese text\"}\n",
    "\n",
    "for key in specificities_consistency.keys():\n",
    "    consistency_list[key] = specificities_consistency[key]\n",
    "for key in specificities_description.keys():\n",
    "    description_list[key] = specificities_description[key]\n",
    "\n",
    "path_scores_file = \"results/\" + \"2\" + \"/scores.csv\"\n",
    "dfFINAL = pd.read_csv(path_scores_file)\n",
    "dfFINAL[\"consistency\"] = consistency_list\n",
    "dfFINAL[\"description\"] = description_list\n",
    "dfFINAL.to_csv('scores.csv', encoding='utf-8')\n",
    "#nb_batch = \"1\"\n",
    "#path_scoresINIT_file = \"results/\" + nb_batch + \"/scores.csv\"\n",
    "#path_scoresFINAL_file = \"results/\" + nb_batch + \"/scores4.csv\"\n",
    "#dfFINAL = pd.read_csv(path_scoresFINAL_file)\n",
    "#dfINIT = pd.read_csv(path_scoresINIT_file)\n",
    "#dfFINAL[\"consistency\"] = dfINIT[\"consistency\"]\n",
    "#dfFINAL[\"description\"] = dfINIT[\"description\"]\n",
    "#dfFINAL.to_csv('scores.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_list = [1]*25\n",
    "description_list = [-1]*25\n",
    "specificities_consistency = {3:0, 4:0, 9:0, 10:0, 12:0, 15:0, 16:0, 17:0, 19:0, 20:0, 23:0, 24:0}\n",
    "specificities_description = {2:\"Too long, takes back the text but with hallucinations\", 3:\"Repeats the text\", 4:\"Repeats the text\", 5:\"Très bon résumé\", 6:\"Statement en une ligne du modèle, pas compris l'instruction et dit n'imp\", 7:\"Beaucoup trop court, trop incomplet\", 8:\"Une phrase répétée 2 fois\", 9:\"Répétitions du texte\", 10:\"Répétitions du texte\", 15:\"Répétitions du texte\", 12:\"Répétitions du texte\", 16:\"Répétitions du texte\", 17:\"Répétitions du texte\", 19:\"Répétitions du texte\", 20:\"Répétitions du texte\", 23:\"Répétitions du texte\", 24:\"Répétitions du texte\"}\n",
    "\n",
    "for key in specificities_consistency.keys():\n",
    "    consistency_list[key] = specificities_consistency[key]\n",
    "for key in specificities_description.keys():\n",
    "    description_list[key] = specificities_description[key]\n",
    "\n",
    "path_scores_file = \"results/\" + \"3\" + \"/scores.csv\"\n",
    "dfFINAL = pd.read_csv(path_scores_file)\n",
    "dfFINAL[\"consistency\"] = consistency_list\n",
    "dfFINAL[\"description\"] = description_list\n",
    "dfFINAL.to_csv('scores.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGEN\n",
    "#### 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: This inference batch is aimed at testing XGen 8bit on summarization. We shall compare his performance on French and on English\n",
      "Le batch 1 contient 39/40 échantillons cohérents.\n",
      "Parmi les réponses écrites en français, 7/7 des questions sont écrites en français\n",
      "Parmi les réponses écrites en anglais, 20/32 des questions sont écrites en anglais\n",
      "\n",
      "Moyennes questions françaises, réponses françaises (7 échantillons):\n",
      "Rouge 2: 0.06477100407250354 ---- Rouge L: 0.15354240474238873 ---- BertScore: -0.001854958121839447\n",
      "\n",
      "Moyennes questions anglaises, réponses anglaises (20 échantillons):\n",
      "Rouge 2: 0.0938697219794203 ---- Rouge L: 0.1929056223867459 ---- BertScore: 0.24701896104961635\n",
      "\n",
      "Moyennes questions françaises, réponses anglaises (12 échantillons):\n",
      "Rouge 2: 0.04485129846821542 ---- Rouge L: 0.14029715907759835 ---- BertScore: 0.13658359218000743\n",
      "\n",
      "Taux de compression questions anglaises réponses anglaises: 0.3851305874064335\n",
      "Taux de compression questions françaises réponses anglaises: 0.7368235511257591\n",
      "Taux de compression questions françaises réponses françaises: 0.3189696962188044\n",
      "\n",
      "\n",
      "Batch 2: This inferenee batch is aimed at testing XGen on summarization. We shall compare his performance on French and on English\n",
      "Le batch 2 contient 25/41 échantillons cohérents.\n",
      "Parmi les réponses écrites en français, 5/5 des questions sont écrites en français\n",
      "Parmi les réponses écrites en anglais, 9/20 des questions sont écrites en anglais\n",
      "\n",
      "Moyennes questions françaises, réponses françaises (5 échantillons):\n",
      "Rouge 2: 0.055665765171895275 ---- Rouge L: 0.11554488533408172 ---- BertScore: -0.06662082597613335\n",
      "\n",
      "Moyennes questions anglaises, réponses anglaises (9 échantillons):\n",
      "Rouge 2: 0.11335563719438833 ---- Rouge L: 0.19999924497708865 ---- BertScore: 0.28210562384790844\n",
      "\n",
      "Moyennes questions françaises, réponses anglaises (11 échantillons):\n",
      "Rouge 2: 0.04972507123076217 ---- Rouge L: 0.1434353015020035 ---- BertScore: 0.14845114777033974\n",
      "\n",
      "Taux de compression questions anglaises réponses anglaises: 0.3898719152705461\n",
      "Taux de compression questions françaises réponses anglaises: 0.5390283374752893\n",
      "Taux de compression questions françaises réponses françaises: 0.44582327168141644\n",
      "\n",
      "\n",
      "Batch 0: This inference batch is aimed at testing this code. It helped debugging. it was performed with a 4bit quantized version of XGen 7B. One take away is that for 4 out of the 5 fredsum texts, there was too many tokens (above 1800)\n",
      "Le batch 0 contient 28/40 échantillons cohérents.\n",
      "Parmi les réponses écrites en français, 1/1 des questions sont écrites en français\n",
      "Parmi les réponses écrites en anglais, 16/27 des questions sont écrites en anglais\n",
      "\n",
      "Moyennes questions françaises, réponses françaises (1 échantillons):\n",
      "Rouge 2: 0.0574162679425837 ---- Rouge L: 0.0904761904761904 ---- BertScore: -0.0642949044704437\n",
      "\n",
      "Moyennes questions anglaises, réponses anglaises (16 échantillons):\n",
      "Rouge 2: 0.10337345389955058 ---- Rouge L: 0.19059100544868074 ---- BertScore: 0.2400263991439715\n",
      "\n",
      "Moyennes questions françaises, réponses anglaises (11 échantillons):\n",
      "Rouge 2: 0.06339291110835027 ---- Rouge L: 0.13676942533994166 ---- BertScore: 0.16332498328252268\n",
      "\n",
      "Taux de compression questions anglaises réponses anglaises: 0.38074562576774057\n",
      "Taux de compression questions françaises réponses anglaises: 0.7730682068955758\n",
      "Taux de compression questions françaises réponses françaises: 0.6304347826086957\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_en[\"compression_rate\"] = consistent_df_en_en[\"nb_words_generated\"] / consistent_df_en_en[\"nb_words_input\"]\n",
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_fr[\"compression_rate\"] = consistent_df_en_fr[\"nb_words_generated\"] / consistent_df_en_fr[\"nb_words_input\"]\n",
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_en[\"compression_rate\"] = consistent_df_en_en[\"nb_words_generated\"] / consistent_df_en_en[\"nb_words_input\"]\n",
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_fr[\"compression_rate\"] = consistent_df_en_fr[\"nb_words_generated\"] / consistent_df_en_fr[\"nb_words_input\"]\n",
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_en[\"compression_rate\"] = consistent_df_en_en[\"nb_words_generated\"] / consistent_df_en_en[\"nb_words_input\"]\n",
      "C:\\Users\\rayci\\AppData\\Local\\Temp\\ipykernel_88320\\2079108961.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  consistent_df_en_fr[\"compression_rate\"] = consistent_df_en_fr[\"nb_words_generated\"] / consistent_df_en_fr[\"nb_words_input\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batches = {'0', '1', '2'}\n",
    "\n",
    "for nb_batch in batches:\n",
    "    name_file = \"results/\" + nb_batch + \"/desc.txt\"\n",
    "    file = open(name_file, 'r', encoding='utf-8')\n",
    "    description = file.readline()\n",
    "    print(\"Batch \" + nb_batch + \": \" + description)\n",
    "    # Je souhaite obtenir le dataset des samples cohérents -> filtrage\n",
    "    path_scores_file = \"results/\" + nb_batch + \"/scores.csv\"\n",
    "    # Extract consistency and description\n",
    "    df = pd.read_csv(path_scores_file)\n",
    "    array = df.values\n",
    "\n",
    "    consistent_df = df[df[\"consistency\"]==1]\n",
    "\n",
    "    consistent_df_en = consistent_df[consistent_df[\"output_language\"]==1]\n",
    "    consistent_df_en_en = consistent_df_en[consistent_df_en[\"input_language\"]==1]\n",
    "\n",
    "    consistent_df_en_fr = consistent_df_en[consistent_df_en[\"input_language\"]==0] # Réponses anglaises à une question française\n",
    "\n",
    "    consistent_df_fr = consistent_df[consistent_df[\"output_language\"]==0]\n",
    "    consistent_df_fr_fr = consistent_df_fr[consistent_df_fr[\"input_language\"]==0]\n",
    "\n",
    "    print(\"Le batch \" + nb_batch + \" contient \" + str(len(consistent_df)) + \"/\" + str(len(df)) + \" échantillons cohérents.\")\n",
    "    print(\"Parmi les réponses écrites en français, \" + str(len(consistent_df_fr_fr)) + \"/\" + str(len(consistent_df_fr)) + \" des questions sont écrites en français\")\n",
    "    print(\"Parmi les réponses écrites en anglais, \" + str(len(consistent_df_en_en)) + \"/\" + str(len(consistent_df_en)) + \" des questions sont écrites en anglais\")\n",
    "    print()\n",
    "\n",
    "    rouge2_en_fr = consistent_df_en_fr['rouge2'].mean()\n",
    "    rougel_en_fr = consistent_df_en_fr['rougel'].mean()\n",
    "    bert_en_fr = consistent_df_en_fr['bertscore'].mean()\n",
    "\n",
    "    rouge2_fr_fr = consistent_df_fr_fr['rouge2'].mean()\n",
    "    rougel_fr_fr = consistent_df_fr_fr['rougel'].mean()\n",
    "    bert_fr_fr = consistent_df_fr_fr['bertscore'].mean()\n",
    "\n",
    "    rouge2_en_en = consistent_df_en_en['rouge2'].mean()\n",
    "    rougel_en_en = consistent_df_en_en['rougel'].mean()\n",
    "    bert_en_en = consistent_df_en_en['bertscore'].mean()\n",
    "\n",
    "    print(\"Moyennes questions françaises, réponses françaises (\" + str(len(consistent_df_fr_fr)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_fr_fr) + \" ---- Rouge L: \" + str(rougel_fr_fr) + \" ---- BertScore: \" + str(bert_fr_fr))\n",
    "    print()\n",
    "    print(\"Moyennes questions anglaises, réponses anglaises (\" + str(len(consistent_df_en_en)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_en_en) + \" ---- Rouge L: \" + str(rougel_en_en) + \" ---- BertScore: \" + str(bert_en_en))\n",
    "    print()\n",
    "    print(\"Moyennes questions françaises, réponses anglaises (\" + str(len(consistent_df_en_fr)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_en_fr) + \" ---- Rouge L: \" + str(rougel_en_fr) + \" ---- BertScore: \" + str(bert_en_fr))\n",
    "    print()\n",
    "\n",
    "    consistent_df_en_en[\"compression_rate\"] = consistent_df_en_en[\"nb_words_generated\"] / consistent_df_en_en[\"nb_words_input\"]\n",
    "    consistent_df_en_fr[\"compression_rate\"] = consistent_df_en_fr[\"nb_words_generated\"] / consistent_df_en_fr[\"nb_words_input\"]\n",
    "    consistent_df_fr_fr[\"compression_rate\"] = consistent_df_fr_fr[\"nb_words_generated\"] / consistent_df_fr_fr[\"nb_words_input\"]\n",
    "    compression_rate_en_en = consistent_df_en_en[\"compression_rate\"].mean()\n",
    "    compression_rate_en_fr = consistent_df_en_fr[\"compression_rate\"].mean()\n",
    "    compression_rate_fr_fr = consistent_df_fr_fr[\"compression_rate\"].mean()\n",
    "\n",
    "    print(\"Taux de compression questions anglaises réponses anglaises: \" + str(compression_rate_en_en))\n",
    "    print(\"Taux de compression questions françaises réponses anglaises: \" + str(compression_rate_en_fr))\n",
    "    print(\"Taux de compression questions françaises réponses françaises: \" + str(compression_rate_fr_fr))\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    # Grosse tendance à écrire en anglais. Et c'est normal, le header de finetuning est en anglais... Les tâches de finetuning ne sont pas multilingues !\n",
    "    # Du coup, problème lors du calcul des scores: calculs sur du gold fr et du generated en. De plus, problème plus général sur les métriques, un bertscore français est différent d'un bertscore anglais, pas comparable et la moyenne du rouge score entre deux textes randoms en langue anglais et française est probablement différente... Limites de ces mesures. Justifie l'analyse qualitative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Batch n°4 =====\n",
      "This inference batch is aimed at testing Llama 2 chat on summarization. There is no French summarization at all.\n",
      "\n",
      "--- Cohérence ---\n",
      "Nombre de réponses cohérentes: 22/25\n",
      "Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\n",
      "  * samsum : 4/5 réponses cohérentes.\n",
      "  * fredsum : 5/5 réponses cohérentes.\n",
      "  * xsum : 5/5 réponses cohérentes.\n",
      "  * mediasum : 5/5 réponses cohérentes.\n",
      "  * dialogsum : 3/5 réponses cohérentes.\n",
      "\n",
      "--- Métriques ---\n",
      "Moyenne des métriques sur les données cohérentes:\n",
      " - bertscore : 0.22819629311561582      (moyenne sur les données non cohérentes: 0.21816766828298564)\n",
      " - rouge2 : 0.09702697170780832      (moyenne sur les données non cohérentes: 0.09284349835794554)\n",
      " - rougel : 0.1830404136983603      (moyenne sur les données non cohérentes: 0.18044059901959206)\n",
      "\n",
      "Par corpus:\n",
      "  *** samsum ***\n",
      " - bertscore : 0.2265312910079956       (moyenne sur 4/5 échantillons)\n",
      " - rouge2 : 0.1075007523575792       (moyenne sur 4/5 échantillons)\n",
      " - rougel : 0.1988513172825444       (moyenne sur 4/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.6079470198675496       Rapport taille du gold sur taille du généré: 0.30718954248366015\n",
      "\n",
      "  *** fredsum ***\n",
      " - bertscore : 0.2582384556531906       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.12605372809656873       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.21843854967899007       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.3800999167360533       Rapport taille du gold sur taille du généré: 0.4129244249726178\n",
      "\n",
      "  *** xsum ***\n",
      " - bertscore : 0.17987040281295774       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.044450932582190114       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.12481975482267345       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.3337819650067295       Rapport taille du gold sur taille du généré: 0.1935483870967742\n",
      "\n",
      "  *** mediasum ***\n",
      " - bertscore : 0.16888247728347777       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.07126382594297624       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.14884925342220715       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.4460278956943602       Rapport taille du gold sur taille du généré: 0.20054384772263767\n",
      "\n",
      "  *** dialogsum ***\n",
      " - bertscore : 0.2573157146573066       (moyenne sur 3/5 échantillons)\n",
      " - rouge2 : 0.1149482528104134       (moyenne sur 3/5 échantillons)\n",
      " - rougel : 0.21124411989154498       (moyenne sur 3/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.7911318553092181       Rapport taille du gold sur taille du généré: 0.1415929203539823\n",
      "\n",
      "\n",
      "===== Batch n°3 =====\n",
      "This inference batch is aimed at testing MPT7B on summarization. There is no French summarization at all.\n",
      "\n",
      "--- Cohérence ---\n",
      "Nombre de réponses cohérentes: 13/25\n",
      "Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\n",
      "  * samsum : 1/5 réponses cohérentes.\n",
      "  * fredsum : 4/5 réponses cohérentes.\n",
      "  * xsum : 2/5 réponses cohérentes.\n",
      "  * mediasum : 3/5 réponses cohérentes.\n",
      "  * dialogsum : 3/5 réponses cohérentes.\n",
      "\n",
      "--- Métriques ---\n",
      "Moyenne des métriques sur les données cohérentes:\n",
      " - bertscore : 0.16584586488226286      (moyenne sur les données non cohérentes: 0.12781221078243107)\n",
      " - rouge2 : 0.060541818448925595      (moyenne sur les données non cohérentes: 0.06465480896413361)\n",
      " - rougel : 0.16737172038941864      (moyenne sur les données non cohérentes: 0.1489117193761551)\n",
      "\n",
      "Par corpus:\n",
      "  *** samsum ***\n",
      " - bertscore : 0.10428314607124774       (moyenne sur 1/5 échantillons)\n",
      " - rouge2 : 0.07637952610264342       (moyenne sur 1/5 échantillons)\n",
      " - rougel : 0.17356554262262985       (moyenne sur 1/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.6711111111111111       Rapport taille du gold sur taille du généré: 0.2847682119205298\n",
      "\n",
      "  *** fredsum ***\n",
      " - bertscore : 0.09614156540483233       (moyenne sur 4/5 échantillons)\n",
      " - rouge2 : 0.06756395832852072       (moyenne sur 4/5 échantillons)\n",
      " - rougel : 0.1617952820895177       (moyenne sur 4/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.06183574879227053       Rapport taille du gold sur taille du généré: 2.55859375\n",
      "\n",
      "  *** xsum ***\n",
      " - bertscore : 0.15681952238082886       (moyenne sur 2/5 échantillons)\n",
      " - rouge2 : 0.049940044306241424       (moyenne sur 2/5 échantillons)\n",
      " - rougel : 0.11615135684420527       (moyenne sur 2/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.17647058823529413       Rapport taille du gold sur taille du généré: 0.29901960784313725\n",
      "\n",
      "  *** mediasum ***\n",
      " - bertscore : 0.1019551046192646       (moyenne sur 3/5 échantillons)\n",
      " - rouge2 : 0.05708309633070143       (moyenne sur 3/5 échantillons)\n",
      " - rougel : 0.13158128847031145       (moyenne sur 3/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.1739343459088682       Rapport taille du gold sur taille du généré: 0.4929577464788733\n",
      "\n",
      "  *** dialogsum ***\n",
      " - bertscore : 0.17986171543598176       (moyenne sur 3/5 échantillons)\n",
      " - rouge2 : 0.07230741975256108       (moyenne sur 3/5 échantillons)\n",
      " - rougel : 0.16146512685411124       (moyenne sur 3/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.5520421607378129       Rapport taille du gold sur taille du généré: 0.19093078758949883\n",
      "\n",
      "\n",
      "===== Batch n°0 =====\n",
      "This inference batch is aimed at testing this code. It helped debugging. it was performed with a 4bit quantized version of XGen 7B. One take away is that for 4 out of the 5 fredsum texts, there was too many tokens (above 1800)\n",
      "\n",
      "--- Cohérence ---\n",
      "Nombre de réponses cohérentes: 16/20\n",
      "Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\n",
      "  * samsum : 4/5 réponses cohérentes.\n",
      "  * fredsum : 5/5 réponses cohérentes.\n",
      "  * xsum : 5/5 réponses cohérentes.\n",
      "  * mediasum : 0/0 réponses cohérentes.\n",
      "  * dialogsum : 2/5 réponses cohérentes.\n",
      "\n",
      "--- Métriques ---\n",
      "Moyenne des métriques sur les données cohérentes:\n",
      " - bertscore : 0.2400263991439715      (moyenne sur les données non cohérentes: 0.19889409290626645)\n",
      " - rouge2 : 0.10337345389955058      (moyenne sur les données non cohérentes: 0.09591926739941928)\n",
      " - rougel : 0.19059100544868074      (moyenne sur les données non cohérentes: 0.17911801732270216)\n",
      "\n",
      "Par corpus:\n",
      "  *** samsum ***\n",
      " - bertscore : 0.24557315111160277       (moyenne sur 4/5 échantillons)\n",
      " - rouge2 : 0.12139306430791671       (moyenne sur 4/5 échantillons)\n",
      " - rougel : 0.20579521289870722       (moyenne sur 4/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.45026881720430106       Rapport taille du gold sur taille du généré: 0.43283582089552236\n",
      "\n",
      "  *** fredsum ***\n",
      " - bertscore : 0.2634072661399841       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.1286817736771608       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.22654506986490786       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.14196502914238135       Rapport taille du gold sur taille du généré: 0.8563049853372433\n",
      "\n",
      "  *** xsum ***\n",
      " - bertscore : 0.17052976675331588       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.04697053347880063       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.13253569720635588       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.3086585912965455       Rapport taille du gold sur taille du généré: 0.20930232558139536\n",
      "\n",
      "  *** mediasum ***\n",
      " - bertscore : nan       (moyenne sur 0/0 échantillons)\n",
      " - rouge2 : nan       (moyenne sur 0/0 échantillons)\n",
      " - rougel : nan       (moyenne sur 0/0 échantillons)\n",
      "    Taux de compression moyen sur le corpus: nan       Rapport taille du gold sur taille du généré: nan\n",
      "\n",
      "  *** dialogsum ***\n",
      " - bertscore : 0.11606618762016292       (moyenne sur 2/5 échantillons)\n",
      " - rouge2 : 0.08663169813379897       (moyenne sur 2/5 échantillons)\n",
      " - rougel : 0.15159608932083762       (moyenne sur 2/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.4169811320754717       Rapport taille du gold sur taille du généré: 0.28054298642533937\n",
      "\n",
      "\n",
      "===== Batch n°1 =====\n",
      "This inference batch is aimed at testing XGen 8bit on summarization. We shall compare his performance on French and on English\n",
      "\n",
      "--- Cohérence ---\n",
      "Nombre de réponses cohérentes: 20/20\n",
      "Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\n",
      "  * samsum : 5/5 réponses cohérentes.\n",
      "  * fredsum : 0/0 réponses cohérentes.\n",
      "  * xsum : 5/5 réponses cohérentes.\n",
      "  * mediasum : 5/5 réponses cohérentes.\n",
      "  * dialogsum : 5/5 réponses cohérentes.\n",
      "\n",
      "--- Métriques ---\n",
      "Moyenne des métriques sur les données cohérentes:\n",
      " - bertscore : 0.24701896104961635      (moyenne sur les données non cohérentes: 0.24701896104961635)\n",
      " - rouge2 : 0.0938697219794203      (moyenne sur les données non cohérentes: 0.0938697219794203)\n",
      " - rougel : 0.1929056223867459      (moyenne sur les données non cohérentes: 0.1929056223867459)\n",
      "\n",
      "Par corpus:\n",
      "  *** samsum ***\n",
      " - bertscore : 0.29256742596626284       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.1218644437664977       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.21453316704218106       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.5118679050567595       Rapport taille du gold sur taille du généré: 0.3790322580645161\n",
      "\n",
      "  *** fredsum ***\n",
      " - bertscore : nan       (moyenne sur 0/0 échantillons)\n",
      " - rouge2 : nan       (moyenne sur 0/0 échantillons)\n",
      " - rougel : nan       (moyenne sur 0/0 échantillons)\n",
      "    Taux de compression moyen sur le corpus: nan       Rapport taille du gold sur taille du généré: nan\n",
      "\n",
      "  *** xsum ***\n",
      " - bertscore : 0.20141179859638214       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.05796099152629759       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.17592222833407986       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.24450426200089725       Rapport taille du gold sur taille du généré: 0.26422018348623855\n",
      "\n",
      "  *** mediasum ***\n",
      " - bertscore : 0.17691542580723757       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.06877839963834839       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.16383553886125685       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.17707701637355971       Rapport taille du gold sur taille du généré: 0.5051369863013698\n",
      "\n",
      "  *** dialogsum ***\n",
      " - bertscore : 0.3171811938285828       (moyenne sur 5/5 échantillons)\n",
      " - rouge2 : 0.12687505298653748       (moyenne sur 5/5 échantillons)\n",
      " - rougel : 0.21733155530946574       (moyenne sur 5/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.41217798594847777       Rapport taille du gold sur taille du généré: 0.27651515151515155\n",
      "\n",
      "\n",
      "===== Batch n°2 =====\n",
      "This inferenee batch is aimed at testing XGen on summarization. We shall compare his performance on French and on English\n",
      "\n",
      "--- Cohérence ---\n",
      "Nombre de réponses cohérentes: 9/21\n",
      "Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\n",
      "  * samsum : 2/5 réponses cohérentes.\n",
      "  * fredsum : 1/1 réponses cohérentes.\n",
      "  * xsum : 3/5 réponses cohérentes.\n",
      "  * mediasum : 1/5 réponses cohérentes.\n",
      "  * dialogsum : 2/5 réponses cohérentes.\n",
      "\n",
      "--- Métriques ---\n",
      "Moyenne des métriques sur les données cohérentes:\n",
      " - bertscore : 0.28210562384790844      (moyenne sur les données non cohérentes: -0.17057885690813973)\n",
      " - rouge2 : 0.11335563719438833      (moyenne sur les données non cohérentes: 0.04951469418508333)\n",
      " - rougel : 0.19999924497708865      (moyenne sur les données non cohérentes: 0.09905647915052437)\n",
      "\n",
      "Par corpus:\n",
      "  *** samsum ***\n",
      " - bertscore : -0.2398363918066025       (moyenne sur 2/5 échantillons)\n",
      " - rouge2 : 0.027472365512159157       (moyenne sur 2/5 échantillons)\n",
      " - rougel : 0.10612679865844421       (moyenne sur 2/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.410958904109589       Rapport taille du gold sur taille du généré: 0.31666666666666665\n",
      "\n",
      "  *** fredsum ***\n",
      " - bertscore : 0.3726310729980469       (moyenne sur 1/1 échantillons)\n",
      " - rouge2 : 0.1908127208480565       (moyenne sur 1/1 échantillons)\n",
      " - rougel : 0.2456140350877192       (moyenne sur 1/1 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.1141552511415525       Rapport taille du gold sur taille du généré: 1.264\n",
      "\n",
      "  *** xsum ***\n",
      " - bertscore : -0.11018482893705368       (moyenne sur 3/5 échantillons)\n",
      " - rouge2 : 0.04145761600262336       (moyenne sur 3/5 échantillons)\n",
      " - rougel : 0.10947880626708603       (moyenne sur 3/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.170844327176781       Rapport taille du gold sur taille du généré: 0.33976833976833976\n",
      "\n",
      "  *** mediasum ***\n",
      " - bertscore : -0.43636366724967957       (moyenne sur 1/5 échantillons)\n",
      " - rouge2 : 0.0442885411045152       (moyenne sur 1/5 échantillons)\n",
      " - rougel : 0.062237762237762215       (moyenne sur 1/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.24060150375939848       Rapport taille du gold sur taille du généré: 0.71875\n",
      "\n",
      "  *** dialogsum ***\n",
      " - bertscore : -0.0045725256204605215       (moyenne sur 2/5 échantillons)\n",
      " - rouge2 : 0.056580648788440976       (moyenne sur 2/5 échantillons)\n",
      " - rougel : 0.08907103825136611       (moyenne sur 2/5 échantillons)\n",
      "    Taux de compression moyen sur le corpus: 0.4037735849056604       Rapport taille du gold sur taille du généré: 0.27102803738317754\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpora = {'dialogsum', 'fredsum', 'mediasum', 'xsum', 'samsum'}\n",
    "scores = {'rouge2', 'rougel', 'bertscore'}\n",
    "def identify_datasets(s):\n",
    "    for corpus in corpora:\n",
    "        if s.find(corpus)!=-1:\n",
    "            return corpus\n",
    "    return None\n",
    "\n",
    "batches = {'0', '1', '2', '3', '4'}\n",
    "\n",
    "for nb_batch in batches:\n",
    "    print(\"===== Batch n°\" + nb_batch + \" =====\")\n",
    "    name_file = \"results/\" + nb_batch + \"/desc.txt\"\n",
    "    file = open(name_file, 'r', encoding='utf-8')\n",
    "    description = file.readline()\n",
    "    print(description)\n",
    "    print()\n",
    "    # Je souhaite obtenir le dataset des samples cohérents -> filtrage\n",
    "    path_scores_file = \"results/\" + nb_batch + \"/scores.csv\"\n",
    "    # Extract english data\n",
    "    df = pd.read_csv(path_scores_file)\n",
    "    df = df[df[\"input_language\"] == 1] # We extract English only\n",
    "    array = df.values\n",
    "    # Consistency information\n",
    "    consistent_df = df[df[\"consistency\"]==1]\n",
    "    print(\"--- Cohérence ---\")\n",
    "    print(\"Nombre de réponses cohérentes: \" + str(len(consistent_df)) + \"/\" + str(len(df)))\n",
    "    print(\"Par dataset:                       (cela comprend aussi les générations qui ont échoué, notamment avec fredsum sur XGen)\")\n",
    "    per_corpus = {}\n",
    "    consistent_per_corpus = {}\n",
    "    for corpus in corpora:\n",
    "        per_corpus[corpus] = df[df[\"dataset\"]==corpus]\n",
    "        consistent_per_corpus[corpus] = consistent_df[consistent_df[\"dataset\"]==corpus]\n",
    "        print(\"  * \" + corpus + \" : \" + str(len(consistent_per_corpus[corpus])) + \"/\" + str(len(per_corpus[corpus])) + \" réponses cohérentes.\")\n",
    "    print()\n",
    "    print(\"--- Métriques ---\")\n",
    "    print(\"Moyenne des métriques sur les données cohérentes:\")\n",
    "    for score in scores:\n",
    "        print(\" - \" + score + \" : \" + str(consistent_df[score].mean()) + \"      (moyenne sur les données non cohérentes: \" + str(df[score].mean()) + \")\" )\n",
    "    print()\n",
    "    print(\"Par corpus:\")\n",
    "    for corpus in corpora:\n",
    "        print(\"  *** \" + corpus + \" ***\")\n",
    "        for score in scores:\n",
    "            print(\" - \" + score + \" : \" +str(per_corpus[corpus][score].mean()) + \"       (moyenne sur \" + str(len(consistent_per_corpus[corpus])) + \"/\" + str(len(per_corpus[corpus])) + \" échantillons)\")\n",
    "        print(\"    Taux de compression moyen sur le corpus: \" + str(consistent_per_corpus[corpus][\"nb_words_generated\"].mean()/consistent_per_corpus[corpus][\"nb_words_input\"].mean()) + \"       Rapport taille du gold sur taille du généré: \" + str(consistent_per_corpus[corpus][\"nb_words_gold\"].mean()/consistent_per_corpus[corpus][\"nb_words_generated\"].mean()))\n",
    "        print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = {'0', '1', '2', '3', '4'}\n",
    "\n",
    "for nb_batch in batches:\n",
    "    df = pd.read_csv(\"results/\" + nb_batch + \"/scores.csv\")\n",
    "    dataset_column = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        dataset_column.append(identify_datasets(row[\"input_path\"]))\n",
    "    df[\"dataset\"] = dataset_column\n",
    "    df.to_csv(\"scores\" + nb_batch + \".csv\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                               24\n",
      "input_path            samsum_3_text_en.json\n",
      "rouge2                             0.236364\n",
      "rougel                             0.267857\n",
      "bertscore                          0.430125\n",
      "nb_words_input                           92\n",
      "nb_words_gold                            41\n",
      "nb_words_generated                       71\n",
      "success                                   1\n",
      "over_context                              0\n",
      "output_language                           1\n",
      "input_language                            1\n",
      "consistency                               1\n",
      "description                              -1\n",
      "Name: 24, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/0/scores.csv')\n",
    "print(df.iloc[24])\n",
    "\n",
    "for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        consistent_count[identify_datasets(row[\"input_path\"])] +=1\n",
    "    for corpus in consistent_count:\n",
    "        print(\" - \" + corpus + \" - Nombre de réponses cohérentes: \" + str(consistent_count[corpus]) + \"/5\")\n",
    "    print()\n",
    "    # Metrics\n",
    "    print(\"Moyennes des métriques sur le corpus entier\")\n",
    "    \n",
    "    results = {\"total\":{}, \"consistent_total\":{}, \"consistent_per_corpus\":{corpus:{} for corpus in corpora}, \"per_corpus\":{corpus:{} for corpus in corpora}}\n",
    "    for score in scores:\n",
    "        results[\"total\"][score] = df[score].mean()\n",
    "        results[\"consistent_total\"][score] = consistent_df[score].mean()\n",
    "        print(\" - \" + score + \" moyen: \" + str(results[\"total\"][score]))\n",
    "    print()\n",
    "    # Per corpus\n",
    "    print(\"--- Par dataset ---\")\n",
    "    consistent_per_corpus = {corpus:consistent_df[identify_datasets(consistent_df[\"input_path\"]) == corpus] for corpus in corpora}\n",
    "    df_per_corpus = {corpus:df[identify_datasets(df[\"input_path\"]) == corpus] for corpus in corpora}\n",
    "    print(\"Moyennes des métriques par dataset entier\")\n",
    "\n",
    "    for corpus in corpora:\n",
    "        print(\" - \" + corpus + \":\")\n",
    "        for score in scores:\n",
    "            results[\"per_corpus\"][corpus][score] = df_per_corpus[corpus][score].mean()\n",
    "            results[\"consistent_per_corpus\"][corpus][score] = consistent_per_corpus[corpus][score].mean()\n",
    "            print(\"   * \" + score + \": \" + str(results[\"per_corpus\"][corpus][score]))\n",
    "            \n",
    "    print(\"Moyennes des métriques par dataset pour les réponses cohérentes\")\n",
    "    \n",
    "    # Et c'est normal, le header de finetuning est en anglais... Les tâches de finetuning ne sont pas multilingues !\n",
    "    # Du coup, problème lors du calcul des scores: calculs sur du gold fr et du generated en. De plus, problème plus général sur les métriques, un bertscore français est différent d'un bertscore anglais, pas comparable et la moyenne du rouge score entre deux textes randoms en langue anglais et française est probablement différente... Limites de ces mesures. Justifie l'analyse qualitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge2_en_fr = consistent_df_en_fr['rouge2'].mean()\n",
    "    rougel_en_fr = consistent_df_en_fr['rougel'].mean()\n",
    "    bert_en_fr = consistent_df_en_fr['bertscore'].mean()\n",
    "\n",
    "    rouge2_fr_fr = consistent_df_fr_fr['rouge2'].mean()\n",
    "    rougel_fr_fr = consistent_df_fr_fr['rougel'].mean()\n",
    "    bert_fr_fr = consistent_df_fr_fr['bertscore'].mean()\n",
    "\n",
    "    rouge2_en_en = consistent_df_en_en['rouge2'].mean()\n",
    "    rougel_en_en = consistent_df_en_en['rougel'].mean()\n",
    "    bert_en_en = consistent_df_en_en['bertscore'].mean()\n",
    "\n",
    "    print(\"Moyennes questions françaises, réponses françaises (\" + str(len(consistent_df_fr_fr)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_fr_fr) + \" ---- Rouge L: \" + str(rougel_fr_fr) + \" ---- BertScore: \" + str(bert_fr_fr))\n",
    "    print()\n",
    "    print(\"Moyennes questions anglaises, réponses anglaises (\" + str(len(consistent_df_en_en)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_en_en) + \" ---- Rouge L: \" + str(rougel_en_en) + \" ---- BertScore: \" + str(bert_en_en))\n",
    "    print()\n",
    "    print(\"Moyennes questions françaises, réponses anglaises (\" + str(len(consistent_df_en_fr)) + \" échantillons):\")\n",
    "    print(\"Rouge 2: \" + str(rouge2_en_fr) + \" ---- Rouge L: \" + str(rougel_en_fr) + \" ---- BertScore: \" + str(bert_en_fr))\n",
    "    print()\n",
    "\n",
    "    consistent_df_en_en[\"compression_rate\"] = consistent_df_en_en[\"nb_words_generated\"] / consistent_df_en_en[\"nb_words_input\"]\n",
    "    consistent_df_en_fr[\"compression_rate\"] = consistent_df_en_fr[\"nb_words_generated\"] / consistent_df_en_fr[\"nb_words_input\"]\n",
    "    consistent_df_fr_fr[\"compression_rate\"] = consistent_df_fr_fr[\"nb_words_generated\"] / consistent_df_fr_fr[\"nb_words_input\"]\n",
    "    compression_rate_en_en = consistent_df_en_en[\"compression_rate\"].mean()\n",
    "    compression_rate_en_fr = consistent_df_en_fr[\"compression_rate\"].mean()\n",
    "    compression_rate_fr_fr = consistent_df_fr_fr[\"compression_rate\"].mean()\n",
    "\n",
    "    print(\"Taux de compression questions anglaises réponses anglaises: \" + str(compression_rate_en_en))\n",
    "    print(\"Taux de compression questions françaises réponses anglaises: \" + str(compression_rate_en_fr))\n",
    "    print(\"Taux de compression questions françaises réponses françaises: \" + str(compression_rate_fr_fr))\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    # Grosse tendance à écrire en anglais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
