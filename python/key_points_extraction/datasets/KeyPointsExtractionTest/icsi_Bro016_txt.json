E: Let 's see .
E: Test ?
E: Test ?
E: Yeah .
E: OK .
B: Channel one .
A: Hello ?
A: Hello ?
C: Test .
E: I was saying Hynek 'll be here next week ,
E: uh , Wednesday through Friday <disfmarker>
E: uh , through Saturday ,
E: and , um ,
E: I won't be here Thursday and Friday .
E: But my suggestion is that , uh , at least for this meeting , people should go ahead ,
E: uh , cuz Hynek will be here ,
E: and ,
E: you know , we don't have any Czech accent yet ,
E: uh , <vocalsound> as far as I know ,
E: so <disfmarker>
F: OK .
E: There we go .
E: Um .
E: So other than reading digits , what 's our agenda ?
F: I don't really have , uh , anything new .
F: Been working on <pause> Meeting Recorder stuff .
F: So .
E: OK .
E: Um .
E: Do you think that would be the case for next week also ?
E: Or is <disfmarker> is , uh <disfmarker> ?
E: What 's your projection on <disfmarker> ?
F: Um .
E: Cuz the one thing <disfmarker> the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me <disfmarker>
E: it was sort of an obvious thing <disfmarker>
E: is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .
F: I did play with that , actually , a little bit .
F: Um . What happens is , uh , <vocalsound> when you get to the noisy stuff , you start getting lots of insertions .
E: Right .
F: And , um ,
F: so I 've tried playing around a little bit with , um , the insertion penalties and things like that .
E: Yeah .
F: Um .
F: I mean , it <disfmarker> it didn't make a whole lot of difference .
F: Like for the well - matched case , it seemed like it was pretty good .
F: Um . <vocalsound> I could do more playing with that , though .
F: And , uh <disfmarker>
F: and see .
E: But you were looking at mel cepstrum .
F: Yes .
E: Right .
F: Oh , you 're talking about for th <vocalsound> for our features .
E: Right .
E: So , I mean , i it it 's not the direction that you were working with that we were saying what 's the <disfmarker> uh , what 's the best you can do with <disfmarker> with mel cepstrum .
F: Mmm .
E: But , they raised a very valid point ,
E: which , I guess <disfmarker>
E: So , to first order <disfmarker> I mean , you have other things you were gonna do ,
E: but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @ <comment> with , uh , you know , how many states and so forth , that it <disfmarker> it doesn't particularly improve the performance .
E: In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad .
E: Right ?
E: And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,
F: Right .
E: but , um ,
E: let 's just <disfmarker>
E: If we had to <disfmarker> if we had to draw a conclusion on the information we have so far , we 'd say something like that .
E: Right ?
F: Mm - hmm .
E: Uh , so the next question to ask , which is I think the one that <disfmarker> that <disfmarker> that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end ,
E: but anybody using the system would .
F: Yeah .
E: So ,
E: if you were just adjusting the back - end , how much better would you do , uh , in noise ?
E: Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .
F: Mm - hmm .
E: But , um , they 're probably not at all set right for these things ,
E: particularly these things that look over , uh , larger time windows , in one way or another with <disfmarker> with LDA and KLT and neural nets and <vocalsound> all these things .
E: In the fa past we 've always found that we had to increase the insertion penalty to <disfmarker> to correspond to such things .
E: So ,
E: I think that 's , uh , @ @ <comment> that 's kind of a first - order thing that <disfmarker> that we should try .
F: So for th
F: so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth ,
F: and then tweak that a little bit
F: and see how much of a difference it makes
E: So by " our front - end " I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .
F: if we were <disfmarker>
F: Mm - hmm .
E: Um .
E: I mean , y don't wanna do this over a hundred different things that they 've tried
E: but , you know , for some version that you say is a good one .
E: You know ?
E: Um .
E: How <disfmarker> how much , uh , does it improve if you actually adjust that ?
F: OK .
E: But it is interesting .
E: You say you <disfmarker> you have for the noisy <disfmarker>
E: How about for the <disfmarker> for the mismatched or <disfmarker> or <disfmarker> or <disfmarker> or the <disfmarker> or the medium mismatched conditions ?
E: Have you <disfmarker> ?
E: When you adjusted those numbers for mel cepstrum , did it <disfmarker> ?
F: Uh , I <disfmarker> I don't remember off the top of my head .
F: Um .
F: Yeah . I didn't even write them down .
F: I <disfmarker> I <disfmarker> I don't remember .
F: I would need to <disfmarker>
F: Well , I did write down ,
F: um <disfmarker>
F: So , when I was doing <disfmarker> I just wrote down some numbers for the well - matched case .
E: Yeah .
F: Um .
F: Looking at the <disfmarker> I wrote down what the deletions , substitutions , and insertions were ,
F: uh ,
F: for different numbers of states per phone .
E: Yeah .
F: Um , but , uh , that <disfmarker> that 's all I wrote down .
E: OK .
F: So .
F: I <disfmarker> I would <disfmarker>
F: Yeah .
F: I would need to do that .
E: OK .
E: So <disfmarker>
F: I can do that for next week .
E: Yeah .
E: And , um <disfmarker>
E: Yeah .
E: Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it
E: and you can supervise or something .
E: But <disfmarker>
E: but I think it would be <disfmarker> it 'd be good to know that .
F: OK .
F: I just need to get , um , <vocalsound> front - end , uh , stuff from you
B: Hmm .
F: or you point me to some files <pause> that you 've already calculated .
B: Yeah .
B: Alright .
E: OK .
E: Uh .
F: I probably will have time to do that and time to play a little bit with the silence model .
E: Mm - hmm .
F: So maybe I can have that for next week when Hynek 's here .
E: Yeah .
B: Mm - hmm .
E: Yeah .
E: Cuz , I mean , the <disfmarker> the other <disfmarker>
E: That , in fact , might have been part of what , uh , the difference was <disfmarker>
E: at least part of it that <disfmarker> that we were seeing .
E: Remember we were seeing the SRI system was so much better than the tandem system .
F: Hmm .
E: Part of it might just be that the SRI system , they <disfmarker> they <disfmarker> they always adjust these things to be sort of optimized ,
F: Is there <disfmarker> ?
E: and <disfmarker>
F: I wonder if there 's anything that we could do <vocalsound> to the front - end that would affect the insertion <disfmarker>
E: Yes .
E: I think you can .
F: What could you do ?
E: Well , um <disfmarker>
E: uh ,
E: part of what 's going on , um , is the , uh , the range of values .
E: So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .
F: Oh .
F: Mm - hmm .
E: You know ?
E: If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort .
E: If it 's like seven probabilities together , you can take the seventh root of it or something ,
E: or if it 's in the log domain , divide it by seven .
F: Mm - hmm .
E: But <disfmarker>
E: but ,
E: um ,
E: that has a similar effect
E: because it changes the scale of the numbers <disfmarker> of the differences between different candidates from the acoustic model
F: Oh ,
F: right .
E: as opposed to what 's coming from the language model .
F: So that w
F: Right .
F: So , in effect , that 's changing the value of your insertion penalty .
E: Yeah .
E: I mean , it 's more directly like the <disfmarker> the language scaling or the , uh <disfmarker> the model scaling or acoustic scaling ,
F: That 's interesting .
E: but you know that those things have kind of a similar effect to the insertion penalty
F: Mm - hmm .
E: anyway . They 're a slightly different way of <disfmarker> of handling it .
F: Right .
E: So , um <disfmarker>
F: So if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,
F: so that they <pause> match with that .
E: I think so .
E: Yeah .
E: Yeah .
E: So that 's why I think
E: that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off .
F: Mm - hmm .
E: I mean , the other thing is , are aren't we seeing <disfmarker> ? Y y
E: I 'm sure you 've already looked at this
E: bu in these noisy cases , are <disfmarker> ? We are seeing lots of insertions .
E: Right ?
E: The insertion number is quite high ?
E: I know the VAD takes pre care of part of that ,
B: Yeah .
F: Yeah .
E: but <disfmarker>
F: I 've seen that with the mel cepstrum .
B: Yeah .
F: I don't <disfmarker> I don't know about <pause> the Aurora front - end ,
F: but <disfmarker>
B: I think it 's much more balanced with , uh <disfmarker> when the front - end is more robust .
B: Yeah .
B: I could look at it <disfmarker> at this .
B: Yeah .
E: Yeah .
E: Wha - what 's a typical number ?
B: Mm - hmm .
B: I don't <disfmarker> I don't know .
E: Do we <disfmarker> ?
E: Oh , you <disfmarker> oh , you don't know .
E: OK .
B: I don't have this in <disfmarker>
E: I 'm sure it 's more balanced ,
E: but it <disfmarker> it <disfmarker> it wouldn't surprise me if there 's still <disfmarker>
B: Mm - hmm .
E: I mean , in <disfmarker> in the <disfmarker> the <disfmarker> the old systems we used to do , I <disfmarker> I <disfmarker> uh , I remember numbers kind of like insertions being half the number of deletions , as being <disfmarker> and both numbers being <disfmarker> tend to be on the small side comparing to <disfmarker> to , uh , substitutions .
B: Mm - hmm .
B: Mm - hmm .
F: Well , this <disfmarker>
F: the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down <pause> that one time
F: and <disfmarker>
F: and that was when people were saying , well we should have a , uh , uh , voice activity detector <disfmarker>
E: Right .
F: that , because all that stuff <comment> that we 're getting thr the silence that 's getting through is causing insertions .
F: So .
E: Right .
B: Mmm .
F: I 'll bet you there 's still a lot <vocalsound> of insertions .
B: Mm - hmm .
E: Yeah .
E: And it may be less of a critical thing .
E: I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .
F: Mm - hmm .
E: So , I mean , the insertions is <disfmarker> is a symptom .
E: It 's a symptom that there 's something , uh , wrong with the range .
F: Right .
E: But there 's <disfmarker> uh , your <disfmarker> your <disfmarker> your substitutions tend to go up as well .
E: So , uh , I <disfmarker> I <disfmarker> I think that ,
F: Mm - hmm .
E: uh , the most obvious thing is just the insertions , @ @ .
E: But <disfmarker>
E: Uh <disfmarker>
E: um .
E: If you 're operating in the wrong range <disfmarker> I mean , that 's why just in general , if you <vocalsound> change what these <disfmarker> these penalties and scaling factors are , you reach some point that 's a <disfmarker> that 's a minimum .
E: So .
E: Um .
E: Um .
E: We do have to do well over a range of different conditions ,
E: some of which are noisier than others .
E: Um .
E: But , um , I think we may get a better handle on that if we <disfmarker> if we see <disfmarker>
E: Um , I mean we ca
E: it 's if we actually could pick a <disfmarker> a <disfmarker> a more stable value for the range of these features , it , um , uh , could <disfmarker>
E: Uh <disfmarker>
E: Even though it 's <disfmarker> it 's <disfmarker> it 's true that in a real situation you can in fact adjust the <disfmarker> these <disfmarker> these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time .
F: Hmm .
E: And if you have a nice front - end that 's in roughly the right range <disfmarker>
E: I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level ,
E: and we would rarely adjust them again ,
E: even though you could get a <disfmarker>
F: Mm - hmm .
E: for an evaluation you can get an extra point or something if you tweaked it a little bit .
E: But ,
E: once we knew what rou roughly the right operating range was , it was pretty stable ,
E: and <disfmarker> Uh , we might just not even be in the right operating range .
F: So , would the <disfmarker> ?
F: Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ?
F: So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as <disfmarker> ?
E: No . You don't wanna change it for different conditions .
E: No .
E: No .
E: I <disfmarker> I <disfmarker> I <disfmarker> What <disfmarker> what I 'm saying <disfmarker>
F: Oh , I wasn't suggesting change it for different conditions .
F: I was just saying that when we pick a range , we <disfmarker> we wanna pick a range that we map our numbers into <disfmarker>
F: we should probably pick it based on the range that we get in the well - matched case .
E: Yeah .
F: Otherwise , I mean , what range are we gonna choose
F: to <disfmarker> to map everything into ?
E: Well . It depends how much we wanna do gamesmanship and how much we wanna do <disfmarker>
E: I mean , i if he
E: it <disfmarker> to me , actually , even if you wanna be <disfmarker> play on the gamesmanship side , it can be kinda tricky .
E: So , I mean , what you would do is set the <disfmarker> set the scaling factors , uh , so that you got the best number for this point four five times the <disfmarker> <vocalsound> you know , and so on .
F: Mm - hmm .
E: But they might change that <disfmarker>
E: those weightings .
F: Yeah .
E: Um .
E: So <disfmarker>
E: Uh <disfmarker>
E: I just sorta think we need to explore the space .
F: Mm - hmm .
E: Just take a look at it a little bit .
F: OK .
E: And we <disfmarker> we <disfmarker> we may just find that <disfmarker> that we 're way off .
F: Mm - hmm .
E: Maybe we 're not .
E: You know ?
E: As for these other things , it may turn out that , uh , <vocalsound> it 's kind of reasonable .
E: But then <disfmarker>
E: I mean , Andreas gave a very reasonable response ,
E: and he 's probably not gonna be the only one who 's gonna say this in the future <disfmarker>
E: of , you know ,
E: people <disfmarker> people within this tight - knit community who are doing this evaluation <vocalsound> are accepting , uh , more or less , that these are the rules .
F: Yeah .
E: But , people outside of it who look in at the broader picture are certainly gonna say " Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,
E: when all you could do is just adjust this in the back - end with one s one knob . "
F: Mm - hmm .
E: And
E: so we have to at least , I think , determine that that 's not true ,
E: which would be OK ,
E: or determine that it is true ,
E: in which case we want to adjust that
E: and then continue with <disfmarker> with what we 're doing .
F: Right .
E: And as you say <disfmarker> as you point out <disfmarker> finding ways to then compensate for that in the front - end <vocalsound> also then becomes a priority for this particular test ,
E: and saying you don't have to do that .
F: Mm - hmm .
E: So .
E: OK .
E: So , uh <disfmarker>
E: What 's new with you ?
B: Uh .
B: So there 's nothing <pause> new .
E: Uh , what 's old with you that 's developed ?
B: Um .
B: I 'm sorry ?
E: You <disfmarker>
E: OK .
E: What 's old with you that has developed over the last week or two ?
B: Mmm .
B: Well , so we 've been mainly working on the report
B: and <disfmarker> and <disfmarker>
B: Yeah .
F: Mainly working on what ?
B: On the report <pause> of the work that was already done .
F: Oh .
B: Um .
F: How about that <disfmarker> ?
B: Mm - hmm .
B: That 's all .
F: Any - anything new on the thing that , uh , you were working on with the , uh <disfmarker> ?
C: I don't have results yet .
F: No results ?
F: Yeah .
E: What was that ?
F: The <disfmarker> the ,
F: uh ,
A: Voicing thing .
F: voicing detector .
E: I mean , what what 's <disfmarker> what 's going on now ?
E: What are you <pause> doing ?
C: Uh , to try to found , nnn , robust feature for detect between voice and unvoice .
C: And we <disfmarker> w we try to use <vocalsound> the variance <vocalsound> of the es difference between the FFT spectrum and mel filter bank spectrum .
E: Yeah .
C: Uh , also the <disfmarker> another parameter is <disfmarker> relates with the auto - correlation function .
E: Uh - huh .
C: R - ze energy and the variance a also of the auto - correlation function .
E: Uh - huh .
E: So , that 's <disfmarker>
E: Yeah . That 's what you were describing , I guess , a week or two ago .
E: So .
C: Yeah .
C: But we don't have res we don't have result of the AURO for Aurora yet .
E: Mm - hmm .
C: We need to train the neural network
C: and <disfmarker>
E: So you 're training neural networks now ?
C: No ,
C: not yet .
E: So , what <disfmarker> wha <vocalsound> wh wha what what 's going on ?
C: Well , we work in the report , too ,
C: because we have a lot of result ,
E: Uh - huh .
C: they are very dispersed ,
C: and was necessary to <disfmarker> to look in all the directory to <disfmarker> to <disfmarker> to give some more structure .
E: So . B So <disfmarker>
B: Yea
E: Yeah .
E: I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion ,
E: f generating many results and doing many experiments
E: and trying to pull it together into some coherent form to be able to see wha see what happens .
C: Hm - hmm .
B: Uh ,
B: y yeah . Basically we we 've stopped , uh , experimenting ,
E: Yes ?
B: I mean . We 're just writing some kind of technical report .
B: And <disfmarker>
F: Is this a report that 's for Aurora ?
F: Or is it just like a tech report for ICSI ,
C: No .
F: or <disfmarker> ?
B: Yeah .
C: For ICSI .
F: Ah .
F: I see .
B: Yeah .
C: Just summary of the experiment and the conclusion
C: and
C: something like that .
E: Yeah .
B: Mm - hmm .
E: OK .
E: So , my suggestion , though , is that you <disfmarker> you not necessarily finish that .
E: But that you put it all together so that it 's <disfmarker> you 've got <disfmarker> you 've got a clearer structure to it .
E: You know what things are ,
E: you have things documented ,
E: you 've looked things up that you needed to look up .
E: So that , you know <disfmarker> so that such a thing can be written .
B: Mm - hmm .
E: And , um <disfmarker>
E: When <disfmarker> when <disfmarker> when do you leave again ?
C: Uh , in July .
C: First of July .
E: First of July ?
E: OK .
E: And that you figure on actually finishing it in <disfmarker> in June .
E: Because , you know , you 're gonna have another bunch of results to fit in there anyway .
B: Mm - hmm .
C: Mm - hmm .
E: And right now it 's kind of important that we actually go forward with experiments .
C: It 's not .
E: So <disfmarker> so , I <disfmarker> I think it 's good to pause , and to gather everything together and make sure it 's in good shape ,
E: so that other people can get access to it
E: and so that it can go into a report in June .
E: But I think <vocalsound> to <disfmarker> to really work on <disfmarker> on fine - tuning the report n at this point is <disfmarker> is probably bad timing , I <disfmarker> I <pause> think .
B: Mm - hmm .
B: Yeah .
B: Well , we didn't <disfmarker>
B: we just planned to work on it one week on this report ,
B: not <disfmarker> no more , anyway .
B: Um .
E: But you ma you may really wanna add other things later anyway
B: Yeah .
B: Mm - hmm .
E: because you <disfmarker>
B: Mmm .
E: There 's more to go ?
B: Yeah .
B: Well ,
B: so I don't know . There are small things that we started to <disfmarker> to do .
B: But <disfmarker>
F: Are you discovering anything , uh , that makes you scratch your head as you write this report ,
F: like why did we do that ,
F: or why didn't we do this ,
B: Uh .
F: or <disfmarker> ?
B: Yeah .
B: Yeah .
B: And <disfmarker>
B: Actually , there were some tables that were also with partial results .
B: We just noticed that ,
B: wh while gathering the result that for some conditions we didn't have everything .
F: Mmm .
B: But anyway .
B: Um .
B: Yeah , yeah .
B: We have , yeah , extracted actually the noises from <pause> the SpeechDat - Car .
B: And so ,
B: we can train neural network with speech and these noises .
B: Um .
B: It 's difficult to say what it will give ,
B: because when we look at the Aurora <disfmarker> the TI - digits experiments , um , they have these three conditions that have different noises ,
B: and apparently this system perform as well on the seen noises <disfmarker> on the unseen noises and on the seen noises .
B: But ,
B: I think this is something we have to try anyway .
B: So <disfmarker>
B: adding the noises from <disfmarker> from the SpeechDat - Car .
B: Um .
E: That 's <disfmarker>
E: that 's , uh <disfmarker>
E: that 's permitted ?
B: Uh .
B: Well ,
B: OGI does <disfmarker> did that .
B: Um .
B: At some point they did that for <disfmarker> for the voice activity detector .
C: Uh , for a v VAD .
B: Right ?
B: Um .
F: Could you say it again ?
F: What <disfmarker> what exactly did they do ?
B: They used some parts of the , um , Italian database to train the voice activity detector , I think .
B: It <disfmarker>
E: Yeah . I guess the thing is <disfmarker>
E: Yeah .
E: I guess that 's a matter of interpretation .
E: The rules as I understand it , is that in principle the Italian and the Spanish and the English <disfmarker>
E: no ,
E: Italian and the Finnish and the English ? <disfmarker> were development data
B: Yeah .
B: And Spanish , yeah .
E: on which you could adjust things .
E: And the <disfmarker> and the German and Danish were the evaluation data .
B: Mm - hmm .
E: And then when they finally actually evaluated things they used everything .
B: Yeah .
B: That 's right .
E: So <disfmarker>
B: Uh <disfmarker>
E: Uh ,
E: and it is true that the performance , uh , on the German was <disfmarker>
E: I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .
B: Mm - hmm .
E: So <disfmarker>
E: And , uh ,
E: it <disfmarker> it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that <disfmarker> that going to a different language really hurt you .
E: And the noises were not exactly the same .
E: Right ?
E: Because it was taken from a different ,
E: uh <disfmarker>
E: I mean they were different drives .
B: Different cars .
E: I mean , it was <disfmarker> it was actual different cars and so on .
B: Yeah .
B: Yeah .
E: So .
E: Um , it 's somewhat tuned .
E: It 's tuned more than , you know , a <disfmarker> a <disfmarker> a <disfmarker> a <disfmarker>
B: Mm - hmm .
E: You 'd really like to have something that needed no particular noise at all ,
E: maybe just some white noise or something like that a at most .
B: Mm - hmm .
E: But that 's not really what this contest is .
E: So .
E: Um , I guess it 's OK .
B: Mm - hmm .
F: I think it 's <disfmarker>
E: That 's something I 'd like to understand before we actually use something from it ,
E: because it would <disfmarker>
F: it 's probably something that , mmm , the <disfmarker> you know , the , uh , experiment designers didn't really think about ,
F: because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models .
F: I mean , they just <pause> doing signal - processing .
B: Yeah .
F: So .
E: Well , it 's true ,
E: except that , uh , that 's what we used in Aurora one ,
E: and then they designed the things for Aurora - two knowing that we were doing that .
F: Yeah .
F: That 's true .
E: Um .
F: And they didn't forbid us <disfmarker>
F: right ? <disfmarker>
F: to build models on the data ?
E: No .
E: But , I think <disfmarker> I think that it <disfmarker> it <disfmarker>
E: it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that <disfmarker> that it would look bad .
E: And I think someone would notice
E: and would say " Well , look . This is not generalizing . "
F: Mm - hmm .
E: I would hope tha I would hope they would .
E: Um .
E: But , uh ,
E: it 's true .
E: You know , maybe there 's parameters that other people have used <disfmarker>
E: you know , th that they have tuned in some way for other things .
E: So it 's <disfmarker> it 's , uh <disfmarker>
E: We should <disfmarker> we should <disfmarker>
E: Maybe <disfmarker> that 's maybe a topic <disfmarker>
E: Especially if you talk with him when I 'm not here ,
E: that 's a topic you should discuss with Hynek
E: to , you know , double check it 's OK .
B: Mm - hmm .
F: Do we know anything about <pause> the speakers for each of the , uh , training utterances ?
B: What do you mean ?
F: Do you have speaker information ?
B: We <disfmarker> we <disfmarker>
E: Social security number
F: That would be good .
B: Like , we have <pause> male , female ,
F: Bank PIN .
C: Hmm .
F: Just male f female ?
B: at least .
B: Mmm .
E: What kind of information do you mean ?
F: Well , I was thinking about things like , you know , gender , uh <disfmarker> you know , gender - specific nets and , uh , vocal tract length normalization .
B: Mm - hmm .
F: Things like that .
F: I d I don't <disfmarker> I didn't know what information we have about the speakers that we could try to take advantage of .
B: Mm - hmm .
E: Hmm .
E: Uh .
E: Right .
E: I mean , again , i if you had the whole system you were optimizing , that would be easy to see .
E: But if you 're <vocalsound> supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure <disfmarker>
E: I mean , having the two nets <disfmarker> Suppose you detected that it was male , it was female <disfmarker> you come up with different <disfmarker>
F: Well , you could put them both in as separate streams or something .
F: Uh .
B: Mm - hmm .
E: Maybe .
F: I don't know .
F: I was just wondering if there was other information we could exploit .
B: Mm - hmm .
E: Hmm .
E: Yeah , it 's an interesting thought .
E: Maybe having something along the <disfmarker>
E: I mean , you can't really do vocal tract normalization .
E: But something that had some of that effect
F: Yeah .
E: being applied to the data in some way .
F: Mm - hmm .
E: Um .
B: Do you have something simple in mind for <disfmarker> I mean , vocal tract length normalization ?
F: Uh no . I hadn't <disfmarker> I hadn't thought <disfmarker> it was <disfmarker> thought too much about it , really .
F: It just <disfmarker> something that popped into my head just now .
F: And so I <disfmarker> I <disfmarker>
F: I mean , you could maybe use the ideas <disfmarker> a similar <pause> idea to what they do in vocal tract length normalization .
F: You know , you have some sort of a , uh , general speech model ,
F: you know , maybe just a mixture of Gaussians that you evaluate every utterance against ,
F: and then you see where each , you know , utterance <disfmarker> like , the likelihood of each utterance . You divide the <disfmarker> the range of the likelihoods up into discrete bins
F: and then each bin 's got some knob <disfmarker> uh , setting .
E: Yeah . But just listen to yourself .
E: I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that <disfmarker> and where you 're not adjusting the statistical engine at all .
F: Yeah .
F: Yeah .
B: Mm - hmm .
F: Yeah .
F: That 's true .
F: Right .
E: You know , that just <disfmarker>
B: Hmm .
F: Could be expensive .
E: I mean <disfmarker>
E: Yeah .
E: No .
E: Well not just expensive .
E: I <disfmarker> I <disfmarker> I don't see how you could possibly do it .
E: You can't look at the whole utterance and do anything . You know , you can only <disfmarker>
F: Oh ,
E: Right ?
F: right .
E: Each frame comes in and it 's gotta go out the other end .
F: Right .
E: So , uh <disfmarker>
F: So whatever it was , it would have to be uh sort of on a per frame basis .
E: Yeah .
B: Mm - hmm .
E: Yeah .
E: I mean , you can do ,
E: um <disfmarker>
F: Yeah .
E: Fairly quickly you can do male female <disfmarker> f male female stuff .
F: Yeah .
E: But as far as ,
E: I mean <disfmarker> Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back .
E: Maybe other people did too .
E: With <disfmarker> with , uh , uh , l trying to identify third formant <disfmarker> average third formant <disfmarker> <vocalsound> using that as an indicator of <disfmarker>
F: I don't know .
E: So .
E: You know , third formant <disfmarker>
E: I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion <disfmarker>
F: Mm - hmm .
E: So , if you had a first formant that was one hundred hertz before , if the fifty <disfmarker> if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz ,
E: and so on .
E: So , that 's a move of two hundred fifty hertz .
E: Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty ,
E: you know so it 's at <disfmarker>
E: So ,
E: although , you frequently get less distinct higher formants , it 's still <disfmarker> third formant 's kind of a reasonable compromise ,
E: and <disfmarker>
F: Mm - hmm .
E: So , I think , eh , if I recall correctly , they did something like that .
F: Hmm .
E: And <disfmarker> and <disfmarker>
E: But <disfmarker> Um , that doesn't work for just having one frame or something .
F: Yeah .
E: You know ? That 's more like looking at third formant over <disfmarker> over a turn or something like that ,
B: Mm - hmm .
B: Mm - hmm .
E: and <disfmarker>
F: Right .
E: Um .
E: So .
E: But on the other hand , male female is a <disfmarker> is a <disfmarker> is a much simpler categorization than figuring out a <disfmarker> a factor to , uh , squish or expand the <disfmarker> the spectrum .
F: Mm - hmm .
E: So , um .
E: Y you could imagine that <disfmarker>
E: I mean , just like we 're saying voiced - unvoiced is good to know <disfmarker>
E: uh , male female is good to know also .
F: Mm - hmm .
E: Um .
E: But , you 'd have to figure out a way to <disfmarker> to <disfmarker> to , uh , incorporate it on the fly .
E: Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the <disfmarker> the male and female output vectors <disfmarker> you know , tr nets trained only on males and n trained only on females
E: or <disfmarker>
E: or , uh ,
E: you know .
E: But <disfmarker>
E: Um .
E: I don't know if that would really help ,
E: because you already have males and females
E: and it 's mm - hmm putting into one net .
E: So
E: is it <disfmarker> ?
F: Is it balanced ,
F: um , in terms of gender <disfmarker>
F: the data ?
E: Do you know ?
B: Mmm .
B: Almost ,
B: yeah .
F: Hmm .
B: Mm - hmm .
E: Hmm .
E: OK .
E: Y you 're <disfmarker> you were saying before <disfmarker> ?
B: Uh . Yeah .
B: So , this noise ,
B: um <disfmarker>
B: Yeah . The MSG <disfmarker>
B: Um .
B: Mmm .
B: There is something <disfmarker> perhaps , I could spend some days to look at this thing ,
B: cuz it seems that when we train networks on <disfmarker> let 's say , on TIMIT with MSG features , they <disfmarker> they look as good as networks trained on PLP .
B: But ,
B: um ,
B: when they are used on <disfmarker> on the SpeechDat - Car data , it 's not the case <disfmarker>
B: oh , well .
B: The MSG features are much worse ,
B: and so maybe they 're , um , less <disfmarker> more sensitive to different recording conditions ,
E: Shouldn't be .
B: or <disfmarker> Shou
E: They should be less so .
B: Yeah .
B: But <disfmarker>
E: R right ?
B: Mmm .
E: Wh - ?
E: But let me ask you this .
E: What <disfmarker> what 's the , um <disfmarker> ?
E: Do you kno recall if the insertions were <disfmarker> were higher with MSG ?
B: I don't know .
B: I cannot tell .
B: But <disfmarker>
B: It 's <disfmarker> it <disfmarker>
B: the <disfmarker> the error rate is higher .
E: Yeah . But you should always look at insertions , deletions , and substitutions .
B: So , I don
B: Yeah .
B: Mm - hmm .
E: So <disfmarker>
B: Mm - hmm .
E: so , uh <disfmarker>
E: MSG is very , very dif
E: Eh , PLP is very much like mel cepstrum .
E: MSG is very different from both of them .
B: Mm - hmm .
E: So , if it 's very different , then this is the sort of thing <disfmarker>
E: I mean I 'm really glad Andreas brought this point up .
E: I <pause> sort of had forgotten to discuss it .
E: Um .
E: You always have to look at how this <disfmarker> uh , these adjustments , uh , affect things .
E: And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .
E: So if it <disfmarker> if in fact , uh <disfmarker>
B: Mm - hmm .
E: The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .
B: Mm - hmm .
E: And you might wanna change that .
B: Mm - hmm .
B: But <disfmarker>
B: Yeah .
B: But , it 's d it 's after <disfmarker>
B: Well , it 's tandem features ,
B: so <disfmarker>
B: Mmm .
E: Yeah .
B: Yeah .
B: We <disfmarker> we have estimation of post posteriors with PLP and with MSG as input ,
E: Yeah .
B: so I don
B: Well .
B: I don't know .
E: That means they 're between zero and one .
B: Mm - hmm .
E: But i it <disfmarker> it <disfmarker> it <disfmarker> it doesn't necessarily <disfmarker>
E: You know , they could be ,
E: um <disfmarker>
E: Do - doesn't tell you what the variance of the things is .
B: Mmm .
B: Mm - hmm .
E: Right ?
E: Cuz if you 're taking the log of these things , it could be ,
E: uh <disfmarker>
E: Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .
B: Mm - hmm .
B: Yeah .
E: So .
B: Yeah .
B: So we should look at the likelihood ,
B: or <disfmarker> or
B: what ?
B: Or <disfmarker>
B: well ,
B: at the log , perhaps ,
B: and <disfmarker>
E: Yeah .
B: Mm - hmm .
E: Yeah .
E: Or what <disfmarker> you know , what you 're uh <disfmarker> the thing you 're actually looking at .
B: Mm - hmm .
E: So your <disfmarker> your <disfmarker>
E: the values that are <disfmarker> are actually being fed into HTK .
B: Mm - hmm .
E: What do they look like ?
F: No
B: But <disfmarker>
F: And so th the , uh <disfmarker> for the tandem system , the values that come out of the net don't go through the sigmoid .
F: Right ?
F: They 're sort of the pre - nonlinearity values ?
E: Right .
B: Yes .
E: So they 're <pause> kinda like log probabilities is what I was saying .
F: And those <disfmarker>
F: OK .
F: And tho that 's what goes <pause> into <pause> HTK ?
E: Uh , almost .
E: But then you actually do a KLT on them .
F: OK .
E: Um .
E: They aren't normalized after that ,
E: are they ?
B: Mmm . No ,
B: they are not <disfmarker>
E: No .
B: no .
E: OK .
E: So , um .
E: Right .
E: So the question is <disfmarker> Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is <disfmarker> is gonna be a good or a bad thing ?
E: So .
B: Mm - hmm .
E: Uh , and that 's something that
E: nothing <disfmarker> nothing else after that is gonna <disfmarker>
E: Uh , things are gonna scale it <disfmarker>
E: Uh , you know , subtract things from it ,
E: scale it from it ,
E: but nothing will have that same effect .
E: Um .
E: So .
E: Um .
E: Anyway , eh <disfmarker>
F: Yeah .
F: Cuz if <disfmarker> if the log probs that are coming out of the MSG are really big , the standard <pause> insertion penalty is gonna have very little effect
E: Well , the <disfmarker>
E: Right .
F: compared to , you know , a smaller set of log probs .
E: Yeah .
E: No . Again you don't really <pause> look at that .
E: It 's something <disfmarker> that ,
E: and then it 's going through this transformation that 's probably pretty close to <disfmarker>
E: It 's , eh , whatever the KLT is doing .
E: But it 's probably pretty close to what a <disfmarker> a <disfmarker> a discrete cosine transformation is doing .
F: Yeah .
E: But still it 's <disfmarker> it 's not gonna probably radically change the scale of things .
E: I would think .
E: And , uh <disfmarker>
E: Yeah .
E: It may be entirely off
E: and <disfmarker> and it may be <disfmarker> at the very least it may be quite different for MSG than it is for mel cepstrum or PLP .
E: So that would be <disfmarker>
E: So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions .
E: And if the <disfmarker> if
E: the , uh <disfmarker>
E: i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might <disfmarker> might be in that direction .
B: Mm - hmm .
B: Mm - hmm .
E: Anything else ?
B: Yeah . But ,
B: my <disfmarker> my point was more that it <disfmarker> it works sometimes
B: and <disfmarker>
E: Yeah .
B: but sometimes it doesn't work .
B: So .
E: Well .
B: And it works on TI - digits
B: and on SpeechDat - Car it doesn't work ,
B: and <disfmarker>
E: Yeah .
B: Mm - hmm .
B: Yeah .
B: Well .
E: But , you know , some problems are harder than others ,
B: Mm - hmm .
B: Yeah .
E: and <disfmarker>
E: And , uh , sometimes , you know , there 's enough evidence for something to work
E: and then it 's harder ,
E: it breaks .
E: You know ,
E: so it 's <disfmarker>
B: Mm - hmm .
E: But it <disfmarker> but , um , i it <disfmarker> it could be that when you say it works maybe we could be doing much better ,
E: even in TI - digits .
E: Right ?
B: Yeah .
E: So .
B: Yeah , sure .
B: Uh .
E: Hmm ?
E: Yeah .
B: Yeah .
B: Well ,
B: there is also the spectral subtraction ,
B: which ,
B: um <disfmarker>
B: I think maybe we should , uh , try to integrate it in <disfmarker> in our system .
E: Yeah .
B: Mmm .
B: Mm - hmm .
E: Right .
B: But ,
E: O
B: I think that would involve to <disfmarker> <vocalsound> to mmm <vocalsound> use a big <disfmarker> a <disfmarker> al already a big bunch of the system of Ericsson .
B: Because he has spectral subtraction ,
B: then it 's followed by , <vocalsound> um , other kind of processing that 's <disfmarker> are dependent on the <disfmarker> uh , if it 's speech or noi or silence .
E: Mm - hmm .
B: And there is this kind of spectral flattening after <disfmarker> if it 's silence ,
B: and <disfmarker>
B: and s I <disfmarker> I think it 's important , um , <vocalsound> to reduce this musical noise and this <disfmarker> this increase of variance during silence portions .
B: So .
B: Well .
B: This was in this would involve to take almost everything from <disfmarker> from the <disfmarker> this proposal
B: and <disfmarker>
B: and then just add some kind of on - line normalization in <disfmarker> in the neural network .
B: Mmm .
E: OK .
E: Well , this 'll be , I think , something for discussion with Hynek next week .
B: Yeah .
B: Mm - hmm .
E: Yeah .
E: OK .
E: Right .
E: So .
E: How are , uh , uh <disfmarker> how are things going with what you 're doing ?
D: Oh .
D: Well , um ,
D: I took a lot of time just getting my taxes out of the way <disfmarker>
D: multi - national taxes .
D: So , I 'm <disfmarker> I 'm starting to write code now for my work
D: but I don't have any results yet .
D: Um , i it would be good for me to talk to Hynek , I think , when he 's here .
E: Yeah .
D: Do you know what his schedule will be like ?
E: Uh , he 'll be around for three days .
E: Uh , we 'll have a lot of time .
D: OK .
D: So , y
E: So , uh <disfmarker>
D: OK .
E: Um .
E: I 'll , uh <disfmarker>
E: You know , he 's <disfmarker>
E: he 'll <disfmarker>
E: he 'll be talking with everybody in this room
E: So .
F: But you said you won't <disfmarker> you won't be here next Thursday ?
E: Not Thursday and Friday .
E: Yeah .
E: Cuz I will be at faculty retreat .
F: Hmm .
E: So .
E: I 'll try to <vocalsound> connect with him and people as <disfmarker> as I can on <disfmarker> on Wednesday .
E: But <disfmarker>
E: Um .
E: Oh , how 'd taxes go ?
E: Taxes go OK ?
D: Mmm . Yeah .
E: Yeah . Oh , good . Yeah .
E: Yeah .
E: That 's just <disfmarker> that 's <disfmarker> that 's one of the big advantages of not making much money is <vocalsound> the taxes are easier .
E: Yeah .
F: Unless you 're getting money in two countries .
E: I think you are .
F: They both want their cut .
E: Aren't you ?
B: Hmm .
D: Hmm . Yeah .
F: Right ?
E: Yeah .
E: Yeah .
E: Huh .
E: Canada w Canada wants a cut ?
D: Mm - hmm .
E: Have to do <disfmarker> So you <disfmarker> you have to do two returns ?
D: Mmm . W uh , for two thousand I did .
D: Yeah .
E: Oh , oh .
E: Yeah .
E: For tw
E: That 's right ,
E: ju
F: But not for this next year ?
E: Two thousand .
E: Yeah .
E: Probably not this next year , I guess .
D: Ye
E: Yeah .
D: Um .
E: Yeah .
D: Uh , I 'll <disfmarker> I 'll still have a bit of Canadian income
D: but it 'll be less complicated
D: because I will not be a <disfmarker> considered a resident of Canada anymore ,
D: so I won't have to declare my American income on my Canadian return .
E: OK .
E: Alright .
E: Uh .
E: Barry ,
E: do you wanna <pause> say something about your stuff here ?
A: Oh ,
A: um .
A: Right .
A: I <pause> just , um , continuing looking at , uh , ph uh , phonetic events ,
A: and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events .
A: Um , came up with , uh , a plan of attack ,
A: uh , gonna execute ,
A: and
A: um <disfmarker>
A: Yeah .
A: It 's <disfmarker> that 's pretty much it .
E: Oh , well .
E: No
E: Um , why don't you say something about what it is ?
A: Oh ,
A: you <disfmarker> oh , you want <disfmarker> you want details .
A: Hmm .
A: OK .
E: Well , we 're all gathered here together .
E: I thought we 'd , you know <disfmarker>
A: I was hoping I could wave my hands .
A: Um .
A: So ,
A: um .
A: So , once wa
A: I <disfmarker> I was thinking getting <disfmarker> getting us a set of acoustic events to <disfmarker> um , to be able to distinguish between , uh , phones and words and stuff .
A: And <vocalsound> um ,
A: once we <disfmarker>
A: we would figure out a set of these events that can be , you know , um , hand - labeled or <disfmarker> or derived , uh , from h the hand - labeled phone targets .
A: Um , we could take these events and , um , <vocalsound> do some cheating experiments ,
A: um , where we feed , um , these events into <pause> an SRI system , um , eh , and evaluate its performance on a Switchboard task .
D: Hey , Barry ?
A: Uh , yeah .
D: Can you give an example of an event ?
A: Yeah .
A: Sure .
A: Um , I <disfmarker> I can give you an example of <pause> twenty - odd events .
A: Um <disfmarker>
A: So , he In this paper , um , it 's talking about phoneme recognition using acoustic events .
A: So , things like frication or , uh , nasality .
E: Whose paper is it ?
A: Um ,
A: this is a paper by Hubener and Cardson <pause> Benson <disfmarker> Bernds - Berndsen .
E: Yeah .
E: Huh .
E: From , uh , University of Hamburg and Bielefeld .
A: Mm - hmm .
E: OK .
A: Um .
F: Yeah . I think the <disfmarker>
F: just to expand a little bit on the idea of acoustic event .
A: Mm - hmm .
F: There 's , um <disfmarker> in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events .
F: And I think of acoustic features as being , um , things that linguists talk about ,
F: like , um <disfmarker>
E: So , stuff that 's not based on data .
F: Stuff that 's not based on data , necessarily .
E: Yeah .
E: Oh , OK .
F: Right .
E: Yeah .
E: Yeah ,
F: That 's not based on , you know , acoustic data .
E: OK .
F: So they talk about features for phones ,
F: like , uh , its height ,
F: its tenseness ,
A: Yeah .
F: laxness ,
F: things like that ,
A: Mm - hmm .
F: which may or may not be all that easy to measure in the acoustic signal .
F: Versus an acoustic event , which is just <nonvocalsound> some <nonvocalsound> something in the acoustic signal <nonvocalsound> that is fairly easy to measure .
F: Um . So it 's , um <disfmarker> it 's a little different ,
F: in <disfmarker> at least in my mind .
E: I mean , when we did the SPAM work <disfmarker> I mean , there we had <disfmarker> we had this notion of an , uh , auditory <disfmarker> @ @ <comment> auditory event .
A: Good . That 's great .
E: And , uh ,
E: um ,
E: called them " avents " ,
F: Mm - hmm .
E: uh , uh , uh , with an A at the front .
E: Uh .
E: And the <disfmarker> the <disfmarker> the idea was something that occurred that is important to a bunch of neurons somewhere .
E: So .
A: Mm - hmm .
E: Um . A sudden change or a relatively rapid change in some spectral characteristic will <disfmarker> will do sort of this .
E: I mean , there 's certainly a bunch of <disfmarker> a bunch of places where you know that neurons are gonna fire because something novel has happened .
E: That was <disfmarker> that was the main thing that we were focusing on there .
E: But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes ,
E: but <disfmarker>
F: It 's kinda like the difference between top - down and bottom - up .
E: Yeah .
F: I think of the acoustic <disfmarker> you know , phonetic features as being top - down .
F: You know , you look at the phone
F: and you say this phone is supposed to be <disfmarker> you know , have this feature , this feature , and this feature .
F: Whether tha those features show up in the acoustic signal is sort of irrelevant .
F: Whereas , an acoustic event goes the other way .
F: Here 's the signal .
F: Here 's some event .
A: Mm - hmm .
F: What <disfmarker> ?
F: And then that <disfmarker> you know , that may map to this phone sometimes ,
F: and sometimes it may not .
F: It just depen maybe depends on the context ,
F: things like that .
F: And so it 's sort of a different way of looking .
E: Mm - hmm .
E: Mm - hmm .
A: Yeah .
A: So .
A: Yeah .
D: OK .
A: Mm - hmm .
A: Um <disfmarker>
A: Using these <disfmarker> these events , um , you know , we can <disfmarker> we can perform these <disfmarker> these , uh , cheating experiments .
A: See how <disfmarker> how <disfmarker> how good they are , um , in , um <disfmarker> in terms of phoneme recognition or word recognition .
A: And ,
A: um <disfmarker>
A: and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this <disfmarker> this probabilistic AND - OR model that he uses .
A: Um ,
A: eh , try to extend it to , um <disfmarker> to account for other <disfmarker> other phenomena like , um , CMR co - modulation release .
A: And ,
A: um <disfmarker>
A: and maybe also investigate ways to <disfmarker> to modify the structure of these models , um , in a data - driven way ,
A: uh , similar to the way that , uh , Jeff <disfmarker> Jeff , uh , Bilmes did his work .
A: Um ,
A: and while I 'm <disfmarker> I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets .
A: Um ,
A: and <disfmarker>
A: So <disfmarker>
A: so , once we have these <disfmarker> these , uh , event detectors , um , we could put them together and <disfmarker> and feed the outputs of the event detectors into <disfmarker> into the SRI , um , HMM <disfmarker> HMM system ,
A: and ,
A: um <disfmarker>
A: and test it on <disfmarker> on Switchboard or , um , maybe even Aurora stuff .
A: And ,
A: that 's pretty much the <disfmarker> the big picture of <disfmarker> of um , the plan .
E: By the way ,
E: um ,
E: there 's , uh , a couple people who are gonna be here <disfmarker>
E: I forget if I already told you this ,
E: but , a couple people who are gonna be here for six months .
A: Mm - hmm .
E: Uh <disfmarker>
E: uh , there 's a Professor Kollmeier , uh , from Germany
E: who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area
E: and , um , Michael Kleinschmidt , who 's worked with him ,
E: who also looks at <vocalsound> auditory properties inspired by various , uh , brain function things .
A: Hmm .
E: So ,
E: um ,
E: um , I think they 'll be interesting to talk to , in this sort of issue
E: as these detectors are <disfmarker> are , uh , developing .
A: Hmm .
A: OK .
E: So , he looks at interesting <disfmarker> interesting things in <disfmarker> in the <disfmarker> <vocalsound> different ways of looking at spectra in order to <disfmarker> to get various speech properties out .
E: So .
A: OK .
E: OK .
E: Well ,
E: short meeting ,
E: but that 's OK .
E: And , uh ,
E: we might as well do our digits .
E: And like I say , I <disfmarker> I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek .
E: Alright ,
E: I 'll <disfmarker> I 'll start .
E: It 's , uh , one thirty - five .
E: seventeen
E: OK
