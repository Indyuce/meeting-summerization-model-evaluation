{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.92.0-py2.py3-none-any.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting httplib2<1.dev0,>=0.15.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0.dev0,>=1.19.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /workspace/.miniconda3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, httplib2, cachetools, rsa, pyasn1-modules, googleapis-common-protos, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.3.1 google-api-core-2.11.1 google-api-python-client-2.92.0 google-auth-2.21.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.59.1 httplib2-0.22.0 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 uritemplate-4.1.1\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-uaf34nd3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-uaf34nd3\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 30ed3adf474aaf2972ab56f5624089bc24a6adf3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers==4.31.0.dev0)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0.dev0)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /workspace/.miniconda3/lib/python3.10/site-packages (from transformers==4.31.0.dev0) (4.51.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests->transformers==4.31.0.dev0) (2022.12.7)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7308539 sha256=572e932b29f9d5a981fbb63006ea1a3b03ef2d0abaa21807b30de10eb726b3fd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mc0_du5j/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, regex, pyyaml, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 pyyaml-6.0 regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0.dev0\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-t6nc09mj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-t6nc09mj\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 95bffdec4326acf6a5d1c3dbaa857a26502aa265\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from accelerate==0.21.0.dev0) (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.21.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0.dev0) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0.dev0) (1.2.1)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=241741 sha256=6f54a2971974f8f9c7eb365719725e8a5d0357ab55bc1718cc51e01e959ee2b1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-im_59kwc/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0.dev0\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.miniconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n",
      "Requirement already satisfied: torch in /workspace/.miniconda3/lib/python3.10/site-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: filelock in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /workspace/.miniconda3/lib/python3.10/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.miniconda3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /workspace/.miniconda3/lib/python3.10/site-packages (from scipy) (1.24.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n",
    "!pip install bitsandbytes>=0.39.0\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git\n",
    "!pip install tiktoken\n",
    "!pip install torch\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 13:43:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070         Off| 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   55C    P8               16W / 220W|     15MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1165      G   /usr/lib/xorg/Xorg                            9MiB |\n",
      "|    0   N/A  N/A      1319      G   /usr/bin/gnome-shell                          4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:      181108932    10473132    73337164     5609268    97298636   163382608\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8316f3ca56c94b1eaf02767682c6c0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      4\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:484\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    483\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:2904\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2895\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2897\u001b[0m     (\n\u001b[1;32m   2898\u001b[0m         model,\n\u001b[1;32m   2899\u001b[0m         missing_keys,\n\u001b[1;32m   2900\u001b[0m         unexpected_keys,\n\u001b[1;32m   2901\u001b[0m         mismatched_keys,\n\u001b[1;32m   2902\u001b[0m         offload_index,\n\u001b[1;32m   2903\u001b[0m         error_msgs,\n\u001b[0;32m-> 2904\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   2923\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3244\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3243\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3244\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3248\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3249\u001b[0m     state_dict,\n\u001b[1;32m   3250\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3254\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3255\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:460\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'legendhasit/xgen-7b-8k-inst-8bit'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub[\"cli\"]\n",
    "!huggingface-cli delete-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found 12 samples: ['sample_10_9852.txt', 'sample_11_10498.txt', 'sample_12_11166.txt', 'sample_1_4693.txt', 'sample_2_11567.txt', 'sample_3_12019.txt', 'sample_4_13389.txt', 'sample_5_1343.txt', 'sample_6_10232.txt', 'sample_7_11826.txt', 'sample_8_7292.txt', 'sample_9_4578.txt']\n"
     ]
    }
   ],
   "source": [
    "def mkdir(folder_path):\n",
    "    try:\n",
    "        os.mkdir(folder_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "# Define prompt template\n",
    "# ==========================================================================================\n",
    "PROMPT_TEMPLATE = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "<UI> Uh, making a profit of fifty million Euros.\n",
    "<ID> Alright so twenty five.\n",
    "<ME> Mm 'kay.\n",
    "<UI> So, it's go gonna have to be be pretty damn trendy.\n",
    "<ID> So yeah, I've The only the only remote controls I've used usually come with the television, and they're fairly basic.\n",
    "<UI> Yeah.\n",
    "<ME> Mm-hmm.\n",
    "<UI> Yeah.\n",
    "<ID> So uh Mm.\n",
    "<UI> Yeah, I was thinking that as well, I think the the only ones that I've seen that you buy are the sort of one for all type things where they're, yeah.\n",
    "<ME> Yeah the universal ones.\n",
    "<ME> Yeah.\n",
    "<UI> So presumably that might be an idea to put into.\n",
    "<ID> But but to sell it for twenty five you need a lot of neat features.\n",
    "<PM> Slim.\n",
    "<ID> For sure.\n",
    "<ME> Yeah.\n",
    "<UI> Yeah, yeah.\n",
    "<UI> Uh 'cause I mean, what uh twenty five Euros, that's about I dunno, fifteen Pounds or so?\n",
    "<ME> Mm-hmm, it's about that.\n",
    "<UI> And that's quite a lot for a remote control.\n",
    "<ID> Yeah, yeah.\n",
    "<ME> Mm.\n",
    "<ME> Um well my first thoughts would be most remote controls are grey or black.\n",
    "<ME> As you said they come with the TV so it's normally just your basic grey black remote control functions, so maybe we could think about colour?\n",
    "<UI> Uh-huh.\n",
    "<UI> Mm-hmm.\n",
    "<ME> Make that might make it a bit different from the rest at least.\n",
    "<ME> Um, and as you say, we need to have some kind of gimmick, so um I thought maybe something like if you lose it and you can whistle, you know those things?\n",
    "<UI> Okay.\n",
    "<UI> The the keyrings, yeah yeah.\n",
    "<ME> Because we always lose our remote control.\n",
    "<ID> Right.\n",
    "<UI> Okay, that's cool.\n",
    "<PM> Uh yeah uh, being as a Marketing Exper Expert I will like to say like before deciding the cost of this remote control or any other things we must see the market potential for this product like what is the competition in the market?\n",
    "<PM> What are the available prices of the other remote controls in the prices?\n",
    "<PM> What speciality other remote controls are having and how complicated it is to use these remote controls as compared to other remote controls available in the market.\n",
    "<UI> Okay.\n",
    "<PM> So before deciding or before finalising this project, we must discuss all these things, like and apart from this, it should be having a good look also, because people really li uh like to play with it when they are watching movies or playing with or playing with their CD player, MP three player like any electronic devices.\n",
    "<ME> Okay.\n",
    "<ME> Mm.\n",
    "<ME> Mm-hmm.\n",
    "<ME> Mm-hmm.\n",
    "<PM> They really want to have something good, having a good design in their hands, so, yes, all this.\n",
    "<ME> Yeah.\n",
    "<UI> Okay.\n",
    "<UI> 'Kay.\n",
    "<ID> Uh, what do we think a What do we think a good size would be for this?\n",
    "<UI> So, we're looking for 'Kay.\n",
    "<UI> We're Sorry, carry on.\n",
    "<ID> 'Cause I I know as you add more buttons to the remote it sometimes gets so big and clunky and there's just like a hundred buttons on it, or you could have a really small slim one but then you could lose it easily.\n",
    "<ME> Yeah.\n",
    "<UI> Mm-hmm.\n",
    "<UI> Mm-hmm.\n",
    "<ME> Yeah.\n",
    "<ME> Then you lose it, yeah.\n",
    "<UI> Okay.\n",
    "<ME> Kind of um, maybe more like a PDA kind of, just hand held, like, 'cause Yeah.\n",
    "<UI> For for uh remember we're trying to make it for twelve Euros fifty.\n",
    "<ME> No, I wasn't, no sorry I wasn't thinking of the screen of like a PDA but Okay.\n",
    "<UI> Okay well right we'll have to um I'll we're k having another meeting in half an hour so um we should all look into a bit uh, oh actually, no, we'll allocate.\n",
    "<UI> So you do the looking around at other remote controls.\n",
    "<PM> Yeah.\n",
    "<UI> Um, if you could maybe come up with sort of shapes and suggested shades or whatever, and you could look into um basically how how it's made IE like how you make it all in one, how what sort of materials are available to you whatever.\n",
    "<UI> And obviously, other instructions will come from the personal coach.\n",
    "<ID> Right.\n",
    "<UI> Which will probably just usurp what I said so Shapes and colours and um basically how to make it attractive.\n",
    "<ME> So you want me to look at shapes and everything you said?\n",
    "<ME> Yep.\n",
    "<ME> Okay.\n",
    "<UI> Uh.\n",
    "<ME> Mm-hmm.\n",
    "<UI> And you look at competition and design.\n",
    "<PM> Yep.\n",
    "<UI> Cool.\n",
    "<ME> Okay.\n",
    "<ID> Okay.\n",
    "<UI> So we have uh Um.\n",
    "<ID> Wait for emails?\n",
    "<PM> Uh.\n",
    "<ID> Hmm.\n",
    "<UI> Okay, groovy.\n",
    "<UI> And no doubt we'll get um Sorry.\n",
    "<ME> Oh no, .\n",
    "<ME> Sorry it's okay.\n",
    "<UI> We'll get um warnings for next meetings as well.\n",
    "<ME> Okay, cool.\n",
    "<UI> Okay.\n",
    "<UI> I shall I can't imagine these are worth much.\n",
    "<UI> Okay.\n",
    "<PM> Hmm.\n",
    "<UI> Fashion into electronic.\n",
    "<UI> Okay.\n",
    "\n",
    "### Assistant: The group discussed their initial ideas about the features that they wanted to integrate into the design. They discussed making a universal remote with a locator function. They also discussed the shape and the number of functions in the main interface. The Project Manager instructed the Marketing Expert to examine competitors' remotes, the User Interface Designer to research possible shapes and colors, and the Industrial Designer to research possible materials and the necessary internal components of the device.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "<ID> So welcome.\n",
    "<ID> The first kick-off meeting.\n",
    "<ID> What shall we do?\n",
    "<ID> First the opening, then the rest.\n",
    "<ID> What are we going to do.\n",
    "<ID> We m have to make a new remote control.\n",
    "<ID> It has to be original, trendy and user-friendly.\n",
    "<ID> So we will get back th on that.\n",
    "<ID> First we have to make a functional design.\n",
    "<ID> After that we have to make a conceptual design, and then after that a detailed design.\n",
    "<ID> So we'll discuss that later.\n",
    "<ID> First we have a look at.\n",
    "<ID> So first to we have to make a small painting.\n",
    "<ID> What have do we have to do.\n",
    "<ID> First you can save the documents.\n",
    "<ID> We have to do that every time we make something.\n",
    "<ID> You can print it.\n",
    "<ID> No.\n",
    "<ID> And we have to use the pen and the eraser.\n",
    "<ID> So Now.\n",
    "<ID> We all have to use this one.\n",
    "<ID> You have to make your own favourite animal.\n",
    "<ID> So I'll make an example.\n",
    "<ME> Yep.\n",
    "<ID> First don't touch that things.\n",
    "<ID> You can use the pen.\n",
    "<ID> And then you can make um something.\n",
    "<UI> Nice.\n",
    "<ID> Um you can change some things.\n",
    "<ID> Um format, line, and change it.\n",
    "<ID> And you can change the colour.\n",
    "<UI> An elephant.\n",
    "<ID> So that's it.\n",
    "<ID> So So and after it you have to save it.\n",
    "<ME> Okay.\n",
    "<ID> Now we can make a new one.\n",
    "<ID> You have to paint now.\n",
    "<ME> Oh.\n",
    "<ID> So you're next.\n",
    "<UI> 'Kay.\n",
    "<ME> Well we will try.\n",
    "<ME> Where it going?\n",
    "<PM> Hmm.\n",
    "<PM> That's uh strange.\n",
    "<ID> What is going on?\n",
    "<UI> pop-ups.\n",
    "<ID> What are you What?\n",
    "<ME> Hmm.\n",
    "<UI> What is this, Pictionary.\n",
    "<ME> Uh Mm.\n",
    "<ID> Um Is a It is a It is a A duck.\n",
    "<UI> Uh a bird.\n",
    "<UI> Bird.\n",
    "<ME> So Now save?\n",
    "<UI> Yeah.\n",
    "<ID> Yes.\n",
    "<ID> Hmm.\n",
    "<ME> Now uh blank?\n",
    "<ID> Blank, yes.\n",
    "<PM> Yeah.\n",
    "<ME> Yeah.\n",
    "<ID> Okay next one.\n",
    "<PM> Okay.\n",
    "<PM> Let's try this.\n",
    "<UI> Whoo.\n",
    "<PM> Uh Um.\n",
    "<ME> Yeah, yeah.\n",
    "<PM> Mm-hmm.\n",
    "<PM> Mm.\n",
    "<UI> Oh not.\n",
    "<UI> Oh.\n",
    "<ID> Oh.\n",
    "<UI> Okay.\n",
    "<UI> Okay.\n",
    "<UI> Yeah.\n",
    "<UI> No problem.\n",
    "<UI> Shit happens.\n",
    "<ME> I'm not getting anything uh on my screen now.\n",
    "<ME> Okay.\n",
    "<UI> A parrot.\n",
    "<ME> Wow.\n",
    "<UI> Ish.\n",
    "<ME> Oh.\n",
    "<UI> He did it before.\n",
    "<PM> Uh No, no.\n",
    "<PM> Yeah.\n",
    "<PM> Okay.\n",
    "<ME> Nice.\n",
    "<UI> Oh.\n",
    "<ID> Very good.\n",
    "<PM> Uh blank.\n",
    "<UI> Thank you.\n",
    "<ID> Okay.\n",
    "<ID> Very good.\n",
    "<ID> So um you can always go back.\n",
    "<ID> So That's it.\n",
    "<ID> So that was two.\n",
    "<ID> Now next.\n",
    "<ID> The budget.\n",
    "<ID> The b Uh we will sell the t at twenty five Euros.\n",
    "<ID> And we have only twenty of twelve and a half Euro to make it.\n",
    "<ID> So now we have to think about what we will make.\n",
    "<ID> First I wanna hear from you.\n",
    "<ID> Uh what are your experiences with remote controls.\n",
    "<ID> So F first.\n",
    "<UI> Uh I will start.\n",
    "<UI> Uh Big one, they are uh not easy to use.\n",
    "<UI> Um I have one set and uh a remote control, when I dropped it, uh it broke.\n",
    "<UI> So that won't be uh our goal, I think.\n",
    "<PM> No.\n",
    "<UI> And uh g big buttons, m uh that's easier to use than uh I think.\n",
    "<UI> Not all the small buttons, you don't know Big buttons, positive.\n",
    "<ID> Is this positive or negative, that uh big buttons?\n",
    "<ID> Positive.\n",
    "<UI> All all small buttons like when you have uh like a hundred buttons on your remote control, you won't know what they're working for.\n",
    "<ID> Okay.\n",
    "<ID> What are your experiences?\n",
    "<PM> Uh well I think the the the goal of a remote control is that it's it it has an influence on the TV set.\n",
    "<PM> And that it controls the channels and the the volume.\n",
    "<ID> Mm.\n",
    "<PM> And uh I I I think it's positive if there's a a LED uh uh a LED on the corner of the of the remote.\n",
    "<PM> So that you know it s it still has batteries on it in it.\n",
    "<PM> And that if you push the button the LED uh gives a light, and uh and you see that it's working.\n",
    "<PM> And uh yeah.\n",
    "<PM> Uh Yeah, but No no no.\n",
    "<ID> So and do they always have that?\n",
    "<PM> But I my my experience is that it it it's convenient to have that.\n",
    "<ID> It's easy to you.\n",
    "<PM> Yeah.\n",
    "<ID> Okay.\n",
    "<PM> Yeah.\n",
    "<ID> 'Kay.\n",
    "<ME> Uh at home we have a TV, a video uh recorder, a DVD player, and a satellite receiver.\n",
    "<ME> We have uh four distinctive remote controls for that.\n",
    "<UI> Thank you.\n",
    "<ME> That's not really ea easy.\n",
    "<UI> Help also.\n",
    "<ME> So it would be nice if we have one for all.\n",
    "<UI> Thank you.\n",
    "<ME> And we also had a remote control for our radio set.\n",
    "<ME> But um i it it had a lot of buttons on it, and you didn't know which one was what.\n",
    "<ME> And it was uh uh v not easy to use.\n",
    "<ME> So we n barely used it.\n",
    "<ID> Okay so they have too much.\n",
    "<ID> So next.\n",
    "<PM> Hmm.\n",
    "<ID> For our own remote control we have to think how do we make it.\n",
    "<ID> So what ideas do you have for it, for the new remote control?\n",
    "<ID> What what does it have to have?\n",
    "<UI> The weight.\n",
    "<UI> Not not too heavy.\n",
    "<ID> Not too heavy.\n",
    "<UI> Not much buttons.\n",
    "<ID> Yes.\n",
    "<ID> Yeah.\n",
    "<UI> Bust-free.\n",
    "<UI> That when you drop it, it won't break.\n",
    "<UI> Like uh some kind of rubber on it.\n",
    "<UI> Or hard uh hard plastic.\n",
    "<UI> Uh buttons not too small.\n",
    "<UI> Uh something like when you uh lose your uh remote control, sometimes it happen.\n",
    "<ID> Yes.\n",
    "<UI> Uh it between the couch and you can't find it.\n",
    "<UI> When you push a but a button on the TV, then you hear some uh some sort of bleep.\n",
    "<ID> Like a phone.\n",
    "<UI> And then you uh, hey there there's remote control.\n",
    "<ME> Yeah.\n",
    "<ID> Okay.\n",
    "<PM> Yeah.\n",
    "<ID> So, that's.\n",
    "<UI> Next.\n",
    "<PM> Yeah well that's that are good ideas.\n",
    "<PM> Uh Yeah well the LED on the corner, that that indicates that it's working.\n",
    "<PM> If you push a button.\n",
    "<PM> Um Yeah.\n",
    "<PM> And looking on the budget, not too expensive uh material.\n",
    "<PM> So probably plastic or something.\n",
    "<PM> Uh Mm no.\n",
    "<ID> Okay.\n",
    "<ME> Yeah I think it uh from a marketing point of view, it also has to look nice.\n",
    "<ME> Or you won't sell it.\n",
    "<ID> Yes.\n",
    "<ME> And um yeah uh on our website we can see what products we already have.\n",
    "<ME> And it should work with as many uh as possible of them.\n",
    "<ID> Okay.\n",
    "<ID> This is It has to be compatible with other things.\n",
    "<ME> Yes.\n",
    "<ID> Okay.\n",
    "<UI> I have one more idea.\n",
    "<UI> Just popped up.\n",
    "<ID> Yes?\n",
    "<UI> Uh it it won't take a lot of batteries.\n",
    "<UI> So you don't won't have to change the batteries uh once a week or uh once every two weeks.\n",
    "<ID> No battery use.\n",
    "<ID> So more ideas?\n",
    "<ID> No okay.\n",
    "<ID> It's only the first ideas.\n",
    "<ID> So uh what are we going to do now is Next meeting is in half an h hour.\n",
    "<ID> Uh Okay.\n",
    "<ID> Next meeting, half an hour.\n",
    "<ID> Um, what you have to do.\n",
    "<ID> Well look on your.\n",
    "<ID> And Next instructions you'll get in your email.\n",
    "<ID> So This is the first meeting.\n",
    "<ID> See you later in half an hour.\n",
    "<PM> Yes.\n",
    "<UI> Okay.\n",
    "<ME> Okay.\n",
    "<UI> Thank you.\n",
    "\n",
    "### Assistant: For the first meeting, the task of designing a remote control was briefly introduced along with the plan for the subsequent meetings. The group then drew animals to practise using the drawing platform. They discussed their likes and dislikes regarding current remote controls, including ease of use, multiple systems and power indicators. They then offered suggestions as to what they would like from their remote. They would like the remote to be durable, for it to include a device to help find it when lost and not use too many batteries.\n",
    "\n",
    "### Human: Summarize the following text.\n",
    "\n",
    "{text}\n",
    "\n",
    "### Assistant:\"\"\"\n",
    "\n",
    "# Load samples from dataset\n",
    "# ==========================================================================================\n",
    "samples = os.listdir('input/texts')\n",
    "samples = [sample for sample in samples if sample.endswith('.txt')]\n",
    "samples.sort()\n",
    "n_samples = len(samples)\n",
    "print('-- Found', n_samples, 'samples:', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHARACTER_CHUNK_SIZE = 2000 * 3\n",
    "\n",
    "def chunkize(text):\n",
    "    \"\"\"\n",
    "    Greedy implementation of a dialogue transcript chunking algorithm. This method returns a list of transcript chunks.\n",
    "    - It priorities stability over performance. There is a set maximum chunk size for LLM inference stability. Really long utterances bypass this limit.\n",
    "    - It guarantees the cuts are made at utterance ends.\n",
    "\n",
    "    !! WARNING !! The maximum size is in characters, not tokens. A good upper bound shall be used as there are\n",
    "    no clear and easy correspondance between characters and tokens, as it obviously depends on the model tokenizer.\n",
    "\n",
    "    Dialogue format recognized (used in the HF AMI dataset):\n",
    "    ----------------------\n",
    "    <A> Hello!\n",
    "    <B> Hey there\n",
    "    <A> What have you been up to\n",
    "    <B> Not much honestly\n",
    "    ----------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    chunks = [] # Final list of transcript chunks. This makes up the loop invariant\n",
    "    utterances = text.split('\\n') # Transcript is split into sentences\n",
    "    current_chunk = ''\n",
    "\n",
    "    # While there is still an utterance to process\n",
    "    while len(utterances) > 0:\n",
    "        utterance = utterances.pop()\n",
    "\n",
    "        # Add to current chunk and proceed to next\n",
    "        if len(current_chunk) + len(utterance) <= MAX_CHARACTER_CHUNK_SIZE:\n",
    "            if len(current_chunk) > 0:\n",
    "                current_chunk += '\\n'\n",
    "            current_chunk += utterance\n",
    "        \n",
    "        # Utterance is larger than maximum chunk size\n",
    "        elif len(current_chunk) == 0:\n",
    "            chunks.append(current_chunk)\n",
    "            chunks.append(utterance)\n",
    "            current_chunk = ''\n",
    "\n",
    "        # Current chunk is big enough, append to list and create new one\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = utterance\n",
    "\n",
    "    if len(current_chunk) > 0:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "<ME> Okay, see you.\n",
      "<UI> Okay, so you can I guess we'll see you for lunch in a sec?\n",
      "<ME> Cool.\n",
      "<UI> Right on time.\n",
      "<UI> Okay?\n",
      "<ME> Okay.\n",
      "<UI> No, we have we have after lunch we have thirty minutes to ourselves to prepare, so that's fine, w before lunch we just have to complete the questionnaire and some sort of summary.\n",
      "<ME> Sorry, but um the next meeting um are we going to have it um right after lunch or shall we prepare our To prepare, okay, yeah, that's good.\n",
      "<ME> Hmm.\n",
      "<UI> Components, yeah.\n",
      "<ID> Con components, oh.\n",
      "<ID> Wha what was it again that I was supposed to look into?\n",
      "<ME> Uh something conceptual, yeah.\n",
      "<UI> You'll be looking you'll be looking at the user interface concept, on something conceptual and you're watching trends to see how we go and surely voice recognition'll fall off the map or something that um we'll keep keep our options op hmm?\n",
      "<ID> I guess I'll find out.\n",
      "<UI> Yeah.\n",
      "<ME> Yeah.\n",
      "<UI> Whatever that means.\n",
      "<UI> Yeah?\n",
      "<ID> Right.\n",
      "<UI> Um as to where we're going from here, you're going to look at the components concept.\n",
      "<PM> Okay, cool.\n",
      "<UI> So, if you put them in there, we'll all be able to see them and refer to them if we need to.\n",
      "<PM> That's me done.\n",
      "<ME> Yeah.\n",
      "<PM> Okay, so that's good.\n",
      "<UI> Technical requirements and something something, yeah.\n",
      "<ID> No.\n",
      "<UI> No, they're all called something slightly different.\n",
      "<PM> But is everyone's called functional requirements?\n",
      "<PM> There you go.\n",
      "<UI> Yeah, then you don't have to email them.\n",
      "<UI> Oh yeah, put them in there.\n",
      "<ME> Oh so so we'll just put them i there, we we yeah, w we won't even okay.\n",
      "<PM> Okay.\n",
      "<UI> Yeah, that would be great.\n",
      "<PM> Oh, so y you want our um PowerPoint presentations in there, hey?\n",
      "<UI> Yeah, and email them round.\n",
      "<ID> Yeah, yeah in that one, right yeah.\n",
      "<ME> It's just yeah, yeah.\n",
      "<ME> Did you find it?\n",
      "<UI> So I'll put it I'll put them there as soon as I've written them.\n",
      "<ME> Yeah.\n",
      "<ID> Yeah.\n",
      "<UI> It should be on your desktop, so on the yeah.\n",
      "<ID> So where exactly is this i Ah, okay.\n",
      "<UI> Um I'll put the minutes in that project documents folder, but I'll send you an email when I do it, so that you know.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Send me your presentations so that I can use them to make the minutes, and then we've got a lunch break and after lunch we go back to our own little stations and have thirty minutes more work.\n",
      "<UI> What we have to do now is to go back to our little places, complete our questionnaire and some sort of summarisation, which y you'll get immediately by email.\n",
      "<ID> Okay.\n",
      "<ID> Right.\n",
      "<ME> Mm-hmm.\n",
      "<ME> The major ones, yeah.\n",
      "<UI> But if we go away with that that kind of general um specification in mind that we're looking at fifteen to thirty five year olds, we want it to look simple, but still have the buttons so it's easy to use, but only those key buttons, the major buttons and then one sort of menu one, and then voice recognition included as an option um but that obviously needs a little bit more working out as to whether it's really feasible and some of those problems we were mentioning um.\n",
      "<UI> Okay, I think we're gonna have to wrap this up um.\n",
      "<UI> Yeah.\n",
      "<PM> Yeah, definitely, yeah.\n",
      "<ID> Alright, yeah.\n",
      "<UI> The l Well that's right, but it solves the problem of having different noises.\n",
      "<PM> Yeah, 'cause it's it's quite important that you don't lose the the bit to locate the remote control.\n",
      "<ME> Okay, yeah, mm-hmm.\n",
      "<ID> Right, yeah, yeah, yeah.\n",
      "<ME> Oh yeah, yeah.\n",
      "<ME> Okay.\n",
      "<UI> That's but then if you're buying the remote separately, but y you could have something, but i if it was something that you could like stick onto the TV or something, some like a two p if you bought it in a two part pack, so one part attaches to the TV.\n",
      "<UI> Mm-hmm.\n",
      "<ID> So uh wh another thing uh that can be used is that uh there can be a beeper button on the TV, so you can go and press that button and um and the remote control, wherever it is, it'll beep, so we we can probably come to know where it is.\n",
      "<UI> Yeah.\n",
      "<ID> Mm.\n",
      "<UI> Yeah.\n",
      "<ID> Yeah.\n",
      "<UI> Yeah.\n",
      "<ME> No, but I I I was just defending the the fact why why we want to keep the remote control close to us, a and uh not to yell at it from the distance.\n",
      "<UI> Yeah.\n",
      "<ME> Yeah, yeah, yeah.\n",
      "<UI> Mm.\n",
      "<ID> Mm yeah and it might become very difficult from a distance for the television to understand what you're saying because of the noise factor for the remote control being cl I mean it'll it'll mm.\n",
      "<PM> Yeah, yeah, I suppose nearer to you but a b like if you have surround sound then Yeah.\n",
      "<ME> Yeah, but then the remote control I think I mean um the idea is kind of it's it's not that it's sitting there on on top of the television, because then you could already yell at the television and you wouldn't you you wouldn't need the remote control, so the remote control is still something you keep n near yourself.\n",
      "<UI> Alright.\n",
      "<UI> Yeah.\n",
      "<PM> It's more like if you lost it and it's down the sofa sometime, you can yell at it and it'll just change it, you can look for it later, yeah.\n",
      "<PM> Yeah, you know, so you have to have the remote control.\n",
      "<UI> So that you can yell at it, yeah.\n",
      "<PM> Do you not think that defeats the object of having voice recognition on a remote control though?\n",
      "<PM> Yeah.\n",
      "<UI> Yeah.\n",
      "<ID> Mm.\n",
      "<ME> Yeah but m but on the other hand, remote control isn't as close to you you probably might just just uh speak into it and and the TV would be already further away, so it might not pick up the other things coming from there.\n",
      "<UI> But that's definitely a possibility.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Yeah, that's Right.\n",
      "<ID> Alright.\n",
      "<PM> Yeah, yeah, and that would be really annoying.\n",
      "<UI> Watch Sky and yeah.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> Yeah, but then the code word would be even more important, because I mean Sky advertise on every channel, don't they, you know, so then it would be you'd be watching Charmed, and then the Sky advert would come on and it would change to Sky.\n",
      "<UI> So that if that was in the the voice recognition, that would be great.\n",
      "-----------------------------------------\n",
      "<ID> Yeah, so if uh if something like that can be incorporated, some kind of Mm-hmm.\n",
      "<UI> Uh-huh.\n",
      "<PM> Yeah, that would be another way to do it.\n",
      "<UI> Uh-huh.\n",
      "<ID> If we can do with away with that, our product can be really popular uh in the sense that uh a person can say, I want to watch uh ITV one instead of saying that I want to go onto channel number forty five.\n",
      "<ID> What wh uh what I was thinking is that there is this uh separation between what the channels are on TV and how they are numbered on the remote control.\n",
      "<UI> Mm.\n",
      "<UI> Yeah.\n",
      "<ID> W What uh Mm.\n",
      "<ID> Mm.\n",
      "<UI> Yeah, I think we need both.\n",
      "<ME> Yeah, w well now the v the voice recognition if if it works wonderfully w we could possibly do away with all buttons, but I think this is not really the right moment yet, because people are just so used to buttons and um, yeah it's it's kind of safer, so we we need both, so the voice recognition would be just an extra, it wouldn't really reduce the size of the remote.\n",
      "<PM> I don't think there's a lot of uh voice recognition remote controls.\n",
      "<ME> Yeah.\n",
      "<ME> Yeah but uh um Yeah, yeah sure, yeah, yeah.\n",
      "<UI> Um, so if we go for the the fifteen to thirty five age group and then of course we're going to get th anyone who's older than thirty five who wants to look young and hip and trendy and has the money, then they'll they'll still go for the same advertising.\n",
      "<UI> Yeah, but maybe if you wanna look into that just to just to check.\n",
      "<ME> Yeah.\n",
      "<ID> Okay, so it seems like a feasible thing to implement uh for for a limited yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Yeah.\n",
      "<ID> Right.\n",
      "<PM> Although I only watch Charmed, so really I wouldn't know but like so you'd just say remote five, you know, remote ten, remote one two nine.\n",
      "<ID> Mm.\n",
      "<UI> Yeah.\n",
      "<PM> I mean how often do people say remote on TV?\n",
      "<PM> So like when you say change, except that's being said quite a lot on TV, so maybe like, you know, remote.\n",
      "<UI> Mm.\n",
      "<PM> Do you know what I mean?\n",
      "<ID> O Right.\n",
      "<ID> Okay.\n",
      "<ID> Right.\n",
      "<PM> S so y you'd maybe need a code word.\n",
      "<ID> Right.\n",
      "<PM> Yeah.\n",
      "<ME> An Yeah.\n",
      "<UI> With um but with a TV remote it's gonna be quite limited if we're t saying the main things people want to do is on off channel five, louder, tha that should be relatively simple.\n",
      "<UI> Yeah.\n",
      "<PM> I don't know.\n",
      "<ME> Yeah.\n",
      "<ME> Yeah.\n",
      "<ID> But how frequently do we use it anyway and um uh h ho how good is it, you know uh voice recognition softwares are still quite uh Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> Because you have like I mean every mobile phone now has like call this person and it calls them.\n",
      "<PM> You do have it in your mobile phone though, don't you?\n",
      "<ID> Uh and uh Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um I was having a a general outlook on um m most like sophisticated features, but voice recognition itself I'm not very sure about, because one of the p uh things that Cat pointed out was uh uh how do we go about implementing it?\n",
      "<UI> Is that gonna have a an implication for the technical specs?\n",
      "<ME> Yeah.\n",
      "<ID> Mm.\n",
      "<PM> No, do totally.\n",
      "<UI> Yeah, if we ta if we take fifteen to thirty five, but that then does imply that we should try and incorporate voice recognition.\n",
      "<ME> Yeah.\n",
      "<PM> Is not a massive difference, you know.\n",
      "<UI> Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> You know, so I mean that and the disposable income and I don't think it's something to ignore, you know.\n",
      "<UI> Yeah.\n",
      "<PM> I think I think the fact that, you know, ninety one point two percent of fifteen to twenty five year olds are saying yes, I would pay more for a voice recognition remote control, does say quite a lot really.\n",
      "<PM> Yeah.\n",
      "<ME> Or w maybe we can just kind of uh uh Yeah, but at the same time I think maybe we can we can just decide to to have both of these groups as our target, because actually I mean they're all still re young people.\n",
      "<ID> So mm uh are are are Mm.\n",
      "<UI> Yeah.\n",
      "<ME> Yeah, we're still yeah.\n",
      "<ID> Bu but even even in the case of twenty five to thirty five it's quite popular, right?\n",
      "<UI> Mm.\n",
      "<PM> Yeah, I d well we've we've got quite a d decent TV.\n",
      "<ID> Mm.\n",
      "<ME> The s the stu yeah, and the remote control might not yeah, it might not even function with the old TV.\n",
      "<ME> Common, the students yeah, yeah.\n",
      "<PM> We didn't have a TV last year, and everyone thought we were off our heads, you know.\n",
      "<UI> But do they But the TVs are often kind of someone's old TV that's blah blah and be a bit strange to have a fancy rome remote.\n",
      "<ID> Yeah.\n",
      "<UI> Yeah.\n",
      "<ME> Yeah this this is not unaffordable, but the problem is whether people need it, whether they do have a TV to use its full Yeah.\n",
      "<PM> You know, I think Yeah, I d I don't know many people without a TV.\n",
      "<UI> Yeah.\n",
      "<PM> No, I mean that's what, that's like fifteen Pounds?\n",
      "<UI> Yeah, and if we're if we're talking twenty five Euros as a price, that's not unaffordable, even for young people.\n",
      "<PM> Um so I mean like it is an age group to target, really, I think.\n",
      "<ID> So you're more likely to b Yeah.\n",
      "<UI> Yeah.\n",
      "<PM> You're still learning to drive actually, so that just costs more than a car, but yeah.\n",
      "<ID> Yeah.\n",
      "<UI> Kids.\n",
      "<ID> Alright.\n",
      "<UI> Yeah, they've got no commitments and usually not a car and all of those things.\n",
      "<UI> Yeah.\n",
      "<PM> Yeah, I kn I mean I know what you're saying about the fifteen to twenty five year olds, but I mean it has been proven that that people of that age group have a higher disposable income because they don't have like I mean, you know, if you're at university, you're paying your rent, but you don't have a mortgage, you don't have a life insurance policy, you don't normally have a car, yeah, so.\n",
      "<ID> So even they are seventy six percent, is that high amount?\n",
      "<UI> Mm-hmm.\n",
      "<PM> Yeah.\n",
      "<ME> It was seventy something, yeah, yeah.\n",
      "<PM> Seventy six point three percent.\n",
      "<ID> That's alright, if you can just look it up on your computer, wh uh um people between twenty five to thirty five, uh how popular was so it was sti still still quite popular amongst them.\n",
      "<UI> Here, let me Yeah.\n",
      "<ID> Oh, oh, okay.\n",
      "<PM> Do you want me to Yeah.\n",
      "<PM> Oh, I've unplugged it.\n",
      "-----------------------------------------\n",
      "<ID> But uh still, if if you can go back to that slide and uh, how popular was it?\n",
      "<ID> Right.\n",
      "<UI> I would've thought it's it's more that twenty five to thirty five, when people are really moving out and they've got their first job and they want their nice toys and O oh it's on sorry, we unplugged it.\n",
      "<ME> Yeah, you share a television or something that yeah.\n",
      "<ME> Yeah.\n",
      "<UI> Yeah, but you don't have much money, generally.\n",
      "<PM> So, you know Yeah.\n",
      "<ID> Mm.\n",
      "<PM> Well, that's when you go to uni, isn't it?\n",
      "<ID> Right, and Right.\n",
      "<UI> Then again I guess the th where it was most popular was the fifteen to twenty five bracket and the I don't know how often they're buying televisions.\n",
      "<UI> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<ID> Bu but but the survey did say that f things like voice recognition are more popular with them, so if you want to put in something stylish, then uh th it'll certainly be more popular with this i ye with the younger people as compared to older people, yeah.\n",
      "<ID> Right.\n",
      "<ID> Right.\n",
      "<PM> Yeah, I mean that's the thing is that it didn't say in the survey, you know, whether, you know, these are the people that will pay more for a more stylish remote control, but I'm assuming, you know, yes.\n",
      "<ID> Um.\n",
      "<ID> So if we need to have a target group um then uh I think as far as the m motto of our company is concerned, if we want to have something sleek and uh you know, good looking uh we are better off targeting a younger audience then um you know, people who are comparatively elderly.\n",
      "<PM> Ca.\n",
      "<PM> Cat's.\n",
      "<ID> I think one of the very interesting things that came up in um uh Ka Kate Cat Cat's uh presentation was um uh this this issue of uh uh like voice recognition being more popular with uh younger people.\n",
      "<ID> Mm.\n",
      "<UI> So, we've got about ten, fifteen minutes to discuss Mm-hmm.\n",
      "<UI> I'm just gonna tick yes.\n",
      "<UI> Um.\n",
      "<ME> Um that's very good, very interesting.\n",
      "<ID> Okay, that's great, thanks.\n",
      "<UI> That's you, excellent.\n",
      "<PM> That's me.\n",
      "<PM> Cool.\n",
      "<ID> Hmm.\n",
      "<PM> So okay?\n",
      "<UI> Mm-hmm.\n",
      "<PM> So yeah, so maybe something where you clap and then it beeps, something a kind of sound that you don't often hear on the TV, you know, 'cause you don't want your remote control beeping every five minutes, 'cause you you'd then deliberately lose it by throwing it out the window or something.\n",
      "<PM> My flatmate and I were talking about this on the way into uni this morning and I was like I need to get one for everything.\n",
      "<PM> I know, it's weird.\n",
      "<UI> Whistle and it screams at you, yeah.\n",
      "<UI> Keys and things like that, yeah.\n",
      "<ID> Some kind of a ring, some Right.\n",
      "<ID> Mm.\n",
      "<PM> Um and then like a locator, so you know, kind of like you have for a mobile phone or not a mobile phone Yeah, that's it, you know.\n",
      "<PM> Um okay, then a long battery life, like you were talking about earlier and um, you know, I was thinking that solar power would be quite cool because, you know, your remote control just sits there, and you could just sit it in the sunshine and save the environment a bit.\n",
      "<ID> Mm.\n",
      "<ID> Mm.\n",
      "<PM> You know, so things should either be functional or beautiful or preferably both, so I think we need to aim for both.\n",
      "<PM> Um there's a there's an important thing that, you know, people use when, you know, when you're filling up your home, you know, a lot of people fill up their home with bits of crap, basically, you know, and you've got all this stuff, and you're just like, what the hell is that, who is ever gonna use it?\n",
      "<PM> Um you know, functional, so it's useful, but minimalist.\n",
      "<PM> So you have sleek, stylish, sophisticated, you know, so something that's, you know, a bit cool.\n",
      "<PM> Um okay, so these are my personal preferences.\n",
      "<PM> Cool.\n",
      "<PM> Um okay?\n",
      "<ID> Right.\n",
      "<UI> Mm.\n",
      "<PM> Um so clearly voice recognition is something to think about, but um you know I d I do wonder how well that would work given that a TV, you know, tends to be people talking and um, you know, how are you going to stop it from just flipping channels whilst watching TV.\n",
      "<PM> So you can see from that that, you know, younger people to the age of thirty five are quite likely to pay quite a lot more f well quite are quite likely to pay more for voice recognition software, whereas as people get older, they're a bit more sceptical about it and they're less willing to to try it.\n",
      "<PM> Um okay, but that shows how people whether they would pay more for voice recognition software.\n",
      "<UI> That's alright.\n",
      "<PM> Right, um sorry this is pink because I was copying and pasting the table, and I didn't have time to white it out again.\n",
      "<PM> Okay, cool.\n",
      "<PM> Yes.\n",
      "<ID> Hmm.\n",
      "<ID> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right.\n",
      "<PM> Okay, so um I mean the the RSI thing would be that, like when you have the computer keyboards and you keep your wrists up would be something that encourages you want something with an ergonomic t design that encourages good use of the remote control and you know, not straining your wrists watching TV.\n",
      "<PM> Um that yeah.\n",
      "<ID> Mm.\n",
      "<UI> The remote control.\n",
      "<PM> I think if you're watching enough TV to get repetitive strain injury from um you know, watching TV, then that's the least of your problems, but you know, it's up there.\n",
      "<UI> Mm-hmm.\n",
      "<PM> Uh that they get lost, that the uh you know, they're not intuitive and that they're bad for repetitive strain injury.\n",
      "<PM> So um okay, so this is what people find annoying about remote controls.\n",
      "<PM> Okay, cool.\n",
      "<PM> This is the bit that the email messed up for me and that's what I was fiddling about with at the beginning of the thing.\n",
      "<PM> Okay.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Mm-hmm.\n",
      "-----------------------------------------\n",
      "<PM> Yeah, so what the graph shows is that, you know, power, channel selection and volume selection are important, and the rest of them, you know, nobody really uses and so that's the the numbers along the top represent their like um their importance, you know, so on a scale of one to ten, how important is that and, you know, channel selection and volume selection are absolutely essential, and the power, well it's not quite so essential, apparently, although I don't understand how it couldn't be, um and everything else, I think, you know, you can forget about having those buttons on the remote control, 'cause they're just not needed, and they're not used.\n",
      "<UI> Mm-hmm, that's the next one along, yeah?\n",
      "<PM> What you can't see is volume selection, it's a little bit higher than all the others.\n",
      "<UI> Okay.\n",
      "<PM> Um okay, so like what it shows is how much things are used relatively and what you can clearly see from that is the thing that's used most is the channel selection.\n",
      "<ID> Mm-hmm.\n",
      "<PM> Okay, I'm gonna stop playing with the little pointy thing.\n",
      "<PM> Oh yes, cool.\n",
      "<UI> No.\n",
      "<PM> Oh.\n",
      "<PM> Back.\n",
      "<UI> I liked the, I liked the litt ooh come back.\n",
      "<PM> Um but ooh where's it go?\n",
      "<PM> What it is is um it's cones, 'cause I thought they'd be more exciting.\n",
      "<UI> Yeah.\n",
      "<UI> If you explain it to us it'll be fine.\n",
      "<PM> Mm k Okay, well, I can send it to all of you.\n",
      "<UI> Ooh, that's a bit difficult to see.\n",
      "<PM> Um so this is my little graph thing.\n",
      "<PM> Cool.\n",
      "<PM> Okay?\n",
      "<UI> Mm.\n",
      "<ID> Right.\n",
      "<ID> Mm.\n",
      "<PM> Um okay, fifty percent of users say they only use ten percent of the buttons, so that's going back to what, you know, we were saying earlier about, you know, do you need all the buttons on the remote control, they just make it look ugly.\n",
      "<PM> But you have that little thing that comes up at the bottom and tells you what's on.\n",
      "<UI> It's um switching between channels, sort of randomly going through.\n",
      "<PM> Um I dunno what zapping is, but Oh, right.\n",
      "<PM> Um current remote controls, they don't match the user behaviour well, as you'll see on the next slide.\n",
      "<PM> Uh eighty percent of users would spend more to get um you know, a nice looking remote control.\n",
      "<PM> Uh the other twenty five percent have no fashion sense.\n",
      "<PM> Um seventy five percent of users find most remote controls ugly.\n",
      "<PM> What they found is that people don't like how current remote controls are, so you know, definitely you should be looking at something quite different.\n",
      "<PM> Um okay, so.\n",
      "<PM> Not that they actually gave me any answers on the LCD screens, so I should have taken that bit out, but anyway.\n",
      "<PM> What's the most annoying things about remote controls and um the possibility of speech recognition and LCD screens in remote control.\n",
      "<PM> Um so it was all about, you know, how people feel about the look and feel of the remote control, you know.\n",
      "<PM> So what I have, wh where I've got my information from is a survey where the usability lab um observed remote control use with um a hundred subjects and then they gave them a questionnaire.\n",
      "<PM> Cool, okay.\n",
      "<UI> Excellent.\n",
      "<UI> Okay.\n",
      "<PM> It's working.\n",
      "<UI> Is it plugged in prop it's working?\n",
      "<ID> try to press oh, okay, yep.\n",
      "<UI> Hello.\n",
      "<PM> Alright, yeah.\n",
      "<UI> Uh we need to do the function key thing so that it comes up on here.\n",
      "<PM> Okay, functional requirements.\n",
      "<PM> Yep, cool.\n",
      "<UI> You set?\n",
      "<PM> Okay, cool.\n",
      "<PM> Ah, that's why it won't meet.\n",
      "<PM> Cool.\n",
      "<ME> Okay, here you are.\n",
      "<UI> Oh, I'm getting hungry.\n",
      "<ME> Okay, here it comes.\n",
      "<PM> Yeah.\n",
      "<ME> Wait.\n",
      "<ME> No.\n",
      "<ME> Uh am I going in the right direction?\n",
      "<PM> Do you wanna give me the little cable thing?\n",
      "<UI> Do you want to yeah.\n",
      "<PM> Cool.\n",
      "<UI> Sure, we can discuss that maybe after the next one.\n",
      "<ID> Cool.\n",
      "<ME> Yep.\n",
      "<UI> Mm-hmm.\n",
      "<ID> So yeah?\n",
      "<ME> Mm-hmm.\n",
      "<ID> Uh i if the if the costs allow, we can have like an LCD display and uh with um because we do want something fancy and fashionable as well.\n",
      "<ME> Yeah.\n",
      "<UI> Mm.\n",
      "<ME> Yeah.\n",
      "<ID> So well we can probably wait until t we have more knowledge on that.\n",
      "<UI> Mm.\n",
      "<ID> Uh I think the co costs will also play a big role when we come to know about them.\n",
      "<ME> I think I th I would I would think the put the buttons, but if if you have other mm proposals um.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Right.\n",
      "<ID> Yeah, and it'll make the costs yeah.\n",
      "<ME> A little screen or something, but this would be really kind of I think a lot of learning for the user and and I mean the user just wants to get um get a result um quickly, not to spend time in like um giving several orders um I dunno.\n",
      "<ID> Right.\n",
      "<ME> Um well, I think the buttons are still mm kind of the most um easy for the user to use, I mean um what other options would you have?\n",
      "<ID> But uh is is there any uh uh any thoughts on that?\n",
      "<ID> Um but um so so at this stage, uh how we go about implementing those button we will not identify or I mean in we can completely do away with buttons and uh have some kind of a fancy user interface or something like that.\n",
      "<ID> So in the u user interface requirements uh uh uh we we have been able to identify what are the basic buttons that we do want.\n",
      "<UI> Are there any questions for clarification of Maarika before we go on to the next one?\n",
      "<UI> Okay.\n",
      "<UI> Mm-hmm.\n",
      "<UI> Yeah.\n",
      "<UI> Mm-hmm.\n",
      "<UI> It's w it's just whether it's worth arguing about.\n",
      "<UI> If I mean that was the the directive that came through from management, but if we had a a decent case for that we really think it's important to include video and DVD, I could get back to them and see.\n",
      "<UI> Yeah.\n",
      "<ME> If you have questions Yeah, and also it's it's um other question is uh because there are so many different And there are so many different things that could possibly be included because besides video and DVD there are the mm um video CDs and whatever, so it might be problematic to to choose between all these possible things.\n",
      "<ME> So at the for the time being that's uh that's all.\n",
      "<UI> Mm-hmm.\n",
      "-----------------------------------------\n",
      "<ME> And yeah, the last question I had about whether we wanted to incorporate n uh more functionalities, the answer was already no because of the last minute update.\n",
      "<ME> But then um other functionalities um could be just uh there could be a menu button and you could change things on the screen then, um for example brightness and mm similar functions could be just um done through the menu.\n",
      "<ME> Um then yeah, the must-have buttons would be on off and then the channel numbers and then um the one that allows us to go to the next or the previous channel, and then volume has to be there.\n",
      "<ME> And then it must be easy to use, so it must follow some conventions um like whereabouts you find the on off button and maybe the colour tends to be red or something.\n",
      "<ME> So my personal preferences would be uh to keep the mm the whole remote control small um just like the physical size.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Um um among the findings I found that m m most of the curr mm presently available remote controls also include other mm functionalities um in their design, like operating a VCR, but they don't seem to be able to deal with DVD players, but then there are surely there are many other functionali functions that could possibly be added to them, but according to the last minute update um actually um we do not want to have all this complicated functions added to our design.\n",
      "<ME> 'Kay.\n",
      "<ID> Uh switching on off channel, uh volume, okay, that's great.\n",
      "<ID> Sorry, cou could you go back for a second?\n",
      "<ME> Um um I als okay.\n",
      "<ME> And and also the volume is very important.\n",
      "<ME> And uh w some of the main functions would be switching on, switching off, uh then the user would like to switch the channel um for example just m changing to the next channel to to flip through all all of the possible channels, or then mm uh the other possibility would be that um she might just want to choose one particular channel, so we would need the numbers.\n",
      "<ME> Um so the findings uh were um that the main function of the remote control is is just sending messages to the television set, so this quite straightforward.\n",
      "<UI> Mm-hmm.\n",
      "<ME> And yeah, and then just to um put the main function of the remote control in in words.\n",
      "<ME> And then um after having got this inspiration and having compared what I found on the web um just to think about what the de what the user really needs and what um what the user might desire as additional uh functionalities.\n",
      "<ME> Um uh my method was um to look at um other um remote controls, uh so mostly just by searching on the web and to see what um functionality they used.\n",
      "<UI> Mm-hmm.\n",
      "<ME> Um 'kay, so the method I was um adopting at this point, it's not um for the for the whole um period of the um all the project but it's just at th at this very moment.\n",
      "<ME> So I'm going to speak about technical functions design uh just like some some first issues that came up.\n",
      "<ME> Okay, let's start from the beginning.\n",
      "<UI> Okay.\n",
      "<ME> Okay, that's fine, that's good.\n",
      "<ME> Oh okay.\n",
      "<ID> Mm.\n",
      "<UI> Should yeah just wait for a moment, adjusting.\n",
      "<ME> No.\n",
      "<ME> No?\n",
      "<ME> Uh now it's okay.\n",
      "<UI> Okay, so one more time.\n",
      "<ID> And one more time.\n",
      "<ID> Okay.\n",
      "<UI> Oh, if you press if you press function and that again there's there's usually three modes, one where it's only here, one where it's only there, and one where it's both.\n",
      "<ID> Oh, that's strange.\n",
      "<ME> This is the problem, but Um.\n",
      "<UI> There we go, there we go.\n",
      "<ME> But I don't see anything I don't see anything on my computer now.\n",
      "<ME> Adjusting.\n",
      "<UI> Okay, adjusting.\n",
      "<ME> My my computer went blank now.\n",
      "<ME> Oh.\n",
      "<ID> Yeah yeah, it says something now, adjusting Okay.\n",
      "<UI> Maybe again?\n",
      "<ME> Why?\n",
      "<ME> No signal?\n",
      "<ID> It'll come up, it um uh no signal.\n",
      "<UI> Now it's coming, computer no signal.\n",
      "<ID> Oh, there it is, yeah.\n",
      "<ME> Nothin okay, something is coming up.\n",
      "<ME> Oh right, right, right, um Okay.\n",
      "<UI> It ta takes a little Oh, and have you you need to then also press on yours, function F eight, so the blue function key at the bottom and F eight.\n",
      "<ID> I it'll take some time.\n",
      "<ME> Should it just There's just nothing.\n",
      "<ME> Oh i Okay, I hope wait.\n",
      "<UI> Yeah, I thought those last minute things, they're gonna hit you the worst.\n",
      "<ME> Thanks.\n",
      "<UI> Yeah.\n",
      "<ID> Mm 'kay.\n",
      "<ID> Yeah.\n",
      "<UI> I think that has to come out of there.\n",
      "<ME> Yeah, I think since since we were discussing some um design issues then I I I would like to continue okay, yeah.\n",
      "<UI> Okay, so do you want to Yes, shall shall we pull this up?\n",
      "<ME> Yeah.\n",
      "<ID> Yeah, okay.\n",
      "<UI> Yeah, I think that will do.\n",
      "<ME> I think we need like some general discussion at the end probably.\n",
      "<UI> Are there any more questions, or shall we just skip straight to the next one and then we can discuss all of them together at the end?\n",
      "<UI> That's fine.\n",
      "<UI> Yeah.\n",
      "<ID> So so tha yeah, we definitely need to operate within our constraints, but um unfortunately I I do not have any data, so uh I just identified the functional components for that.\n",
      "<ID> Certainly, yeah.\n",
      "<ID> Yeah.\n",
      "<ID> Anything else?\n",
      "<UI> 'Cause that's something to consider, I guess, if we're if we're using more advanced technology, it might increase the price.\n",
      "<ID> Um yeah.\n",
      "<UI> Br Okay.\n",
      "<UI> Do you have any um i idea about costs at this point?\n",
      "<ME> Thanks.\n",
      "<UI> Okay.\n",
      "<ID> So anything that you would like to know or No, I don't have any idea about what each component costs.\n",
      "<ID> That's about it.\n",
      "<ID> And uh also if we can incorporate uh the latest features in our chip design, so that our um uh remote control does not become outdated soon and it's compatible with mot most uh televisions.\n",
      "<ID> This would uh help us uh to upgrade our technology at a future point of time.\n",
      "<ID> Um so i in my personal preferences um I'm hoping that we can ke keep the design as simple and clear as possible.\n",
      "<ID> Okay.\n",
      "<UI> Mm-hmm.\n",
      "<ID> Um so these are the essent so a all the functionality of the remote control, whatever new functions that we need to do, um make the chip more complicated uh and bigger, basically.\n",
      "-----------------------------------------\n",
      "<ID> Um the there can be uh a bulb here or something to indicate whether the remote is on or communicating.\n",
      "<ID> So whe when the user presses a button, it feeds into the chip and the chip then generates a response and takes the response to an infrared terminal, um which then so the output of the chip is an infrared bit code, which is then communicated to the remote site, which h has an infrared receiver.\n",
      "<ID> There is a user interface here.\n",
      "<ID> So if uh if this is our energy source and this is a cell, uh it communicates uh it feeds energy into the into the chip, which basically finds out h uh how how to do everything.\n",
      "<ID> The user interf interface communicates with the chip, so I'll basic go over to the Okay.\n",
      "<ID> Um there's basically an energy source at the heart uh which feeds into the chip and the user interface.\n",
      "<ID> Okay, so he he here is a functional overview of the remote control.\n",
      "<ID> Um also the management wants that um our design should be unique uh it so it should incorporate um colour and the slogan uh that our company um has it as its standard.\n",
      "<ID> How however, our our remote control would only be dealing uh with the the use for television, in order to keep things simple.\n",
      "<ID> And the reason why teletext is outdated because uh of internet and uh the availability of internet over television.\n",
      "<ID> Um also uh the remote control should be used only for television, because incorporating other features um makes it more comp complex.\n",
      "<ID> Um okay, so e the mee email said that teletext is now outdated, so we need to do away with that functionality of the remote control.\n",
      "<ID> Um so basically uh the as I told you the identification of how the remote control works and what are the various parts to it uh and what are the different processes um and how the parts uh communicate with each other.\n",
      "<ID> Uh I just quickly jotted them down.\n",
      "<ID> The last three bullets have been integrated from uh the last minute uh email.\n",
      "<ID> Okay, so these were the basic findings from today.\n",
      "<ID> Uh we'll then integrate this into the product design at a technical level and uh basically update and come up with a new design, so it's a cyclical process.\n",
      "<UI> Hmm.\n",
      "<ID> Um the identification of the components, uh and uh since since I'm dealing only with the technical aspects, I would need feedback from the marketing person uh and uh from the user interface person.\n",
      "<ID> So this is the method that uh I'll mostly be following in my um in my uh role.\n",
      "<ID> So n uh with uh with regard to the uh working design of this uh uh remote control uh I've identified um a few basic uh components of the remote and uh se uh from the design, functional design perspective um w I c we can now uh know wha what exactly the components are and how how they work together with each other.\n",
      "<ID> Uh okay.\n",
      "<ME> Okay, yeah, afterwards, yeah, okay.\n",
      "<UI> Once we you don't have to do it now but when once you go back, just so that I don't have to scribble everything down.\n",
      "<UI> Just before you start, to make it easier, would you three mind emailing me your presentations?\n",
      "<ID> Um so f from the Right sure.\n",
      "<ID> Right.\n",
      "<ME> Mm.\n",
      "<UI> I assume we just pull it out?\n",
      "<ME> Hmm.\n",
      "<UI> Okay, so we need to unplug my laptop and plug in yours.\n",
      "<UI> You wanna go first?\n",
      "<ID> I can go first, yeah.\n",
      "<ID> Alright.\n",
      "<UI> Does anyone have a preference for going first?\n",
      "<UI> So with that I think it's best if I hand over to you.\n",
      "<UI> So we need to yeah, we need to have a fairly defined group that that we want to focus on and then look at the functions um of the dem remote control itself.\n",
      "<ID> So are Okay.\n",
      "<ID> Uh okay, 'kay.\n",
      "<ME> Um Okay.\n",
      "<UI> As uh who it is that we're going to be trying to sell this thing to, yeah.\n",
      "<ID> You said uh targ target groups, what does that mean?\n",
      "<UI> So I would say yeah?\n",
      "<UI> And we've got forty minutes to do that in.\n",
      "<UI> Um and then we need to, by the end of the meeting come to some kind of decision on who our target group's going to be and what the functions of the remote control that's the the main goal is to come up with those two things, target group and functions of the remote control.\n",
      "<ME> Yeah.\n",
      "<ME> Yeah, the last minute, yeah, yeah.\n",
      "<UI> I just sent at the last minute, I'm sorry about that, but we can see how that affects what you were you were doing.\n",
      "<UI> Um then we need to briefly discuss the new project requirements that were sent to us.\n",
      "<UI> The main the main focus of this meeting is your presentations that you've been preparing during the time, so we'll go through each of you one by one.\n",
      "<UI> Um I'll act as secretary for this meeting and just take minutes as we go through, and then I'll send them to you after the meeting.\n",
      "<UI> I'll do that next time.\n",
      "<UI> Yep.\n",
      "<ME> Yes, I think so.\n",
      "<UI> Is it best if I send you an email maybe, to let you know it's there?\n",
      "<ME> Oh okay, yeah.\n",
      "<UI> So I'll put it in there.\n",
      "<UI> Project documents, yeah.\n",
      "<ME> Oh project project documents, yeah, yeah, yeah, okay.\n",
      "<ME> Um um wi on on a what?\n",
      "<ME> Mm.\n",
      "<UI> Um and it should be in there.\n",
      "<UI> Um I'll try and do that for the next meeting as well so if you check in there, there's a shared project documents folder.\n",
      "<UI> Oh well.\n",
      "<UI> No.\n",
      "<ID> Mm.\n",
      "<ME> No.\n",
      "<UI> Did anyone?\n",
      "<UI> I don't know if that meant that you could see it or not.\n",
      "<UI> The agenda for the meeting, I put it in the sh shared documents folder.\n",
      "<UI> Um hopefully this meeting I'll be doing a little bit less talking than I did last time 'cause this is when you get to show us what you've been doing individually.\n",
      "<UI> Okay, so now we are here at the functional design meeting.\n",
      "<UI> All hooked up.\n"
     ]
    }
   ],
   "source": [
    "# Tests for chunking algorithm\n",
    "import os\n",
    "\n",
    "sample_file_path = 'input/texts/' + samples[0]\n",
    "sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "sample = sample_file.read()\n",
    "sample_file.close()\n",
    "\n",
    "chunks = chunkize(sample)\n",
    "for chunk in chunks:\n",
    "    print('-----------------------------------------')\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sample(sample):\n",
    "\n",
    "    # Current summary is the concatenation of all the chunk sub-summaries \n",
    "    current_summary = ''\n",
    "\n",
    "    # Split into chunks\n",
    "    for chunk in chunkize(sample):\n",
    "\n",
    "        # Create prompt for this chunk\n",
    "        prompt = PROMPT_TEMPLATE.format(text=chunk)\n",
    "\n",
    "        # Sample one sub-input\n",
    "        input_ids = tokenizer(chunk, return_tensors=\"pt\").to('cuda')\n",
    "        output_ids = model.generate(**input_ids, do_sample=True, max_new_tokens=2048, top_k=100, eos_token_id=50256, temperature=0.3)\n",
    "        output = tokenizer.decode(sample[0]).strip()\n",
    "\n",
    "        # Add to summary\n",
    "        if len(current_summary) > 0:\n",
    "            current_summary += '\\n\\n'\n",
    "        current_summary += output\n",
    "    \n",
    "    return current_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation...\n",
      "Prompting instruction N1/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_1.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_2.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_3.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_4.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_5.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_6.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_7.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_8.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_9.txt', skipped.\n",
      "Prompting instruction N1/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/1_10.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_1.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_2.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_3.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_4.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_5.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_6.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_7.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_8.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_9.txt', skipped.\n",
      "Prompting instruction N2/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/2_10.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_1.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_2.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_3.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_4.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_5.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_6.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_7.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_8.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_9.txt', skipped.\n",
      "Prompting instruction N3/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/3_10.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_1.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_2.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_3.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_4.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_5.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_6.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_7.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_8.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_9.txt', skipped.\n",
      "Prompting instruction N4/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/4_10.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_1.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_2.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_3.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_4.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_5.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_6.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_7.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_8.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_9.txt', skipped.\n",
      "Prompting instruction N5/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/5_10.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N1/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_1.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N2/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_2.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N3/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_3.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N4/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_4.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N5/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_5.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N6/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_6.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N7/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_7.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N8/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_8.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N9/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_9.txt', skipped.\n",
      "Prompting instruction N6/6 on sample N10/10\n",
      "-- Completion: 0.0%\n",
      "-- Found intermediate result file 'intermediate/6_10.txt', skipped.\n",
      "Done! Took 0:00:00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# ==========================================================================================\n",
    "initial_time = time.time()\n",
    "skipped_samples = 0\n",
    "\n",
    "mkdir('intermediate')\n",
    "\n",
    "print('Starting computation...')\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Estimate completion and time.\n",
    "    cur_samples = sample_n - skipped_samples\n",
    "    tot_samples = n_samples - skipped_samples\n",
    "    progress = cur_samples / tot_samples\n",
    "    pct = round(progress * 100, 1)\n",
    "    print('Prompting on sample N' + str(sample_n + 1) + '/' + str(n_samples))\n",
    "    print('-- Completion: ' + str(pct) + '%')\n",
    "    if cur_samples > 0:\n",
    "        approx_total = (time.time() - initial_time) / cur_samples * tot_samples\n",
    "        approx_remaining = approx_total * (1 - progress)\n",
    "        print('-- Estimated Remaining Time: ' + str(datetime.timedelta(seconds=int(approx_remaining))) + ' (total ' + str(datetime.timedelta(seconds=int(approx_total))) + ')')\n",
    "    \n",
    "    # Read sample and generate prompt\n",
    "    sample_file_path = 'input/texts/' + samples[sample_n]\n",
    "    sample_file = open(sample_file_path, 'r', encoding='utf-8')\n",
    "    sample = sample_file.read()\n",
    "    sample_file.close()\n",
    "    \n",
    "    # Find target file\n",
    "    target_file_path = 'intermediate/' + samples[sample_n]\n",
    "    if os.path.isfile(target_file_path):\n",
    "        print('-- Found intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        skipped_samples += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Inference\n",
    "        output = inference_sample(sample)\n",
    "\n",
    "        # Save answer in file\n",
    "        target_file = open(target_file_path, 'w', encoding='utf-8')\n",
    "        target_file.write(output)\n",
    "        target_file.close()\n",
    "    \n",
    "    except:\n",
    "        print('Could not compute prompt:')\n",
    "        print(sample)\n",
    "        traceback.print_exc()\n",
    "\n",
    "delta = time.time() - initial_time\n",
    "print('Done! Took', datetime.timedelta(seconds=int(delta)), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk->rouge_score) (1.1.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=333555242f4e464ad2f1466233462741b2f13d4d85af3a6bfe866ca7f1f269f6\n",
      "  Stored in directory: /home/linagora/.cache/pip/wheels/3e/94/5c/7ff8a51c53c1bbc8df4cac58aa4990ffbc6fa203e9f0808fdd\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge, absl-py, rouge_score\n",
      "Successfully installed absl-py-1.4.0 rouge-1.0.1 rouge_score-0.1.2\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (2.28.1)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: pandas in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: packaging in /home/linagora/anaconda3/lib/python3.10/site-packages (from evaluate) (22.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/linagora/anaconda3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, responses, datasets, evaluate\n",
      "Successfully installed datasets-2.13.1 evaluate-0.4.0 multiprocess-0.70.14 pyarrow-12.0.1 responses-0.18.0 xxhash-3.2.0\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from bert-score) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (1.5.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (22.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from bert-score) (4.31.0.dev0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2022.7)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.10.3.66)\n",
      "Requirement already satisfied: sympy in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.12.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/linagora/.local/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.7.101)\n",
      "Requirement already satisfied: setuptools in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/linagora/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/linagora/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (16.0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/linagora/anaconda3/lib/python3.10/site-packages (from requests->bert-score) (2.0.4)\n",
      "Requirement already satisfied: fsspec in /home/linagora/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score) (2022.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/linagora/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/linagora/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/linagora/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.0.0->bert-score) (1.2.1)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (2022.7.9)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: colorama in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\n",
      "Requirement already satisfied: lxml in /home/linagora/anaconda3/lib/python3.10/site-packages (from sacrebleu) (4.9.1)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.7.0 sacrebleu-2.3.1\n",
      "Requirement already satisfied: nltk in /home/linagora/anaconda3/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: click in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /home/linagora/anaconda3/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score rouge\n",
    "!pip install evaluate\n",
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/linagora/anaconda3/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linagora/.local/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/linagora/anaconda3/lib/libcudart.so'), PosixPath('/home/linagora/anaconda3/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scores computation...\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29575c6ff19f417080dc51bf873afe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df94b1e466be4d65a1b5d7a0aaf213a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 279482.79 seconds, 0.00 sentences/sec\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Methods and variables\n",
    "# ==========================================================================================\n",
    "print('Starting scores computation...')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "STORAGE_FILE_NAME = 'scores'\n",
    "\n",
    "# Used to process out n-shot examples\n",
    "def find_nth_occurrence(s, sub, n):\n",
    "    count = s.count(sub)\n",
    "    if count < n:\n",
    "        return -1\n",
    "    else:\n",
    "        index = -1\n",
    "        for i in range(n):\n",
    "            index = s.find(sub, index+1)\n",
    "        return index\n",
    "\n",
    "# Script itself\n",
    "# ==========================================================================================\n",
    "\n",
    "# Find output file for CSV scores\n",
    "mkdir('output')\n",
    "storage_file = open('output/' + STORAGE_FILE_NAME + '.csv', 'w', encoding='utf-8')\n",
    "storage_file.write('path;rouge2;rougel;bertscore\\n')\n",
    "\n",
    "target_file_paths = []\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "# For each sample in dataset\n",
    "for sample_n in range(n_samples):\n",
    "\n",
    "    # Find generated summary\n",
    "    target_file_path = 'intermediate/' + samples[sample_n]\n",
    "    if not os.path.isfile(target_file_path):\n",
    "        print('-- Found no intermediate result file \\'' + target_file_path + '\\', skipped.')\n",
    "        continue\n",
    "\n",
    "    # Read sample and generate prompt -> Keep summary\n",
    "    summary_file_path = 'input/summaries/' + samples[sample_n]\n",
    "    summary_file = open(summary_file_path, 'r', encoding='utf-8')\n",
    "    references.append(summary_file.read())\n",
    "    summary_file.close()\n",
    "\n",
    "    # Access generated summary\n",
    "    target_file = open(target_file_path, 'r', encoding='utf-8')\n",
    "    prediction = target_file.read()\n",
    "    target_file.close()\n",
    "\n",
    "    # Process answer\n",
    "    separator = \"### Assistant:\"\n",
    "    cut_index = find_nth_occurrence(prediction, separator, 3) + len(separator)\n",
    "    prediction = prediction[cut_index:]\n",
    "    if prediction[0] == \" \": # Enlever l'espace devant\n",
    "        prediction = prediction[1:]\n",
    "    prediction = prediction[:-len(\"<|endoftext|>\") - 2]\n",
    "\n",
    "    # Add prediction\n",
    "    target_file_paths.append(target_file_path)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calculate metrics\n",
    "result_rouge = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "result_bertscore = bertscore.compute(predictions=predictions, references=references, lang='fr', rescale_with_baseline=True, verbose=True)\n",
    "\n",
    "# Write to csv\n",
    "# Forget about BLEU...\n",
    "# Format: PATH | ROUGE2 | ROUGEL | BERTScore\n",
    "for i in range(len(target_file_paths)):\n",
    "    ligne = target_file_paths[i]\n",
    "    ligne += ';' + str(result_rouge['rouge2'][i]) + \";\" + str(result_rouge['rougeL'][i])\n",
    "    #ligne += \";\" + str(result_bleu['bleu'])\n",
    "    ligne += \";\" + str(result_bertscore['f1'][i])\n",
    "\n",
    "    storage_file.write(ligne + '\\n')\n",
    "\n",
    "storage_file.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
